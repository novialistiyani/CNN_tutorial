{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional Neural Network (CNN) with TensorFlow\n",
    "\n",
    "CNN is a type of architecture in deep learning. Unlike simple deep learning where every layer is fully connected each other, there is sort of selective mechanism. This mechanism can happen thanks to special strcucture named as convolutional layer. Neurons in the first convolutional layer is connected only to pixels in their receptive fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_1.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_2c.png' style='width: 500px' align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_1a.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the implementation, usually the filter is applied to produce several feature maps at once. In a sense, we can imagine that these feature maps try to capture different properties of the image, like horizontal line, edges, vertical lines, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_2.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_1b.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_1c.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A closer look on convolutional layer with more than 1 output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_2a.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_2b.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In addition to convolutional layer, there is also pooling layer in CNN. Intuitively speaking, this layer creates a more compact information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_3a.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_3b.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usually, if we intend to use CNN for classification, there is also fully connected layer. This layer should remind us with the ordinary neural network where every weight is connected to its input (instead of just looking at a particular region of the images like convolutional layer or pooling layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/cnn_3.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In conclusion, there are three basic layers in CNN architecture: convolutional layer, pooling layer, and fully connected layer. Different combination of these basic layers can lead to different result in images classification. In the following section, we will observe the implementation of two early CNN architectures. Nevertheless, we should note that these examples are presented to give rough idea on how we can use TensorFlow to build CNN architecture in images classification. There are many other CNN architecture out there with tweaks and modification in its layers - that allows much better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FIRST TRIAL: LE-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/lenet.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/lenet_table.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/fashion', one_hot = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcea0ba3890>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcea0c90750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[100, :].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 49078.7344, Training Accuracy= 0.242\n",
      "Step 10, Minibatch Loss= 14592.0947, Training Accuracy= 0.414\n",
      "Step 20, Minibatch Loss= 10851.8115, Training Accuracy= 0.516\n",
      "Step 30, Minibatch Loss= 7342.7041, Training Accuracy= 0.656\n",
      "Step 40, Minibatch Loss= 4198.0322, Training Accuracy= 0.719\n",
      "Step 50, Minibatch Loss= 5287.4971, Training Accuracy= 0.734\n",
      "Step 60, Minibatch Loss= 7388.8906, Training Accuracy= 0.688\n",
      "Step 70, Minibatch Loss= 4676.9697, Training Accuracy= 0.766\n",
      "Step 80, Minibatch Loss= 3998.1355, Training Accuracy= 0.758\n",
      "Step 90, Minibatch Loss= 5508.6729, Training Accuracy= 0.773\n",
      "Step 100, Minibatch Loss= 2534.5591, Training Accuracy= 0.789\n",
      "Step 110, Minibatch Loss= 2641.8672, Training Accuracy= 0.805\n",
      "Step 120, Minibatch Loss= 4387.5078, Training Accuracy= 0.781\n",
      "Step 130, Minibatch Loss= 5260.2881, Training Accuracy= 0.688\n",
      "Step 140, Minibatch Loss= 4381.7178, Training Accuracy= 0.758\n",
      "Step 150, Minibatch Loss= 1163.1853, Training Accuracy= 0.867\n",
      "Step 160, Minibatch Loss= 2391.1814, Training Accuracy= 0.758\n",
      "Step 170, Minibatch Loss= 2112.5298, Training Accuracy= 0.773\n",
      "Step 180, Minibatch Loss= 3051.1504, Training Accuracy= 0.773\n",
      "Step 190, Minibatch Loss= 3228.3369, Training Accuracy= 0.727\n",
      "Step 200, Minibatch Loss= 1571.8259, Training Accuracy= 0.836\n",
      "Step 210, Minibatch Loss= 2670.4504, Training Accuracy= 0.758\n",
      "Step 220, Minibatch Loss= 1663.6615, Training Accuracy= 0.836\n",
      "Step 230, Minibatch Loss= 2278.7681, Training Accuracy= 0.750\n",
      "Step 240, Minibatch Loss= 1971.8657, Training Accuracy= 0.812\n",
      "Step 250, Minibatch Loss= 1562.1454, Training Accuracy= 0.836\n",
      "Step 260, Minibatch Loss= 1474.9932, Training Accuracy= 0.828\n",
      "Step 270, Minibatch Loss= 1567.4247, Training Accuracy= 0.867\n",
      "Step 280, Minibatch Loss= 2580.1987, Training Accuracy= 0.812\n",
      "Step 290, Minibatch Loss= 2355.4468, Training Accuracy= 0.781\n",
      "Step 300, Minibatch Loss= 1552.5558, Training Accuracy= 0.797\n",
      "Step 310, Minibatch Loss= 1088.5074, Training Accuracy= 0.930\n",
      "Step 320, Minibatch Loss= 1219.8113, Training Accuracy= 0.836\n",
      "Step 330, Minibatch Loss= 1538.5376, Training Accuracy= 0.797\n",
      "Step 340, Minibatch Loss= 1332.9983, Training Accuracy= 0.852\n",
      "Step 350, Minibatch Loss= 1102.1946, Training Accuracy= 0.859\n",
      "Step 360, Minibatch Loss= 1634.9080, Training Accuracy= 0.781\n",
      "Step 370, Minibatch Loss= 1284.8374, Training Accuracy= 0.898\n",
      "Step 380, Minibatch Loss= 1500.4894, Training Accuracy= 0.812\n",
      "Step 390, Minibatch Loss= 1102.4517, Training Accuracy= 0.836\n",
      "Step 400, Minibatch Loss= 1347.7534, Training Accuracy= 0.820\n",
      "Step 410, Minibatch Loss= 1636.1638, Training Accuracy= 0.844\n",
      "Step 420, Minibatch Loss= 1114.7887, Training Accuracy= 0.812\n",
      "Step 430, Minibatch Loss= 1718.9268, Training Accuracy= 0.797\n",
      "Step 440, Minibatch Loss= 1305.6111, Training Accuracy= 0.875\n",
      "Step 450, Minibatch Loss= 1422.1166, Training Accuracy= 0.773\n",
      "Step 460, Minibatch Loss= 1160.0807, Training Accuracy= 0.844\n",
      "Step 470, Minibatch Loss= 494.9761, Training Accuracy= 0.883\n",
      "Step 480, Minibatch Loss= 587.7359, Training Accuracy= 0.883\n",
      "Step 490, Minibatch Loss= 640.0932, Training Accuracy= 0.898\n",
      "Step 500, Minibatch Loss= 690.5934, Training Accuracy= 0.898\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.871094\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### SECOND TRIAL: ALEX-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/alexnet.png' style='width: 1000px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./images/alexnet_table.png' style='width: 500px' align='left'/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 64\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.8 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create AlexNet model\n",
    "def conv2d(name, l_input, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, 1, 1, 1], padding='SAME'),b), name=name)\n",
    "\n",
    "def max_pool(name, l_input, k):\n",
    "    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME', name=name)\n",
    "\n",
    "def norm(name, l_input, lsize=4):\n",
    "    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)\n",
    "\n",
    "def alex_net(_X, _weights, _biases, _dropout):\n",
    "    # Reshape input picture\n",
    "    _X = tf.reshape(_X, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "        # Convolution Layer\n",
    "    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool1 = max_pool('pool1', conv1, k=2)\n",
    "    # Apply Normalization\n",
    "    norm1 = norm('norm1', pool1, lsize=4)\n",
    "    # Apply Dropout\n",
    "    norm1 = tf.nn.dropout(norm1, _dropout)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d('conv2', norm1, _weights['wc2'], _biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool2 = max_pool('pool2', conv2, k=2)\n",
    "    # Apply Normalization\n",
    "    norm2 = norm('norm2', pool2, lsize=4)\n",
    "    # Apply Dropout\n",
    "    norm2 = tf.nn.dropout(norm2, _dropout)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d('conv3', norm2, _weights['wc3'], _biases['bc3'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    pool3 = max_pool('pool3', conv3, k=2)\n",
    "    # Apply Normalization\n",
    "    norm3 = norm('norm3', pool3, lsize=4)\n",
    "    # Apply Dropout\n",
    "    norm3 = tf.nn.dropout(norm3, _dropout)\n",
    "\n",
    "    # Fully connected layer\n",
    "    dense1 = tf.reshape(norm3, [-1, _weights['wd1'].get_shape().as_list()[0]]) # Reshape conv3 output to fit dense layer input\n",
    "    dense1 = tf.nn.relu(tf.matmul(dense1, _weights['wd1']) + _biases['bd1'], name='fc1') # Relu activation\n",
    "\n",
    "    dense2 = tf.nn.relu(tf.matmul(dense1, _weights['wd2']) + _biases['bd2'], name='fc2') # Relu activation\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.matmul(dense2, _weights['out']) + _biases['out']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([3, 3, 1, 64])),\n",
    "    'wc2': tf.Variable(tf.random_normal([3, 3, 64, 128])),\n",
    "    'wc3': tf.Variable(tf.random_normal([3, 3, 128, 256])),\n",
    "    'wd1': tf.Variable(tf.random_normal([4*4*256, 1024])),\n",
    "    'wd2': tf.Variable(tf.random_normal([1024, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, 10]))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([64])),\n",
    "    'bc2': tf.Variable(tf.random_normal([128])),\n",
    "    'bc3': tf.Variable(tf.random_normal([256])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'bd2': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Construct model\n",
    "pred = alex_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 64, Minibatch Loss= 331836.437500, Training Accuracy= 0.09375\n",
      "Iter 128, Minibatch Loss= 219700.031250, Training Accuracy= 0.12500\n",
      "Iter 192, Minibatch Loss= 183833.218750, Training Accuracy= 0.12500\n",
      "Iter 256, Minibatch Loss= 190779.093750, Training Accuracy= 0.18750\n",
      "Iter 320, Minibatch Loss= 152620.343750, Training Accuracy= 0.21875\n",
      "Iter 384, Minibatch Loss= 217480.343750, Training Accuracy= 0.06250\n",
      "Iter 448, Minibatch Loss= 160081.812500, Training Accuracy= 0.18750\n",
      "Iter 512, Minibatch Loss= 203565.515625, Training Accuracy= 0.09375\n",
      "Iter 576, Minibatch Loss= 160180.843750, Training Accuracy= 0.20312\n",
      "Iter 640, Minibatch Loss= 190081.218750, Training Accuracy= 0.17188\n",
      "Iter 704, Minibatch Loss= 166249.906250, Training Accuracy= 0.06250\n",
      "Iter 768, Minibatch Loss= 123140.734375, Training Accuracy= 0.20312\n",
      "Iter 832, Minibatch Loss= 107390.593750, Training Accuracy= 0.15625\n",
      "Iter 896, Minibatch Loss= 98538.312500, Training Accuracy= 0.26562\n",
      "Iter 960, Minibatch Loss= 116233.820312, Training Accuracy= 0.35938\n",
      "Iter 1024, Minibatch Loss= 126497.914062, Training Accuracy= 0.31250\n",
      "Iter 1088, Minibatch Loss= 178323.625000, Training Accuracy= 0.17188\n",
      "Iter 1152, Minibatch Loss= 133608.296875, Training Accuracy= 0.23438\n",
      "Iter 1216, Minibatch Loss= 110541.890625, Training Accuracy= 0.39062\n",
      "Iter 1280, Minibatch Loss= 91214.140625, Training Accuracy= 0.40625\n",
      "Iter 1344, Minibatch Loss= 88125.664062, Training Accuracy= 0.34375\n",
      "Iter 1408, Minibatch Loss= 70230.593750, Training Accuracy= 0.50000\n",
      "Iter 1472, Minibatch Loss= 67501.875000, Training Accuracy= 0.46875\n",
      "Iter 1536, Minibatch Loss= 91875.390625, Training Accuracy= 0.39062\n",
      "Iter 1600, Minibatch Loss= 110631.835938, Training Accuracy= 0.28125\n",
      "Iter 1664, Minibatch Loss= 68785.875000, Training Accuracy= 0.37500\n",
      "Iter 1728, Minibatch Loss= 90866.789062, Training Accuracy= 0.31250\n",
      "Iter 1792, Minibatch Loss= 85179.562500, Training Accuracy= 0.28125\n",
      "Iter 1856, Minibatch Loss= 86716.109375, Training Accuracy= 0.35938\n",
      "Iter 1920, Minibatch Loss= 48632.906250, Training Accuracy= 0.50000\n",
      "Iter 1984, Minibatch Loss= 70227.203125, Training Accuracy= 0.29688\n",
      "Iter 2048, Minibatch Loss= 62979.296875, Training Accuracy= 0.48438\n",
      "Iter 2112, Minibatch Loss= 66703.710938, Training Accuracy= 0.53125\n",
      "Iter 2176, Minibatch Loss= 93745.875000, Training Accuracy= 0.34375\n",
      "Iter 2240, Minibatch Loss= 94448.109375, Training Accuracy= 0.34375\n",
      "Iter 2304, Minibatch Loss= 73760.328125, Training Accuracy= 0.53125\n",
      "Iter 2368, Minibatch Loss= 92899.031250, Training Accuracy= 0.39062\n",
      "Iter 2432, Minibatch Loss= 95523.875000, Training Accuracy= 0.29688\n",
      "Iter 2496, Minibatch Loss= 79720.710938, Training Accuracy= 0.43750\n",
      "Iter 2560, Minibatch Loss= 77689.031250, Training Accuracy= 0.42188\n",
      "Iter 2624, Minibatch Loss= 77780.132812, Training Accuracy= 0.37500\n",
      "Iter 2688, Minibatch Loss= 41628.375000, Training Accuracy= 0.51562\n",
      "Iter 2752, Minibatch Loss= 75109.250000, Training Accuracy= 0.42188\n",
      "Iter 2816, Minibatch Loss= 45782.683594, Training Accuracy= 0.43750\n",
      "Iter 2880, Minibatch Loss= 57438.445312, Training Accuracy= 0.35938\n",
      "Iter 2944, Minibatch Loss= 58980.257812, Training Accuracy= 0.37500\n",
      "Iter 3008, Minibatch Loss= 73921.453125, Training Accuracy= 0.40625\n",
      "Iter 3072, Minibatch Loss= 47220.898438, Training Accuracy= 0.51562\n",
      "Iter 3136, Minibatch Loss= 56518.554688, Training Accuracy= 0.43750\n",
      "Iter 3200, Minibatch Loss= 49870.675781, Training Accuracy= 0.45312\n",
      "Iter 3264, Minibatch Loss= 59348.492188, Training Accuracy= 0.37500\n",
      "Iter 3328, Minibatch Loss= 55550.792969, Training Accuracy= 0.48438\n",
      "Iter 3392, Minibatch Loss= 50255.289062, Training Accuracy= 0.48438\n",
      "Iter 3456, Minibatch Loss= 60418.445312, Training Accuracy= 0.43750\n",
      "Iter 3520, Minibatch Loss= 78256.062500, Training Accuracy= 0.45312\n",
      "Iter 3584, Minibatch Loss= 51511.070312, Training Accuracy= 0.45312\n",
      "Iter 3648, Minibatch Loss= 63432.531250, Training Accuracy= 0.37500\n",
      "Iter 3712, Minibatch Loss= 50651.710938, Training Accuracy= 0.35938\n",
      "Iter 3776, Minibatch Loss= 48530.191406, Training Accuracy= 0.43750\n",
      "Iter 3840, Minibatch Loss= 37975.585938, Training Accuracy= 0.53125\n",
      "Iter 3904, Minibatch Loss= 46212.332031, Training Accuracy= 0.51562\n",
      "Iter 3968, Minibatch Loss= 51266.468750, Training Accuracy= 0.45312\n",
      "Iter 4032, Minibatch Loss= 47015.835938, Training Accuracy= 0.40625\n",
      "Iter 4096, Minibatch Loss= 40016.300781, Training Accuracy= 0.50000\n",
      "Iter 4160, Minibatch Loss= 55541.164062, Training Accuracy= 0.46875\n",
      "Iter 4224, Minibatch Loss= 29340.156250, Training Accuracy= 0.53125\n",
      "Iter 4288, Minibatch Loss= 37035.929688, Training Accuracy= 0.54688\n",
      "Iter 4352, Minibatch Loss= 58154.707031, Training Accuracy= 0.45312\n",
      "Iter 4416, Minibatch Loss= 52664.394531, Training Accuracy= 0.54688\n",
      "Iter 4480, Minibatch Loss= 54854.921875, Training Accuracy= 0.51562\n",
      "Iter 4544, Minibatch Loss= 55155.648438, Training Accuracy= 0.40625\n",
      "Iter 4608, Minibatch Loss= 44544.234375, Training Accuracy= 0.54688\n",
      "Iter 4672, Minibatch Loss= 66312.835938, Training Accuracy= 0.42188\n",
      "Iter 4736, Minibatch Loss= 46076.968750, Training Accuracy= 0.51562\n",
      "Iter 4800, Minibatch Loss= 53771.000000, Training Accuracy= 0.40625\n",
      "Iter 4864, Minibatch Loss= 34787.839844, Training Accuracy= 0.43750\n",
      "Iter 4928, Minibatch Loss= 35976.726562, Training Accuracy= 0.54688\n",
      "Iter 4992, Minibatch Loss= 37175.921875, Training Accuracy= 0.50000\n",
      "Iter 5056, Minibatch Loss= 36359.648438, Training Accuracy= 0.46875\n",
      "Iter 5120, Minibatch Loss= 45441.824219, Training Accuracy= 0.45312\n",
      "Iter 5184, Minibatch Loss= 42005.234375, Training Accuracy= 0.43750\n",
      "Iter 5248, Minibatch Loss= 29687.103516, Training Accuracy= 0.56250\n",
      "Iter 5312, Minibatch Loss= 32448.171875, Training Accuracy= 0.60938\n",
      "Iter 5376, Minibatch Loss= 32433.544922, Training Accuracy= 0.57812\n",
      "Iter 5440, Minibatch Loss= 41228.019531, Training Accuracy= 0.48438\n",
      "Iter 5504, Minibatch Loss= 36491.382812, Training Accuracy= 0.65625\n",
      "Iter 5568, Minibatch Loss= 37935.898438, Training Accuracy= 0.62500\n",
      "Iter 5632, Minibatch Loss= 47135.082031, Training Accuracy= 0.54688\n",
      "Iter 5696, Minibatch Loss= 43052.261719, Training Accuracy= 0.50000\n",
      "Iter 5760, Minibatch Loss= 50158.851562, Training Accuracy= 0.40625\n",
      "Iter 5824, Minibatch Loss= 41925.691406, Training Accuracy= 0.46875\n",
      "Iter 5888, Minibatch Loss= 65204.726562, Training Accuracy= 0.43750\n",
      "Iter 5952, Minibatch Loss= 43348.691406, Training Accuracy= 0.53125\n",
      "Iter 6016, Minibatch Loss= 48993.898438, Training Accuracy= 0.48438\n",
      "Iter 6080, Minibatch Loss= 42026.429688, Training Accuracy= 0.48438\n",
      "Iter 6144, Minibatch Loss= 33577.269531, Training Accuracy= 0.57812\n",
      "Iter 6208, Minibatch Loss= 30193.275391, Training Accuracy= 0.65625\n",
      "Iter 6272, Minibatch Loss= 38993.523438, Training Accuracy= 0.53125\n",
      "Iter 6336, Minibatch Loss= 26029.619141, Training Accuracy= 0.60938\n",
      "Iter 6400, Minibatch Loss= 49127.390625, Training Accuracy= 0.53125\n",
      "Iter 6464, Minibatch Loss= 36258.269531, Training Accuracy= 0.51562\n",
      "Iter 6528, Minibatch Loss= 53754.250000, Training Accuracy= 0.45312\n",
      "Iter 6592, Minibatch Loss= 43219.820312, Training Accuracy= 0.50000\n",
      "Iter 6656, Minibatch Loss= 41045.363281, Training Accuracy= 0.56250\n",
      "Iter 6720, Minibatch Loss= 32302.121094, Training Accuracy= 0.59375\n",
      "Iter 6784, Minibatch Loss= 35464.523438, Training Accuracy= 0.57812\n",
      "Iter 6848, Minibatch Loss= 29251.234375, Training Accuracy= 0.65625\n",
      "Iter 6912, Minibatch Loss= 37683.859375, Training Accuracy= 0.56250\n",
      "Iter 6976, Minibatch Loss= 32789.031250, Training Accuracy= 0.67188\n",
      "Iter 7040, Minibatch Loss= 43307.523438, Training Accuracy= 0.48438\n",
      "Iter 7104, Minibatch Loss= 20792.675781, Training Accuracy= 0.67188\n",
      "Iter 7168, Minibatch Loss= 44283.960938, Training Accuracy= 0.56250\n",
      "Iter 7232, Minibatch Loss= 42972.382812, Training Accuracy= 0.59375\n",
      "Iter 7296, Minibatch Loss= 49648.273438, Training Accuracy= 0.51562\n",
      "Iter 7360, Minibatch Loss= 36460.753906, Training Accuracy= 0.60938\n",
      "Iter 7424, Minibatch Loss= 39891.367188, Training Accuracy= 0.62500\n",
      "Iter 7488, Minibatch Loss= 49464.207031, Training Accuracy= 0.54688\n",
      "Iter 7552, Minibatch Loss= 44845.593750, Training Accuracy= 0.51562\n",
      "Iter 7616, Minibatch Loss= 73998.523438, Training Accuracy= 0.40625\n",
      "Iter 7680, Minibatch Loss= 39565.855469, Training Accuracy= 0.57812\n",
      "Iter 7744, Minibatch Loss= 37011.828125, Training Accuracy= 0.59375\n",
      "Iter 7808, Minibatch Loss= 34663.703125, Training Accuracy= 0.67188\n",
      "Iter 7872, Minibatch Loss= 24768.804688, Training Accuracy= 0.64062\n",
      "Iter 7936, Minibatch Loss= 26305.007812, Training Accuracy= 0.65625\n",
      "Iter 8000, Minibatch Loss= 45974.062500, Training Accuracy= 0.56250\n",
      "Iter 8064, Minibatch Loss= 26730.835938, Training Accuracy= 0.59375\n",
      "Iter 8128, Minibatch Loss= 32708.466797, Training Accuracy= 0.60938\n",
      "Iter 8192, Minibatch Loss= 27190.460938, Training Accuracy= 0.59375\n",
      "Iter 8256, Minibatch Loss= 29333.976562, Training Accuracy= 0.54688\n",
      "Iter 8320, Minibatch Loss= 32904.812500, Training Accuracy= 0.59375\n",
      "Iter 8384, Minibatch Loss= 23761.523438, Training Accuracy= 0.73438\n",
      "Iter 8448, Minibatch Loss= 31040.769531, Training Accuracy= 0.60938\n",
      "Iter 8512, Minibatch Loss= 36976.574219, Training Accuracy= 0.59375\n",
      "Iter 8576, Minibatch Loss= 41811.781250, Training Accuracy= 0.51562\n",
      "Iter 8640, Minibatch Loss= 37878.156250, Training Accuracy= 0.57812\n",
      "Iter 8704, Minibatch Loss= 50082.148438, Training Accuracy= 0.50000\n",
      "Iter 8768, Minibatch Loss= 27769.187500, Training Accuracy= 0.59375\n",
      "Iter 8832, Minibatch Loss= 49484.734375, Training Accuracy= 0.54688\n",
      "Iter 8896, Minibatch Loss= 42025.691406, Training Accuracy= 0.46875\n",
      "Iter 8960, Minibatch Loss= 27740.455078, Training Accuracy= 0.56250\n",
      "Iter 9024, Minibatch Loss= 45162.414062, Training Accuracy= 0.56250\n",
      "Iter 9088, Minibatch Loss= 39752.839844, Training Accuracy= 0.57812\n",
      "Iter 9152, Minibatch Loss= 51107.429688, Training Accuracy= 0.42188\n",
      "Iter 9216, Minibatch Loss= 39088.710938, Training Accuracy= 0.56250\n",
      "Iter 9280, Minibatch Loss= 33034.953125, Training Accuracy= 0.59375\n",
      "Iter 9344, Minibatch Loss= 37821.058594, Training Accuracy= 0.54688\n",
      "Iter 9408, Minibatch Loss= 42421.605469, Training Accuracy= 0.60938\n",
      "Iter 9472, Minibatch Loss= 31403.082031, Training Accuracy= 0.62500\n",
      "Iter 9536, Minibatch Loss= 23822.105469, Training Accuracy= 0.65625\n",
      "Iter 9600, Minibatch Loss= 27317.867188, Training Accuracy= 0.64062\n",
      "Iter 9664, Minibatch Loss= 37348.570312, Training Accuracy= 0.57812\n",
      "Iter 9728, Minibatch Loss= 49597.070312, Training Accuracy= 0.53125\n",
      "Iter 9792, Minibatch Loss= 35208.289062, Training Accuracy= 0.53125\n",
      "Iter 9856, Minibatch Loss= 22759.498047, Training Accuracy= 0.68750\n",
      "Iter 9920, Minibatch Loss= 47419.074219, Training Accuracy= 0.59375\n",
      "Iter 9984, Minibatch Loss= 34343.378906, Training Accuracy= 0.56250\n",
      "Iter 10048, Minibatch Loss= 32701.185547, Training Accuracy= 0.59375\n",
      "Iter 10112, Minibatch Loss= 39071.367188, Training Accuracy= 0.57812\n",
      "Iter 10176, Minibatch Loss= 28644.878906, Training Accuracy= 0.60938\n",
      "Iter 10240, Minibatch Loss= 42879.781250, Training Accuracy= 0.50000\n",
      "Iter 10304, Minibatch Loss= 41404.796875, Training Accuracy= 0.56250\n",
      "Iter 10368, Minibatch Loss= 43413.093750, Training Accuracy= 0.48438\n",
      "Iter 10432, Minibatch Loss= 22506.089844, Training Accuracy= 0.65625\n",
      "Iter 10496, Minibatch Loss= 27431.277344, Training Accuracy= 0.62500\n",
      "Iter 10560, Minibatch Loss= 59658.234375, Training Accuracy= 0.39062\n",
      "Iter 10624, Minibatch Loss= 36544.015625, Training Accuracy= 0.54688\n",
      "Iter 10688, Minibatch Loss= 38171.816406, Training Accuracy= 0.54688\n",
      "Iter 10752, Minibatch Loss= 32451.281250, Training Accuracy= 0.59375\n",
      "Iter 10816, Minibatch Loss= 23929.587891, Training Accuracy= 0.62500\n",
      "Iter 10880, Minibatch Loss= 19006.859375, Training Accuracy= 0.75000\n",
      "Iter 10944, Minibatch Loss= 26032.597656, Training Accuracy= 0.64062\n",
      "Iter 11008, Minibatch Loss= 49230.035156, Training Accuracy= 0.56250\n",
      "Iter 11072, Minibatch Loss= 28015.625000, Training Accuracy= 0.67188\n",
      "Iter 11136, Minibatch Loss= 49908.632812, Training Accuracy= 0.64062\n",
      "Iter 11200, Minibatch Loss= 52174.492188, Training Accuracy= 0.45312\n",
      "Iter 11264, Minibatch Loss= 37720.246094, Training Accuracy= 0.62500\n",
      "Iter 11328, Minibatch Loss= 26127.625000, Training Accuracy= 0.70312\n",
      "Iter 11392, Minibatch Loss= 42809.609375, Training Accuracy= 0.59375\n",
      "Iter 11456, Minibatch Loss= 47093.320312, Training Accuracy= 0.57812\n",
      "Iter 11520, Minibatch Loss= 26562.085938, Training Accuracy= 0.68750\n",
      "Iter 11584, Minibatch Loss= 31670.296875, Training Accuracy= 0.59375\n",
      "Iter 11648, Minibatch Loss= 30378.568359, Training Accuracy= 0.60938\n",
      "Iter 11712, Minibatch Loss= 29912.343750, Training Accuracy= 0.60938\n",
      "Iter 11776, Minibatch Loss= 29645.855469, Training Accuracy= 0.57812\n",
      "Iter 11840, Minibatch Loss= 22701.478516, Training Accuracy= 0.65625\n",
      "Iter 11904, Minibatch Loss= 36692.593750, Training Accuracy= 0.57812\n",
      "Iter 11968, Minibatch Loss= 24183.125000, Training Accuracy= 0.73438\n",
      "Iter 12032, Minibatch Loss= 34484.097656, Training Accuracy= 0.57812\n",
      "Iter 12096, Minibatch Loss= 41165.843750, Training Accuracy= 0.57812\n",
      "Iter 12160, Minibatch Loss= 35909.421875, Training Accuracy= 0.57812\n",
      "Iter 12224, Minibatch Loss= 32246.914062, Training Accuracy= 0.62500\n",
      "Iter 12288, Minibatch Loss= 27387.488281, Training Accuracy= 0.75000\n",
      "Iter 12352, Minibatch Loss= 36707.089844, Training Accuracy= 0.57812\n",
      "Iter 12416, Minibatch Loss= 27201.281250, Training Accuracy= 0.59375\n",
      "Iter 12480, Minibatch Loss= 35546.679688, Training Accuracy= 0.53125\n",
      "Iter 12544, Minibatch Loss= 28662.478516, Training Accuracy= 0.56250\n",
      "Iter 12608, Minibatch Loss= 36771.085938, Training Accuracy= 0.62500\n",
      "Iter 12672, Minibatch Loss= 35206.136719, Training Accuracy= 0.57812\n",
      "Iter 12736, Minibatch Loss= 28292.056641, Training Accuracy= 0.65625\n",
      "Iter 12800, Minibatch Loss= 38328.671875, Training Accuracy= 0.53125\n",
      "Iter 12864, Minibatch Loss= 30059.822266, Training Accuracy= 0.57812\n",
      "Iter 12928, Minibatch Loss= 28144.675781, Training Accuracy= 0.59375\n",
      "Iter 12992, Minibatch Loss= 33129.292969, Training Accuracy= 0.68750\n",
      "Iter 13056, Minibatch Loss= 33088.042969, Training Accuracy= 0.54688\n",
      "Iter 13120, Minibatch Loss= 32318.136719, Training Accuracy= 0.54688\n",
      "Iter 13184, Minibatch Loss= 25526.363281, Training Accuracy= 0.57812\n",
      "Iter 13248, Minibatch Loss= 23113.527344, Training Accuracy= 0.65625\n",
      "Iter 13312, Minibatch Loss= 32272.357422, Training Accuracy= 0.62500\n",
      "Iter 13376, Minibatch Loss= 24665.054688, Training Accuracy= 0.71875\n",
      "Iter 13440, Minibatch Loss= 20069.378906, Training Accuracy= 0.73438\n",
      "Iter 13504, Minibatch Loss= 47813.121094, Training Accuracy= 0.53125\n",
      "Iter 13568, Minibatch Loss= 26572.156250, Training Accuracy= 0.59375\n",
      "Iter 13632, Minibatch Loss= 28653.179688, Training Accuracy= 0.65625\n",
      "Iter 13696, Minibatch Loss= 33430.554688, Training Accuracy= 0.65625\n",
      "Iter 13760, Minibatch Loss= 9787.449219, Training Accuracy= 0.81250\n",
      "Iter 13824, Minibatch Loss= 47740.453125, Training Accuracy= 0.51562\n",
      "Iter 13888, Minibatch Loss= 41607.546875, Training Accuracy= 0.57812\n",
      "Iter 13952, Minibatch Loss= 41969.382812, Training Accuracy= 0.51562\n",
      "Iter 14016, Minibatch Loss= 29631.449219, Training Accuracy= 0.53125\n",
      "Iter 14080, Minibatch Loss= 34114.144531, Training Accuracy= 0.59375\n",
      "Iter 14144, Minibatch Loss= 24593.167969, Training Accuracy= 0.59375\n",
      "Iter 14208, Minibatch Loss= 25597.628906, Training Accuracy= 0.53125\n",
      "Iter 14272, Minibatch Loss= 26572.613281, Training Accuracy= 0.56250\n",
      "Iter 14336, Minibatch Loss= 15183.466797, Training Accuracy= 0.78125\n",
      "Iter 14400, Minibatch Loss= 22427.371094, Training Accuracy= 0.62500\n",
      "Iter 14464, Minibatch Loss= 17842.292969, Training Accuracy= 0.71875\n",
      "Iter 14528, Minibatch Loss= 21228.179688, Training Accuracy= 0.62500\n",
      "Iter 14592, Minibatch Loss= 18331.785156, Training Accuracy= 0.68750\n",
      "Iter 14656, Minibatch Loss= 31496.142578, Training Accuracy= 0.54688\n",
      "Iter 14720, Minibatch Loss= 30653.259766, Training Accuracy= 0.73438\n",
      "Iter 14784, Minibatch Loss= 29536.205078, Training Accuracy= 0.73438\n",
      "Iter 14848, Minibatch Loss= 25016.535156, Training Accuracy= 0.71875\n",
      "Iter 14912, Minibatch Loss= 31612.404297, Training Accuracy= 0.62500\n",
      "Iter 14976, Minibatch Loss= 20522.339844, Training Accuracy= 0.67188\n",
      "Iter 15040, Minibatch Loss= 38075.566406, Training Accuracy= 0.62500\n",
      "Iter 15104, Minibatch Loss= 37713.910156, Training Accuracy= 0.59375\n",
      "Iter 15168, Minibatch Loss= 33536.453125, Training Accuracy= 0.65625\n",
      "Iter 15232, Minibatch Loss= 31701.968750, Training Accuracy= 0.50000\n",
      "Iter 15296, Minibatch Loss= 36947.679688, Training Accuracy= 0.60938\n",
      "Iter 15360, Minibatch Loss= 26392.654297, Training Accuracy= 0.67188\n",
      "Iter 15424, Minibatch Loss= 31873.992188, Training Accuracy= 0.57812\n",
      "Iter 15488, Minibatch Loss= 18767.683594, Training Accuracy= 0.71875\n",
      "Iter 15552, Minibatch Loss= 26060.638672, Training Accuracy= 0.64062\n",
      "Iter 15616, Minibatch Loss= 19544.921875, Training Accuracy= 0.64062\n",
      "Iter 15680, Minibatch Loss= 24017.271484, Training Accuracy= 0.64062\n",
      "Iter 15744, Minibatch Loss= 12094.807617, Training Accuracy= 0.75000\n",
      "Iter 15808, Minibatch Loss= 17795.632812, Training Accuracy= 0.75000\n",
      "Iter 15872, Minibatch Loss= 28897.904297, Training Accuracy= 0.62500\n",
      "Iter 15936, Minibatch Loss= 26931.320312, Training Accuracy= 0.57812\n",
      "Iter 16000, Minibatch Loss= 21730.140625, Training Accuracy= 0.67188\n",
      "Iter 16064, Minibatch Loss= 23740.507812, Training Accuracy= 0.68750\n",
      "Iter 16128, Minibatch Loss= 28008.287109, Training Accuracy= 0.62500\n",
      "Iter 16192, Minibatch Loss= 30214.710938, Training Accuracy= 0.60938\n",
      "Iter 16256, Minibatch Loss= 22817.970703, Training Accuracy= 0.60938\n",
      "Iter 16320, Minibatch Loss= 29770.292969, Training Accuracy= 0.57812\n",
      "Iter 16384, Minibatch Loss= 21167.699219, Training Accuracy= 0.71875\n",
      "Iter 16448, Minibatch Loss= 35920.414062, Training Accuracy= 0.57812\n",
      "Iter 16512, Minibatch Loss= 27872.941406, Training Accuracy= 0.65625\n",
      "Iter 16576, Minibatch Loss= 26560.851562, Training Accuracy= 0.67188\n",
      "Iter 16640, Minibatch Loss= 35499.136719, Training Accuracy= 0.53125\n",
      "Iter 16704, Minibatch Loss= 22959.333984, Training Accuracy= 0.67188\n",
      "Iter 16768, Minibatch Loss= 30985.183594, Training Accuracy= 0.64062\n",
      "Iter 16832, Minibatch Loss= 27638.259766, Training Accuracy= 0.54688\n",
      "Iter 16896, Minibatch Loss= 30721.216797, Training Accuracy= 0.65625\n",
      "Iter 16960, Minibatch Loss= 23992.367188, Training Accuracy= 0.62500\n",
      "Iter 17024, Minibatch Loss= 12917.365234, Training Accuracy= 0.75000\n",
      "Iter 17088, Minibatch Loss= 23678.136719, Training Accuracy= 0.67188\n",
      "Iter 17152, Minibatch Loss= 26495.087891, Training Accuracy= 0.62500\n",
      "Iter 17216, Minibatch Loss= 28476.746094, Training Accuracy= 0.64062\n",
      "Iter 17280, Minibatch Loss= 25856.523438, Training Accuracy= 0.57812\n",
      "Iter 17344, Minibatch Loss= 20524.796875, Training Accuracy= 0.71875\n",
      "Iter 17408, Minibatch Loss= 12236.148438, Training Accuracy= 0.70312\n",
      "Iter 17472, Minibatch Loss= 30834.986328, Training Accuracy= 0.64062\n",
      "Iter 17536, Minibatch Loss= 24397.183594, Training Accuracy= 0.62500\n",
      "Iter 17600, Minibatch Loss= 16310.170898, Training Accuracy= 0.75000\n",
      "Iter 17664, Minibatch Loss= 24927.296875, Training Accuracy= 0.64062\n",
      "Iter 17728, Minibatch Loss= 24290.089844, Training Accuracy= 0.65625\n",
      "Iter 17792, Minibatch Loss= 17733.998047, Training Accuracy= 0.79688\n",
      "Iter 17856, Minibatch Loss= 25070.058594, Training Accuracy= 0.62500\n",
      "Iter 17920, Minibatch Loss= 29846.609375, Training Accuracy= 0.56250\n",
      "Iter 17984, Minibatch Loss= 24106.058594, Training Accuracy= 0.71875\n",
      "Iter 18048, Minibatch Loss= 27586.132812, Training Accuracy= 0.60938\n",
      "Iter 18112, Minibatch Loss= 31516.738281, Training Accuracy= 0.64062\n",
      "Iter 18176, Minibatch Loss= 18173.109375, Training Accuracy= 0.65625\n",
      "Iter 18240, Minibatch Loss= 21745.660156, Training Accuracy= 0.65625\n",
      "Iter 18304, Minibatch Loss= 27909.269531, Training Accuracy= 0.65625\n",
      "Iter 18368, Minibatch Loss= 21468.365234, Training Accuracy= 0.62500\n",
      "Iter 18432, Minibatch Loss= 23327.658203, Training Accuracy= 0.71875\n",
      "Iter 18496, Minibatch Loss= 13026.876953, Training Accuracy= 0.78125\n",
      "Iter 18560, Minibatch Loss= 15302.537109, Training Accuracy= 0.78125\n",
      "Iter 18624, Minibatch Loss= 25870.339844, Training Accuracy= 0.70312\n",
      "Iter 18688, Minibatch Loss= 22704.957031, Training Accuracy= 0.73438\n",
      "Iter 18752, Minibatch Loss= 20351.183594, Training Accuracy= 0.70312\n",
      "Iter 18816, Minibatch Loss= 23652.892578, Training Accuracy= 0.65625\n",
      "Iter 18880, Minibatch Loss= 17104.033203, Training Accuracy= 0.78125\n",
      "Iter 18944, Minibatch Loss= 18707.929688, Training Accuracy= 0.65625\n",
      "Iter 19008, Minibatch Loss= 15524.654297, Training Accuracy= 0.71875\n",
      "Iter 19072, Minibatch Loss= 22765.384766, Training Accuracy= 0.64062\n",
      "Iter 19136, Minibatch Loss= 17695.023438, Training Accuracy= 0.67188\n",
      "Iter 19200, Minibatch Loss= 28378.230469, Training Accuracy= 0.62500\n",
      "Iter 19264, Minibatch Loss= 22224.904297, Training Accuracy= 0.67188\n",
      "Iter 19328, Minibatch Loss= 20904.167969, Training Accuracy= 0.62500\n",
      "Iter 19392, Minibatch Loss= 22375.640625, Training Accuracy= 0.68750\n",
      "Iter 19456, Minibatch Loss= 27221.441406, Training Accuracy= 0.57812\n",
      "Iter 19520, Minibatch Loss= 25556.919922, Training Accuracy= 0.57812\n",
      "Iter 19584, Minibatch Loss= 24146.800781, Training Accuracy= 0.62500\n",
      "Iter 19648, Minibatch Loss= 20162.167969, Training Accuracy= 0.78125\n",
      "Iter 19712, Minibatch Loss= 27132.265625, Training Accuracy= 0.57812\n",
      "Iter 19776, Minibatch Loss= 23211.457031, Training Accuracy= 0.64062\n",
      "Iter 19840, Minibatch Loss= 17207.371094, Training Accuracy= 0.70312\n",
      "Iter 19904, Minibatch Loss= 21597.818359, Training Accuracy= 0.64062\n",
      "Iter 19968, Minibatch Loss= 19799.419922, Training Accuracy= 0.64062\n",
      "Iter 20032, Minibatch Loss= 19623.326172, Training Accuracy= 0.73438\n",
      "Iter 20096, Minibatch Loss= 19018.496094, Training Accuracy= 0.64062\n",
      "Iter 20160, Minibatch Loss= 24493.519531, Training Accuracy= 0.70312\n",
      "Iter 20224, Minibatch Loss= 27087.439453, Training Accuracy= 0.57812\n",
      "Iter 20288, Minibatch Loss= 24436.048828, Training Accuracy= 0.64062\n",
      "Iter 20352, Minibatch Loss= 30075.580078, Training Accuracy= 0.62500\n",
      "Iter 20416, Minibatch Loss= 18100.093750, Training Accuracy= 0.67188\n",
      "Iter 20480, Minibatch Loss= 27881.945312, Training Accuracy= 0.62500\n",
      "Iter 20544, Minibatch Loss= 23281.750000, Training Accuracy= 0.64062\n",
      "Iter 20608, Minibatch Loss= 27845.810547, Training Accuracy= 0.56250\n",
      "Iter 20672, Minibatch Loss= 24650.476562, Training Accuracy= 0.57812\n",
      "Iter 20736, Minibatch Loss= 28034.589844, Training Accuracy= 0.64062\n",
      "Iter 20800, Minibatch Loss= 21436.996094, Training Accuracy= 0.64062\n",
      "Iter 20864, Minibatch Loss= 19869.691406, Training Accuracy= 0.73438\n",
      "Iter 20928, Minibatch Loss= 24450.876953, Training Accuracy= 0.60938\n",
      "Iter 20992, Minibatch Loss= 15441.009766, Training Accuracy= 0.70312\n",
      "Iter 21056, Minibatch Loss= 15909.657227, Training Accuracy= 0.73438\n",
      "Iter 21120, Minibatch Loss= 27171.054688, Training Accuracy= 0.64062\n",
      "Iter 21184, Minibatch Loss= 26695.574219, Training Accuracy= 0.62500\n",
      "Iter 21248, Minibatch Loss= 24201.457031, Training Accuracy= 0.68750\n",
      "Iter 21312, Minibatch Loss= 30589.898438, Training Accuracy= 0.60938\n",
      "Iter 21376, Minibatch Loss= 24690.486328, Training Accuracy= 0.67188\n",
      "Iter 21440, Minibatch Loss= 37813.355469, Training Accuracy= 0.60938\n",
      "Iter 21504, Minibatch Loss= 15609.152344, Training Accuracy= 0.68750\n",
      "Iter 21568, Minibatch Loss= 25505.501953, Training Accuracy= 0.68750\n",
      "Iter 21632, Minibatch Loss= 19464.949219, Training Accuracy= 0.75000\n",
      "Iter 21696, Minibatch Loss= 25263.542969, Training Accuracy= 0.59375\n",
      "Iter 21760, Minibatch Loss= 25615.578125, Training Accuracy= 0.62500\n",
      "Iter 21824, Minibatch Loss= 16791.367188, Training Accuracy= 0.75000\n",
      "Iter 21888, Minibatch Loss= 19026.921875, Training Accuracy= 0.67188\n",
      "Iter 21952, Minibatch Loss= 22707.675781, Training Accuracy= 0.70312\n",
      "Iter 22016, Minibatch Loss= 18397.771484, Training Accuracy= 0.73438\n",
      "Iter 22080, Minibatch Loss= 22076.138672, Training Accuracy= 0.64062\n",
      "Iter 22144, Minibatch Loss= 21582.121094, Training Accuracy= 0.68750\n",
      "Iter 22208, Minibatch Loss= 27741.570312, Training Accuracy= 0.60938\n",
      "Iter 22272, Minibatch Loss= 29778.345703, Training Accuracy= 0.57812\n",
      "Iter 22336, Minibatch Loss= 14368.938477, Training Accuracy= 0.71875\n",
      "Iter 22400, Minibatch Loss= 15723.535156, Training Accuracy= 0.65625\n",
      "Iter 22464, Minibatch Loss= 20063.359375, Training Accuracy= 0.68750\n",
      "Iter 22528, Minibatch Loss= 10885.002930, Training Accuracy= 0.70312\n",
      "Iter 22592, Minibatch Loss= 27146.302734, Training Accuracy= 0.67188\n",
      "Iter 22656, Minibatch Loss= 13055.359375, Training Accuracy= 0.71875\n",
      "Iter 22720, Minibatch Loss= 20872.023438, Training Accuracy= 0.67188\n",
      "Iter 22784, Minibatch Loss= 18884.105469, Training Accuracy= 0.67188\n",
      "Iter 22848, Minibatch Loss= 14525.613281, Training Accuracy= 0.70312\n",
      "Iter 22912, Minibatch Loss= 20302.146484, Training Accuracy= 0.70312\n",
      "Iter 22976, Minibatch Loss= 18199.533203, Training Accuracy= 0.70312\n",
      "Iter 23040, Minibatch Loss= 9846.582031, Training Accuracy= 0.79688\n",
      "Iter 23104, Minibatch Loss= 15703.863281, Training Accuracy= 0.68750\n",
      "Iter 23168, Minibatch Loss= 14422.142578, Training Accuracy= 0.76562\n",
      "Iter 23232, Minibatch Loss= 24272.812500, Training Accuracy= 0.64062\n",
      "Iter 23296, Minibatch Loss= 23796.167969, Training Accuracy= 0.59375\n",
      "Iter 23360, Minibatch Loss= 17573.080078, Training Accuracy= 0.73438\n",
      "Iter 23424, Minibatch Loss= 13812.044922, Training Accuracy= 0.81250\n",
      "Iter 23488, Minibatch Loss= 14624.900391, Training Accuracy= 0.67188\n",
      "Iter 23552, Minibatch Loss= 17750.570312, Training Accuracy= 0.65625\n",
      "Iter 23616, Minibatch Loss= 15232.398438, Training Accuracy= 0.73438\n",
      "Iter 23680, Minibatch Loss= 16567.703125, Training Accuracy= 0.68750\n",
      "Iter 23744, Minibatch Loss= 26877.359375, Training Accuracy= 0.56250\n",
      "Iter 23808, Minibatch Loss= 19853.060547, Training Accuracy= 0.68750\n",
      "Iter 23872, Minibatch Loss= 25200.349609, Training Accuracy= 0.67188\n",
      "Iter 23936, Minibatch Loss= 27974.152344, Training Accuracy= 0.67188\n",
      "Iter 24000, Minibatch Loss= 24978.205078, Training Accuracy= 0.68750\n",
      "Iter 24064, Minibatch Loss= 22492.632812, Training Accuracy= 0.70312\n",
      "Iter 24128, Minibatch Loss= 13383.269531, Training Accuracy= 0.71875\n",
      "Iter 24192, Minibatch Loss= 19409.070312, Training Accuracy= 0.71875\n",
      "Iter 24256, Minibatch Loss= 20504.257812, Training Accuracy= 0.67188\n",
      "Iter 24320, Minibatch Loss= 17307.289062, Training Accuracy= 0.70312\n",
      "Iter 24384, Minibatch Loss= 19011.564453, Training Accuracy= 0.62500\n",
      "Iter 24448, Minibatch Loss= 23662.351562, Training Accuracy= 0.67188\n",
      "Iter 24512, Minibatch Loss= 19200.304688, Training Accuracy= 0.68750\n",
      "Iter 24576, Minibatch Loss= 18979.667969, Training Accuracy= 0.68750\n",
      "Iter 24640, Minibatch Loss= 13636.162109, Training Accuracy= 0.70312\n",
      "Iter 24704, Minibatch Loss= 22206.625000, Training Accuracy= 0.68750\n",
      "Iter 24768, Minibatch Loss= 22890.300781, Training Accuracy= 0.60938\n",
      "Iter 24832, Minibatch Loss= 25122.796875, Training Accuracy= 0.60938\n",
      "Iter 24896, Minibatch Loss= 29033.646484, Training Accuracy= 0.68750\n",
      "Iter 24960, Minibatch Loss= 20336.964844, Training Accuracy= 0.70312\n",
      "Iter 25024, Minibatch Loss= 20332.613281, Training Accuracy= 0.62500\n",
      "Iter 25088, Minibatch Loss= 24770.929688, Training Accuracy= 0.59375\n",
      "Iter 25152, Minibatch Loss= 21853.269531, Training Accuracy= 0.67188\n",
      "Iter 25216, Minibatch Loss= 24121.488281, Training Accuracy= 0.57812\n",
      "Iter 25280, Minibatch Loss= 29012.023438, Training Accuracy= 0.56250\n",
      "Iter 25344, Minibatch Loss= 18029.644531, Training Accuracy= 0.65625\n",
      "Iter 25408, Minibatch Loss= 20949.996094, Training Accuracy= 0.60938\n",
      "Iter 25472, Minibatch Loss= 16932.730469, Training Accuracy= 0.60938\n",
      "Iter 25536, Minibatch Loss= 19928.722656, Training Accuracy= 0.68750\n",
      "Iter 25600, Minibatch Loss= 13963.425781, Training Accuracy= 0.70312\n",
      "Iter 25664, Minibatch Loss= 10477.133789, Training Accuracy= 0.75000\n",
      "Iter 25728, Minibatch Loss= 19491.777344, Training Accuracy= 0.68750\n",
      "Iter 25792, Minibatch Loss= 16552.480469, Training Accuracy= 0.71875\n",
      "Iter 25856, Minibatch Loss= 13618.089844, Training Accuracy= 0.71875\n",
      "Iter 25920, Minibatch Loss= 21948.566406, Training Accuracy= 0.68750\n",
      "Iter 25984, Minibatch Loss= 20283.654297, Training Accuracy= 0.64062\n",
      "Iter 26048, Minibatch Loss= 21323.492188, Training Accuracy= 0.65625\n",
      "Iter 26112, Minibatch Loss= 17529.832031, Training Accuracy= 0.67188\n",
      "Iter 26176, Minibatch Loss= 17210.169922, Training Accuracy= 0.67188\n",
      "Iter 26240, Minibatch Loss= 24373.779297, Training Accuracy= 0.59375\n",
      "Iter 26304, Minibatch Loss= 26868.136719, Training Accuracy= 0.56250\n",
      "Iter 26368, Minibatch Loss= 14721.695312, Training Accuracy= 0.71875\n",
      "Iter 26432, Minibatch Loss= 28384.812500, Training Accuracy= 0.51562\n",
      "Iter 26496, Minibatch Loss= 35043.179688, Training Accuracy= 0.51562\n",
      "Iter 26560, Minibatch Loss= 38328.664062, Training Accuracy= 0.43750\n",
      "Iter 26624, Minibatch Loss= 18551.019531, Training Accuracy= 0.67188\n",
      "Iter 26688, Minibatch Loss= 18539.351562, Training Accuracy= 0.64062\n",
      "Iter 26752, Minibatch Loss= 22048.906250, Training Accuracy= 0.60938\n",
      "Iter 26816, Minibatch Loss= 31047.515625, Training Accuracy= 0.53125\n",
      "Iter 26880, Minibatch Loss= 27842.792969, Training Accuracy= 0.54688\n",
      "Iter 26944, Minibatch Loss= 15617.495117, Training Accuracy= 0.71875\n",
      "Iter 27008, Minibatch Loss= 16817.458984, Training Accuracy= 0.68750\n",
      "Iter 27072, Minibatch Loss= 20384.414062, Training Accuracy= 0.64062\n",
      "Iter 27136, Minibatch Loss= 15281.892578, Training Accuracy= 0.67188\n",
      "Iter 27200, Minibatch Loss= 22551.292969, Training Accuracy= 0.64062\n",
      "Iter 27264, Minibatch Loss= 19444.250000, Training Accuracy= 0.64062\n",
      "Iter 27328, Minibatch Loss= 9109.366211, Training Accuracy= 0.79688\n",
      "Iter 27392, Minibatch Loss= 29128.363281, Training Accuracy= 0.54688\n",
      "Iter 27456, Minibatch Loss= 21358.373047, Training Accuracy= 0.62500\n",
      "Iter 27520, Minibatch Loss= 25384.390625, Training Accuracy= 0.57812\n",
      "Iter 27584, Minibatch Loss= 19358.376953, Training Accuracy= 0.73438\n",
      "Iter 27648, Minibatch Loss= 23761.273438, Training Accuracy= 0.57812\n",
      "Iter 27712, Minibatch Loss= 19954.382812, Training Accuracy= 0.67188\n",
      "Iter 27776, Minibatch Loss= 20559.429688, Training Accuracy= 0.62500\n",
      "Iter 27840, Minibatch Loss= 18679.042969, Training Accuracy= 0.60938\n",
      "Iter 27904, Minibatch Loss= 16722.925781, Training Accuracy= 0.59375\n",
      "Iter 27968, Minibatch Loss= 13482.019531, Training Accuracy= 0.73438\n",
      "Iter 28032, Minibatch Loss= 10078.246094, Training Accuracy= 0.71875\n",
      "Iter 28096, Minibatch Loss= 17329.117188, Training Accuracy= 0.65625\n",
      "Iter 28160, Minibatch Loss= 15663.057617, Training Accuracy= 0.64062\n",
      "Iter 28224, Minibatch Loss= 15906.533203, Training Accuracy= 0.67188\n",
      "Iter 28288, Minibatch Loss= 14927.170898, Training Accuracy= 0.73438\n",
      "Iter 28352, Minibatch Loss= 20562.789062, Training Accuracy= 0.53125\n",
      "Iter 28416, Minibatch Loss= 15318.907227, Training Accuracy= 0.65625\n",
      "Iter 28480, Minibatch Loss= 22952.179688, Training Accuracy= 0.59375\n",
      "Iter 28544, Minibatch Loss= 23480.042969, Training Accuracy= 0.64062\n",
      "Iter 28608, Minibatch Loss= 17101.515625, Training Accuracy= 0.64062\n",
      "Iter 28672, Minibatch Loss= 21962.394531, Training Accuracy= 0.62500\n",
      "Iter 28736, Minibatch Loss= 11121.371094, Training Accuracy= 0.70312\n",
      "Iter 28800, Minibatch Loss= 21422.478516, Training Accuracy= 0.64062\n",
      "Iter 28864, Minibatch Loss= 11810.626953, Training Accuracy= 0.68750\n",
      "Iter 28928, Minibatch Loss= 12536.783203, Training Accuracy= 0.71875\n",
      "Iter 28992, Minibatch Loss= 15950.674805, Training Accuracy= 0.60938\n",
      "Iter 29056, Minibatch Loss= 14348.042969, Training Accuracy= 0.70312\n",
      "Iter 29120, Minibatch Loss= 16385.580078, Training Accuracy= 0.62500\n",
      "Iter 29184, Minibatch Loss= 11457.580078, Training Accuracy= 0.75000\n",
      "Iter 29248, Minibatch Loss= 16126.123047, Training Accuracy= 0.59375\n",
      "Iter 29312, Minibatch Loss= 13774.988281, Training Accuracy= 0.65625\n",
      "Iter 29376, Minibatch Loss= 17121.769531, Training Accuracy= 0.70312\n",
      "Iter 29440, Minibatch Loss= 24275.644531, Training Accuracy= 0.59375\n",
      "Iter 29504, Minibatch Loss= 16481.955078, Training Accuracy= 0.70312\n",
      "Iter 29568, Minibatch Loss= 16358.685547, Training Accuracy= 0.73438\n",
      "Iter 29632, Minibatch Loss= 14822.649414, Training Accuracy= 0.76562\n",
      "Iter 29696, Minibatch Loss= 8938.389648, Training Accuracy= 0.82812\n",
      "Iter 29760, Minibatch Loss= 22769.222656, Training Accuracy= 0.64062\n",
      "Iter 29824, Minibatch Loss= 6729.103516, Training Accuracy= 0.82812\n",
      "Iter 29888, Minibatch Loss= 16601.101562, Training Accuracy= 0.60938\n",
      "Iter 29952, Minibatch Loss= 15267.039062, Training Accuracy= 0.65625\n",
      "Iter 30016, Minibatch Loss= 23611.730469, Training Accuracy= 0.70312\n",
      "Iter 30080, Minibatch Loss= 23833.109375, Training Accuracy= 0.56250\n",
      "Iter 30144, Minibatch Loss= 17657.150391, Training Accuracy= 0.62500\n",
      "Iter 30208, Minibatch Loss= 16280.148438, Training Accuracy= 0.68750\n",
      "Iter 30272, Minibatch Loss= 21442.744141, Training Accuracy= 0.71875\n",
      "Iter 30336, Minibatch Loss= 23139.386719, Training Accuracy= 0.68750\n",
      "Iter 30400, Minibatch Loss= 13372.140625, Training Accuracy= 0.68750\n",
      "Iter 30464, Minibatch Loss= 18532.789062, Training Accuracy= 0.78125\n",
      "Iter 30528, Minibatch Loss= 11255.830078, Training Accuracy= 0.73438\n",
      "Iter 30592, Minibatch Loss= 12599.238281, Training Accuracy= 0.67188\n",
      "Iter 30656, Minibatch Loss= 15636.280273, Training Accuracy= 0.68750\n",
      "Iter 30720, Minibatch Loss= 15826.741211, Training Accuracy= 0.68750\n",
      "Iter 30784, Minibatch Loss= 23071.736328, Training Accuracy= 0.59375\n",
      "Iter 30848, Minibatch Loss= 12870.770508, Training Accuracy= 0.71875\n",
      "Iter 30912, Minibatch Loss= 13498.976562, Training Accuracy= 0.68750\n",
      "Iter 30976, Minibatch Loss= 17162.933594, Training Accuracy= 0.60938\n",
      "Iter 31040, Minibatch Loss= 16730.203125, Training Accuracy= 0.73438\n",
      "Iter 31104, Minibatch Loss= 16390.480469, Training Accuracy= 0.60938\n",
      "Iter 31168, Minibatch Loss= 10072.728516, Training Accuracy= 0.78125\n",
      "Iter 31232, Minibatch Loss= 17778.007812, Training Accuracy= 0.62500\n",
      "Iter 31296, Minibatch Loss= 16598.683594, Training Accuracy= 0.68750\n",
      "Iter 31360, Minibatch Loss= 19604.968750, Training Accuracy= 0.65625\n",
      "Iter 31424, Minibatch Loss= 20603.281250, Training Accuracy= 0.60938\n",
      "Iter 31488, Minibatch Loss= 13468.757812, Training Accuracy= 0.67188\n",
      "Iter 31552, Minibatch Loss= 18558.925781, Training Accuracy= 0.65625\n",
      "Iter 31616, Minibatch Loss= 22349.195312, Training Accuracy= 0.68750\n",
      "Iter 31680, Minibatch Loss= 18299.468750, Training Accuracy= 0.53125\n",
      "Iter 31744, Minibatch Loss= 14541.494141, Training Accuracy= 0.68750\n",
      "Iter 31808, Minibatch Loss= 20513.121094, Training Accuracy= 0.57812\n",
      "Iter 31872, Minibatch Loss= 19403.925781, Training Accuracy= 0.59375\n",
      "Iter 31936, Minibatch Loss= 10635.675781, Training Accuracy= 0.78125\n",
      "Iter 32000, Minibatch Loss= 12462.138672, Training Accuracy= 0.73438\n",
      "Iter 32064, Minibatch Loss= 10286.713867, Training Accuracy= 0.76562\n",
      "Iter 32128, Minibatch Loss= 14969.679688, Training Accuracy= 0.68750\n",
      "Iter 32192, Minibatch Loss= 9810.893555, Training Accuracy= 0.68750\n",
      "Iter 32256, Minibatch Loss= 16214.814453, Training Accuracy= 0.75000\n",
      "Iter 32320, Minibatch Loss= 14132.847656, Training Accuracy= 0.68750\n",
      "Iter 32384, Minibatch Loss= 16029.234375, Training Accuracy= 0.70312\n",
      "Iter 32448, Minibatch Loss= 12946.640625, Training Accuracy= 0.68750\n",
      "Iter 32512, Minibatch Loss= 21888.691406, Training Accuracy= 0.59375\n",
      "Iter 32576, Minibatch Loss= 20272.386719, Training Accuracy= 0.60938\n",
      "Iter 32640, Minibatch Loss= 13229.567383, Training Accuracy= 0.75000\n",
      "Iter 32704, Minibatch Loss= 11893.712891, Training Accuracy= 0.78125\n",
      "Iter 32768, Minibatch Loss= 18298.921875, Training Accuracy= 0.73438\n",
      "Iter 32832, Minibatch Loss= 17960.238281, Training Accuracy= 0.67188\n",
      "Iter 32896, Minibatch Loss= 14347.775391, Training Accuracy= 0.70312\n",
      "Iter 32960, Minibatch Loss= 7762.235352, Training Accuracy= 0.73438\n",
      "Iter 33024, Minibatch Loss= 18349.156250, Training Accuracy= 0.64062\n",
      "Iter 33088, Minibatch Loss= 17034.361328, Training Accuracy= 0.60938\n",
      "Iter 33152, Minibatch Loss= 14913.991211, Training Accuracy= 0.67188\n",
      "Iter 33216, Minibatch Loss= 14160.241211, Training Accuracy= 0.64062\n",
      "Iter 33280, Minibatch Loss= 19017.144531, Training Accuracy= 0.54688\n",
      "Iter 33344, Minibatch Loss= 14606.874023, Training Accuracy= 0.64062\n",
      "Iter 33408, Minibatch Loss= 10730.731445, Training Accuracy= 0.73438\n",
      "Iter 33472, Minibatch Loss= 12351.931641, Training Accuracy= 0.71875\n",
      "Iter 33536, Minibatch Loss= 8216.080078, Training Accuracy= 0.82812\n",
      "Iter 33600, Minibatch Loss= 13948.155273, Training Accuracy= 0.70312\n",
      "Iter 33664, Minibatch Loss= 8630.252930, Training Accuracy= 0.76562\n",
      "Iter 33728, Minibatch Loss= 16484.158203, Training Accuracy= 0.68750\n",
      "Iter 33792, Minibatch Loss= 17686.605469, Training Accuracy= 0.62500\n",
      "Iter 33856, Minibatch Loss= 6531.023926, Training Accuracy= 0.78125\n",
      "Iter 33920, Minibatch Loss= 14763.780273, Training Accuracy= 0.67188\n",
      "Iter 33984, Minibatch Loss= 11257.895508, Training Accuracy= 0.78125\n",
      "Iter 34048, Minibatch Loss= 13328.412109, Training Accuracy= 0.70312\n",
      "Iter 34112, Minibatch Loss= 13263.641602, Training Accuracy= 0.65625\n",
      "Iter 34176, Minibatch Loss= 5340.406250, Training Accuracy= 0.76562\n",
      "Iter 34240, Minibatch Loss= 17269.519531, Training Accuracy= 0.65625\n",
      "Iter 34304, Minibatch Loss= 21193.140625, Training Accuracy= 0.60938\n",
      "Iter 34368, Minibatch Loss= 9702.151367, Training Accuracy= 0.75000\n",
      "Iter 34432, Minibatch Loss= 15386.212891, Training Accuracy= 0.65625\n",
      "Iter 34496, Minibatch Loss= 13685.270508, Training Accuracy= 0.76562\n",
      "Iter 34560, Minibatch Loss= 11986.161133, Training Accuracy= 0.70312\n",
      "Iter 34624, Minibatch Loss= 12846.723633, Training Accuracy= 0.73438\n",
      "Iter 34688, Minibatch Loss= 19193.511719, Training Accuracy= 0.64062\n",
      "Iter 34752, Minibatch Loss= 16558.820312, Training Accuracy= 0.64062\n",
      "Iter 34816, Minibatch Loss= 14612.748047, Training Accuracy= 0.60938\n",
      "Iter 34880, Minibatch Loss= 11451.162109, Training Accuracy= 0.75000\n",
      "Iter 34944, Minibatch Loss= 12064.896484, Training Accuracy= 0.71875\n",
      "Iter 35008, Minibatch Loss= 8271.572266, Training Accuracy= 0.79688\n",
      "Iter 35072, Minibatch Loss= 16835.240234, Training Accuracy= 0.79688\n",
      "Iter 35136, Minibatch Loss= 20524.650391, Training Accuracy= 0.64062\n",
      "Iter 35200, Minibatch Loss= 16017.624023, Training Accuracy= 0.65625\n",
      "Iter 35264, Minibatch Loss= 11271.249023, Training Accuracy= 0.65625\n",
      "Iter 35328, Minibatch Loss= 7387.357422, Training Accuracy= 0.79688\n",
      "Iter 35392, Minibatch Loss= 14261.152344, Training Accuracy= 0.57812\n",
      "Iter 35456, Minibatch Loss= 11969.664062, Training Accuracy= 0.67188\n",
      "Iter 35520, Minibatch Loss= 15970.294922, Training Accuracy= 0.68750\n",
      "Iter 35584, Minibatch Loss= 11781.300781, Training Accuracy= 0.67188\n",
      "Iter 35648, Minibatch Loss= 12266.043945, Training Accuracy= 0.70312\n",
      "Iter 35712, Minibatch Loss= 13655.414062, Training Accuracy= 0.70312\n",
      "Iter 35776, Minibatch Loss= 10085.721680, Training Accuracy= 0.75000\n",
      "Iter 35840, Minibatch Loss= 18136.019531, Training Accuracy= 0.67188\n",
      "Iter 35904, Minibatch Loss= 10444.767578, Training Accuracy= 0.62500\n",
      "Iter 35968, Minibatch Loss= 10879.981445, Training Accuracy= 0.73438\n",
      "Iter 36032, Minibatch Loss= 13554.477539, Training Accuracy= 0.64062\n",
      "Iter 36096, Minibatch Loss= 11208.900391, Training Accuracy= 0.71875\n",
      "Iter 36160, Minibatch Loss= 13293.761719, Training Accuracy= 0.67188\n",
      "Iter 36224, Minibatch Loss= 18930.375000, Training Accuracy= 0.62500\n",
      "Iter 36288, Minibatch Loss= 12663.732422, Training Accuracy= 0.76562\n",
      "Iter 36352, Minibatch Loss= 20435.183594, Training Accuracy= 0.65625\n",
      "Iter 36416, Minibatch Loss= 18366.515625, Training Accuracy= 0.64062\n",
      "Iter 36480, Minibatch Loss= 16706.873047, Training Accuracy= 0.65625\n",
      "Iter 36544, Minibatch Loss= 14513.145508, Training Accuracy= 0.70312\n",
      "Iter 36608, Minibatch Loss= 14117.037109, Training Accuracy= 0.67188\n",
      "Iter 36672, Minibatch Loss= 11256.877930, Training Accuracy= 0.70312\n",
      "Iter 36736, Minibatch Loss= 15752.113281, Training Accuracy= 0.59375\n",
      "Iter 36800, Minibatch Loss= 6837.893066, Training Accuracy= 0.75000\n",
      "Iter 36864, Minibatch Loss= 10082.775391, Training Accuracy= 0.76562\n",
      "Iter 36928, Minibatch Loss= 14178.711914, Training Accuracy= 0.64062\n",
      "Iter 36992, Minibatch Loss= 18383.644531, Training Accuracy= 0.59375\n",
      "Iter 37056, Minibatch Loss= 12819.444336, Training Accuracy= 0.65625\n",
      "Iter 37120, Minibatch Loss= 22079.000000, Training Accuracy= 0.60938\n",
      "Iter 37184, Minibatch Loss= 18351.957031, Training Accuracy= 0.67188\n",
      "Iter 37248, Minibatch Loss= 13088.935547, Training Accuracy= 0.71875\n",
      "Iter 37312, Minibatch Loss= 9914.613281, Training Accuracy= 0.71875\n",
      "Iter 37376, Minibatch Loss= 20565.144531, Training Accuracy= 0.59375\n",
      "Iter 37440, Minibatch Loss= 10774.758789, Training Accuracy= 0.70312\n",
      "Iter 37504, Minibatch Loss= 11247.990234, Training Accuracy= 0.68750\n",
      "Iter 37568, Minibatch Loss= 7723.613770, Training Accuracy= 0.76562\n",
      "Iter 37632, Minibatch Loss= 11817.626953, Training Accuracy= 0.75000\n",
      "Iter 37696, Minibatch Loss= 12740.384766, Training Accuracy= 0.70312\n",
      "Iter 37760, Minibatch Loss= 6800.408203, Training Accuracy= 0.75000\n",
      "Iter 37824, Minibatch Loss= 12297.072266, Training Accuracy= 0.68750\n",
      "Iter 37888, Minibatch Loss= 17009.980469, Training Accuracy= 0.67188\n",
      "Iter 37952, Minibatch Loss= 16250.437500, Training Accuracy= 0.59375\n",
      "Iter 38016, Minibatch Loss= 12934.764648, Training Accuracy= 0.73438\n",
      "Iter 38080, Minibatch Loss= 7316.053223, Training Accuracy= 0.78125\n",
      "Iter 38144, Minibatch Loss= 14045.277344, Training Accuracy= 0.71875\n",
      "Iter 38208, Minibatch Loss= 20024.718750, Training Accuracy= 0.62500\n",
      "Iter 38272, Minibatch Loss= 17769.242188, Training Accuracy= 0.65625\n",
      "Iter 38336, Minibatch Loss= 11499.369141, Training Accuracy= 0.64062\n",
      "Iter 38400, Minibatch Loss= 14006.646484, Training Accuracy= 0.73438\n",
      "Iter 38464, Minibatch Loss= 12348.752930, Training Accuracy= 0.67188\n",
      "Iter 38528, Minibatch Loss= 13194.822266, Training Accuracy= 0.67188\n",
      "Iter 38592, Minibatch Loss= 14617.398438, Training Accuracy= 0.67188\n",
      "Iter 38656, Minibatch Loss= 16033.934570, Training Accuracy= 0.65625\n",
      "Iter 38720, Minibatch Loss= 11921.748047, Training Accuracy= 0.75000\n",
      "Iter 38784, Minibatch Loss= 12359.455078, Training Accuracy= 0.68750\n",
      "Iter 38848, Minibatch Loss= 25257.011719, Training Accuracy= 0.65625\n",
      "Iter 38912, Minibatch Loss= 18718.281250, Training Accuracy= 0.67188\n",
      "Iter 38976, Minibatch Loss= 14926.048828, Training Accuracy= 0.60938\n",
      "Iter 39040, Minibatch Loss= 13757.379883, Training Accuracy= 0.64062\n",
      "Iter 39104, Minibatch Loss= 20650.769531, Training Accuracy= 0.68750\n",
      "Iter 39168, Minibatch Loss= 9041.058594, Training Accuracy= 0.70312\n",
      "Iter 39232, Minibatch Loss= 5384.913574, Training Accuracy= 0.73438\n",
      "Iter 39296, Minibatch Loss= 20871.304688, Training Accuracy= 0.57812\n",
      "Iter 39360, Minibatch Loss= 11753.568359, Training Accuracy= 0.73438\n",
      "Iter 39424, Minibatch Loss= 8225.821289, Training Accuracy= 0.76562\n",
      "Iter 39488, Minibatch Loss= 11230.180664, Training Accuracy= 0.76562\n",
      "Iter 39552, Minibatch Loss= 12879.448242, Training Accuracy= 0.64062\n",
      "Iter 39616, Minibatch Loss= 12064.505859, Training Accuracy= 0.68750\n",
      "Iter 39680, Minibatch Loss= 13713.503906, Training Accuracy= 0.70312\n",
      "Iter 39744, Minibatch Loss= 13006.184570, Training Accuracy= 0.65625\n",
      "Iter 39808, Minibatch Loss= 14787.846680, Training Accuracy= 0.64062\n",
      "Iter 39872, Minibatch Loss= 12440.119141, Training Accuracy= 0.68750\n",
      "Iter 39936, Minibatch Loss= 15623.361328, Training Accuracy= 0.60938\n",
      "Iter 40000, Minibatch Loss= 17920.908203, Training Accuracy= 0.60938\n",
      "Iter 40064, Minibatch Loss= 9904.982422, Training Accuracy= 0.68750\n",
      "Iter 40128, Minibatch Loss= 10538.879883, Training Accuracy= 0.67188\n",
      "Iter 40192, Minibatch Loss= 7418.370117, Training Accuracy= 0.76562\n",
      "Iter 40256, Minibatch Loss= 9848.597656, Training Accuracy= 0.68750\n",
      "Iter 40320, Minibatch Loss= 12748.119141, Training Accuracy= 0.68750\n",
      "Iter 40384, Minibatch Loss= 17544.738281, Training Accuracy= 0.60938\n",
      "Iter 40448, Minibatch Loss= 17594.822266, Training Accuracy= 0.64062\n",
      "Iter 40512, Minibatch Loss= 11307.055664, Training Accuracy= 0.65625\n",
      "Iter 40576, Minibatch Loss= 10394.507812, Training Accuracy= 0.64062\n",
      "Iter 40640, Minibatch Loss= 11301.094727, Training Accuracy= 0.65625\n",
      "Iter 40704, Minibatch Loss= 12304.199219, Training Accuracy= 0.62500\n",
      "Iter 40768, Minibatch Loss= 17417.417969, Training Accuracy= 0.62500\n",
      "Iter 40832, Minibatch Loss= 11540.452148, Training Accuracy= 0.75000\n",
      "Iter 40896, Minibatch Loss= 18463.488281, Training Accuracy= 0.60938\n",
      "Iter 40960, Minibatch Loss= 8283.875977, Training Accuracy= 0.70312\n",
      "Iter 41024, Minibatch Loss= 16457.402344, Training Accuracy= 0.56250\n",
      "Iter 41088, Minibatch Loss= 14188.134766, Training Accuracy= 0.60938\n",
      "Iter 41152, Minibatch Loss= 11536.148438, Training Accuracy= 0.70312\n",
      "Iter 41216, Minibatch Loss= 12438.935547, Training Accuracy= 0.68750\n",
      "Iter 41280, Minibatch Loss= 13607.211914, Training Accuracy= 0.68750\n",
      "Iter 41344, Minibatch Loss= 6696.664062, Training Accuracy= 0.71875\n",
      "Iter 41408, Minibatch Loss= 8922.798828, Training Accuracy= 0.79688\n",
      "Iter 41472, Minibatch Loss= 12209.162109, Training Accuracy= 0.67188\n",
      "Iter 41536, Minibatch Loss= 12589.391602, Training Accuracy= 0.75000\n",
      "Iter 41600, Minibatch Loss= 10124.738281, Training Accuracy= 0.68750\n",
      "Iter 41664, Minibatch Loss= 8309.695312, Training Accuracy= 0.68750\n",
      "Iter 41728, Minibatch Loss= 11371.419922, Training Accuracy= 0.60938\n",
      "Iter 41792, Minibatch Loss= 7854.169434, Training Accuracy= 0.70312\n",
      "Iter 41856, Minibatch Loss= 15636.291992, Training Accuracy= 0.68750\n",
      "Iter 41920, Minibatch Loss= 14039.738281, Training Accuracy= 0.62500\n",
      "Iter 41984, Minibatch Loss= 11158.417969, Training Accuracy= 0.75000\n",
      "Iter 42048, Minibatch Loss= 10261.111328, Training Accuracy= 0.59375\n",
      "Iter 42112, Minibatch Loss= 9706.860352, Training Accuracy= 0.81250\n",
      "Iter 42176, Minibatch Loss= 8048.043945, Training Accuracy= 0.70312\n",
      "Iter 42240, Minibatch Loss= 14367.867188, Training Accuracy= 0.60938\n",
      "Iter 42304, Minibatch Loss= 13593.437500, Training Accuracy= 0.62500\n",
      "Iter 42368, Minibatch Loss= 14593.913086, Training Accuracy= 0.54688\n",
      "Iter 42432, Minibatch Loss= 11094.051758, Training Accuracy= 0.67188\n",
      "Iter 42496, Minibatch Loss= 6113.635742, Training Accuracy= 0.75000\n",
      "Iter 42560, Minibatch Loss= 13097.916016, Training Accuracy= 0.67188\n",
      "Iter 42624, Minibatch Loss= 10651.527344, Training Accuracy= 0.68750\n",
      "Iter 42688, Minibatch Loss= 8747.073242, Training Accuracy= 0.68750\n",
      "Iter 42752, Minibatch Loss= 10683.183594, Training Accuracy= 0.71875\n",
      "Iter 42816, Minibatch Loss= 10960.062500, Training Accuracy= 0.67188\n",
      "Iter 42880, Minibatch Loss= 13833.219727, Training Accuracy= 0.67188\n",
      "Iter 42944, Minibatch Loss= 13386.136719, Training Accuracy= 0.64062\n",
      "Iter 43008, Minibatch Loss= 15075.183594, Training Accuracy= 0.65625\n",
      "Iter 43072, Minibatch Loss= 9127.753906, Training Accuracy= 0.75000\n",
      "Iter 43136, Minibatch Loss= 9770.488281, Training Accuracy= 0.75000\n",
      "Iter 43200, Minibatch Loss= 8004.604004, Training Accuracy= 0.75000\n",
      "Iter 43264, Minibatch Loss= 9333.630859, Training Accuracy= 0.68750\n",
      "Iter 43328, Minibatch Loss= 7715.654785, Training Accuracy= 0.75000\n",
      "Iter 43392, Minibatch Loss= 14664.872070, Training Accuracy= 0.64062\n",
      "Iter 43456, Minibatch Loss= 11295.854492, Training Accuracy= 0.76562\n",
      "Iter 43520, Minibatch Loss= 7779.964844, Training Accuracy= 0.68750\n",
      "Iter 43584, Minibatch Loss= 9350.246094, Training Accuracy= 0.70312\n",
      "Iter 43648, Minibatch Loss= 12014.131836, Training Accuracy= 0.71875\n",
      "Iter 43712, Minibatch Loss= 6321.448242, Training Accuracy= 0.76562\n",
      "Iter 43776, Minibatch Loss= 11841.912109, Training Accuracy= 0.62500\n",
      "Iter 43840, Minibatch Loss= 16926.347656, Training Accuracy= 0.64062\n",
      "Iter 43904, Minibatch Loss= 12336.866211, Training Accuracy= 0.67188\n",
      "Iter 43968, Minibatch Loss= 11100.787109, Training Accuracy= 0.62500\n",
      "Iter 44032, Minibatch Loss= 15409.510742, Training Accuracy= 0.71875\n",
      "Iter 44096, Minibatch Loss= 12044.367188, Training Accuracy= 0.68750\n",
      "Iter 44160, Minibatch Loss= 16936.152344, Training Accuracy= 0.67188\n",
      "Iter 44224, Minibatch Loss= 6352.267578, Training Accuracy= 0.73438\n",
      "Iter 44288, Minibatch Loss= 8983.226562, Training Accuracy= 0.67188\n",
      "Iter 44352, Minibatch Loss= 14749.186523, Training Accuracy= 0.60938\n",
      "Iter 44416, Minibatch Loss= 17239.765625, Training Accuracy= 0.62500\n",
      "Iter 44480, Minibatch Loss= 11977.764648, Training Accuracy= 0.75000\n",
      "Iter 44544, Minibatch Loss= 4430.087891, Training Accuracy= 0.85938\n",
      "Iter 44608, Minibatch Loss= 11583.876953, Training Accuracy= 0.64062\n",
      "Iter 44672, Minibatch Loss= 10405.283203, Training Accuracy= 0.67188\n",
      "Iter 44736, Minibatch Loss= 11639.867188, Training Accuracy= 0.68750\n",
      "Iter 44800, Minibatch Loss= 12444.958984, Training Accuracy= 0.70312\n",
      "Iter 44864, Minibatch Loss= 9098.275391, Training Accuracy= 0.76562\n",
      "Iter 44928, Minibatch Loss= 11488.189453, Training Accuracy= 0.67188\n",
      "Iter 44992, Minibatch Loss= 12680.980469, Training Accuracy= 0.62500\n",
      "Iter 45056, Minibatch Loss= 15451.467773, Training Accuracy= 0.70312\n",
      "Iter 45120, Minibatch Loss= 12187.257812, Training Accuracy= 0.65625\n",
      "Iter 45184, Minibatch Loss= 8507.693359, Training Accuracy= 0.65625\n",
      "Iter 45248, Minibatch Loss= 7435.783203, Training Accuracy= 0.75000\n",
      "Iter 45312, Minibatch Loss= 11885.780273, Training Accuracy= 0.62500\n",
      "Iter 45376, Minibatch Loss= 6989.500000, Training Accuracy= 0.73438\n",
      "Iter 45440, Minibatch Loss= 15424.328125, Training Accuracy= 0.65625\n",
      "Iter 45504, Minibatch Loss= 12383.124023, Training Accuracy= 0.64062\n",
      "Iter 45568, Minibatch Loss= 7708.548828, Training Accuracy= 0.71875\n",
      "Iter 45632, Minibatch Loss= 10627.023438, Training Accuracy= 0.67188\n",
      "Iter 45696, Minibatch Loss= 9965.321289, Training Accuracy= 0.60938\n",
      "Iter 45760, Minibatch Loss= 9692.023438, Training Accuracy= 0.73438\n",
      "Iter 45824, Minibatch Loss= 17261.214844, Training Accuracy= 0.62500\n",
      "Iter 45888, Minibatch Loss= 7510.054688, Training Accuracy= 0.79688\n",
      "Iter 45952, Minibatch Loss= 9652.833984, Training Accuracy= 0.67188\n",
      "Iter 46016, Minibatch Loss= 12592.413086, Training Accuracy= 0.64062\n",
      "Iter 46080, Minibatch Loss= 8182.694336, Training Accuracy= 0.67188\n",
      "Iter 46144, Minibatch Loss= 14744.678711, Training Accuracy= 0.67188\n",
      "Iter 46208, Minibatch Loss= 9783.587891, Training Accuracy= 0.73438\n",
      "Iter 46272, Minibatch Loss= 6631.342285, Training Accuracy= 0.71875\n",
      "Iter 46336, Minibatch Loss= 8819.701172, Training Accuracy= 0.68750\n",
      "Iter 46400, Minibatch Loss= 9234.550781, Training Accuracy= 0.70312\n",
      "Iter 46464, Minibatch Loss= 12263.090820, Training Accuracy= 0.68750\n",
      "Iter 46528, Minibatch Loss= 7005.567383, Training Accuracy= 0.81250\n",
      "Iter 46592, Minibatch Loss= 13001.407227, Training Accuracy= 0.65625\n",
      "Iter 46656, Minibatch Loss= 11651.178711, Training Accuracy= 0.62500\n",
      "Iter 46720, Minibatch Loss= 12343.062500, Training Accuracy= 0.70312\n",
      "Iter 46784, Minibatch Loss= 12848.385742, Training Accuracy= 0.67188\n",
      "Iter 46848, Minibatch Loss= 10996.128906, Training Accuracy= 0.65625\n",
      "Iter 46912, Minibatch Loss= 12169.507812, Training Accuracy= 0.71875\n",
      "Iter 46976, Minibatch Loss= 11868.564453, Training Accuracy= 0.67188\n",
      "Iter 47040, Minibatch Loss= 13100.830078, Training Accuracy= 0.62500\n",
      "Iter 47104, Minibatch Loss= 13566.427734, Training Accuracy= 0.57812\n",
      "Iter 47168, Minibatch Loss= 7993.226562, Training Accuracy= 0.73438\n",
      "Iter 47232, Minibatch Loss= 10863.761719, Training Accuracy= 0.64062\n",
      "Iter 47296, Minibatch Loss= 4553.341309, Training Accuracy= 0.84375\n",
      "Iter 47360, Minibatch Loss= 6465.958496, Training Accuracy= 0.70312\n",
      "Iter 47424, Minibatch Loss= 11827.806641, Training Accuracy= 0.68750\n",
      "Iter 47488, Minibatch Loss= 9046.088867, Training Accuracy= 0.70312\n",
      "Iter 47552, Minibatch Loss= 11573.772461, Training Accuracy= 0.68750\n",
      "Iter 47616, Minibatch Loss= 7507.611816, Training Accuracy= 0.67188\n",
      "Iter 47680, Minibatch Loss= 6457.639648, Training Accuracy= 0.81250\n",
      "Iter 47744, Minibatch Loss= 8248.363281, Training Accuracy= 0.67188\n",
      "Iter 47808, Minibatch Loss= 7496.380371, Training Accuracy= 0.76562\n",
      "Iter 47872, Minibatch Loss= 8033.420898, Training Accuracy= 0.70312\n",
      "Iter 47936, Minibatch Loss= 7509.942383, Training Accuracy= 0.75000\n",
      "Iter 48000, Minibatch Loss= 7744.367188, Training Accuracy= 0.73438\n",
      "Iter 48064, Minibatch Loss= 6699.882812, Training Accuracy= 0.73438\n",
      "Iter 48128, Minibatch Loss= 12414.479492, Training Accuracy= 0.70312\n",
      "Iter 48192, Minibatch Loss= 16113.522461, Training Accuracy= 0.73438\n",
      "Iter 48256, Minibatch Loss= 11234.148438, Training Accuracy= 0.70312\n",
      "Iter 48320, Minibatch Loss= 7023.460938, Training Accuracy= 0.75000\n",
      "Iter 48384, Minibatch Loss= 9451.894531, Training Accuracy= 0.71875\n",
      "Iter 48448, Minibatch Loss= 12316.765625, Training Accuracy= 0.65625\n",
      "Iter 48512, Minibatch Loss= 17252.593750, Training Accuracy= 0.57812\n",
      "Iter 48576, Minibatch Loss= 12376.063477, Training Accuracy= 0.64062\n",
      "Iter 48640, Minibatch Loss= 9873.047852, Training Accuracy= 0.85938\n",
      "Iter 48704, Minibatch Loss= 9887.403320, Training Accuracy= 0.73438\n",
      "Iter 48768, Minibatch Loss= 8460.867188, Training Accuracy= 0.73438\n",
      "Iter 48832, Minibatch Loss= 12998.365234, Training Accuracy= 0.65625\n",
      "Iter 48896, Minibatch Loss= 10925.244141, Training Accuracy= 0.71875\n",
      "Iter 48960, Minibatch Loss= 5505.325195, Training Accuracy= 0.76562\n",
      "Iter 49024, Minibatch Loss= 12919.210938, Training Accuracy= 0.70312\n",
      "Iter 49088, Minibatch Loss= 8499.630859, Training Accuracy= 0.70312\n",
      "Iter 49152, Minibatch Loss= 8997.694336, Training Accuracy= 0.73438\n",
      "Iter 49216, Minibatch Loss= 5254.143066, Training Accuracy= 0.76562\n",
      "Iter 49280, Minibatch Loss= 9095.589844, Training Accuracy= 0.78125\n",
      "Iter 49344, Minibatch Loss= 8231.377930, Training Accuracy= 0.71875\n",
      "Iter 49408, Minibatch Loss= 5272.210938, Training Accuracy= 0.81250\n",
      "Iter 49472, Minibatch Loss= 8695.371094, Training Accuracy= 0.75000\n",
      "Iter 49536, Minibatch Loss= 9344.832031, Training Accuracy= 0.70312\n",
      "Iter 49600, Minibatch Loss= 9734.242188, Training Accuracy= 0.67188\n",
      "Iter 49664, Minibatch Loss= 11411.985352, Training Accuracy= 0.68750\n",
      "Iter 49728, Minibatch Loss= 8747.576172, Training Accuracy= 0.73438\n",
      "Iter 49792, Minibatch Loss= 12807.992188, Training Accuracy= 0.70312\n",
      "Iter 49856, Minibatch Loss= 11461.094727, Training Accuracy= 0.73438\n",
      "Iter 49920, Minibatch Loss= 10212.655273, Training Accuracy= 0.62500\n",
      "Iter 49984, Minibatch Loss= 8731.107422, Training Accuracy= 0.70312\n",
      "Iter 50048, Minibatch Loss= 5502.991211, Training Accuracy= 0.70312\n",
      "Iter 50112, Minibatch Loss= 15492.259766, Training Accuracy= 0.64062\n",
      "Iter 50176, Minibatch Loss= 10649.862305, Training Accuracy= 0.67188\n",
      "Iter 50240, Minibatch Loss= 14151.162109, Training Accuracy= 0.65625\n",
      "Iter 50304, Minibatch Loss= 13539.429688, Training Accuracy= 0.67188\n",
      "Iter 50368, Minibatch Loss= 8785.705078, Training Accuracy= 0.65625\n",
      "Iter 50432, Minibatch Loss= 8519.093750, Training Accuracy= 0.68750\n",
      "Iter 50496, Minibatch Loss= 9118.503906, Training Accuracy= 0.73438\n",
      "Iter 50560, Minibatch Loss= 6254.562012, Training Accuracy= 0.78125\n",
      "Iter 50624, Minibatch Loss= 8572.190430, Training Accuracy= 0.62500\n",
      "Iter 50688, Minibatch Loss= 6795.903320, Training Accuracy= 0.75000\n",
      "Iter 50752, Minibatch Loss= 11604.186523, Training Accuracy= 0.64062\n",
      "Iter 50816, Minibatch Loss= 18210.710938, Training Accuracy= 0.65625\n",
      "Iter 50880, Minibatch Loss= 4786.413086, Training Accuracy= 0.75000\n",
      "Iter 50944, Minibatch Loss= 11348.410156, Training Accuracy= 0.68750\n",
      "Iter 51008, Minibatch Loss= 10064.528320, Training Accuracy= 0.75000\n",
      "Iter 51072, Minibatch Loss= 8297.931641, Training Accuracy= 0.65625\n",
      "Iter 51136, Minibatch Loss= 13090.148438, Training Accuracy= 0.73438\n",
      "Iter 51200, Minibatch Loss= 11397.291016, Training Accuracy= 0.67188\n",
      "Iter 51264, Minibatch Loss= 11459.927734, Training Accuracy= 0.67188\n",
      "Iter 51328, Minibatch Loss= 22758.759766, Training Accuracy= 0.53125\n",
      "Iter 51392, Minibatch Loss= 8822.464844, Training Accuracy= 0.78125\n",
      "Iter 51456, Minibatch Loss= 8247.622070, Training Accuracy= 0.73438\n",
      "Iter 51520, Minibatch Loss= 8299.812500, Training Accuracy= 0.64062\n",
      "Iter 51584, Minibatch Loss= 7872.083008, Training Accuracy= 0.75000\n",
      "Iter 51648, Minibatch Loss= 7361.905273, Training Accuracy= 0.79688\n",
      "Iter 51712, Minibatch Loss= 9196.617188, Training Accuracy= 0.56250\n",
      "Iter 51776, Minibatch Loss= 11882.478516, Training Accuracy= 0.60938\n",
      "Iter 51840, Minibatch Loss= 15203.151367, Training Accuracy= 0.59375\n",
      "Iter 51904, Minibatch Loss= 11042.960938, Training Accuracy= 0.67188\n",
      "Iter 51968, Minibatch Loss= 8068.236328, Training Accuracy= 0.79688\n",
      "Iter 52032, Minibatch Loss= 9084.951172, Training Accuracy= 0.70312\n",
      "Iter 52096, Minibatch Loss= 7141.553711, Training Accuracy= 0.82812\n",
      "Iter 52160, Minibatch Loss= 15016.340820, Training Accuracy= 0.68750\n",
      "Iter 52224, Minibatch Loss= 10093.299805, Training Accuracy= 0.65625\n",
      "Iter 52288, Minibatch Loss= 8444.153320, Training Accuracy= 0.71875\n",
      "Iter 52352, Minibatch Loss= 10180.612305, Training Accuracy= 0.65625\n",
      "Iter 52416, Minibatch Loss= 5101.723633, Training Accuracy= 0.78125\n",
      "Iter 52480, Minibatch Loss= 14248.230469, Training Accuracy= 0.64062\n",
      "Iter 52544, Minibatch Loss= 14692.158203, Training Accuracy= 0.60938\n",
      "Iter 52608, Minibatch Loss= 8682.992188, Training Accuracy= 0.71875\n",
      "Iter 52672, Minibatch Loss= 7997.947754, Training Accuracy= 0.67188\n",
      "Iter 52736, Minibatch Loss= 5981.175293, Training Accuracy= 0.76562\n",
      "Iter 52800, Minibatch Loss= 9671.815430, Training Accuracy= 0.79688\n",
      "Iter 52864, Minibatch Loss= 9224.021484, Training Accuracy= 0.70312\n",
      "Iter 52928, Minibatch Loss= 9737.773438, Training Accuracy= 0.68750\n",
      "Iter 52992, Minibatch Loss= 11403.126953, Training Accuracy= 0.67188\n",
      "Iter 53056, Minibatch Loss= 10861.530273, Training Accuracy= 0.68750\n",
      "Iter 53120, Minibatch Loss= 11814.232422, Training Accuracy= 0.73438\n",
      "Iter 53184, Minibatch Loss= 7870.916504, Training Accuracy= 0.75000\n",
      "Iter 53248, Minibatch Loss= 9079.728516, Training Accuracy= 0.62500\n",
      "Iter 53312, Minibatch Loss= 12299.392578, Training Accuracy= 0.68750\n",
      "Iter 53376, Minibatch Loss= 7878.705078, Training Accuracy= 0.75000\n",
      "Iter 53440, Minibatch Loss= 4348.691406, Training Accuracy= 0.85938\n",
      "Iter 53504, Minibatch Loss= 7327.053223, Training Accuracy= 0.76562\n",
      "Iter 53568, Minibatch Loss= 9656.154297, Training Accuracy= 0.64062\n",
      "Iter 53632, Minibatch Loss= 10741.726562, Training Accuracy= 0.68750\n",
      "Iter 53696, Minibatch Loss= 7002.965332, Training Accuracy= 0.71875\n",
      "Iter 53760, Minibatch Loss= 11175.761719, Training Accuracy= 0.68750\n",
      "Iter 53824, Minibatch Loss= 12599.916992, Training Accuracy= 0.75000\n",
      "Iter 53888, Minibatch Loss= 10588.541016, Training Accuracy= 0.64062\n",
      "Iter 53952, Minibatch Loss= 8521.391602, Training Accuracy= 0.68750\n",
      "Iter 54016, Minibatch Loss= 6121.478516, Training Accuracy= 0.71875\n",
      "Iter 54080, Minibatch Loss= 8986.863281, Training Accuracy= 0.78125\n",
      "Iter 54144, Minibatch Loss= 7104.596191, Training Accuracy= 0.71875\n",
      "Iter 54208, Minibatch Loss= 6347.270996, Training Accuracy= 0.68750\n",
      "Iter 54272, Minibatch Loss= 14173.882812, Training Accuracy= 0.54688\n",
      "Iter 54336, Minibatch Loss= 8946.221680, Training Accuracy= 0.75000\n",
      "Iter 54400, Minibatch Loss= 13238.666016, Training Accuracy= 0.65625\n",
      "Iter 54464, Minibatch Loss= 8763.029297, Training Accuracy= 0.70312\n",
      "Iter 54528, Minibatch Loss= 7370.704590, Training Accuracy= 0.64062\n",
      "Iter 54592, Minibatch Loss= 11315.748047, Training Accuracy= 0.68750\n",
      "Iter 54656, Minibatch Loss= 13914.753906, Training Accuracy= 0.62500\n",
      "Iter 54720, Minibatch Loss= 9725.566406, Training Accuracy= 0.71875\n",
      "Iter 54784, Minibatch Loss= 11820.740234, Training Accuracy= 0.65625\n",
      "Iter 54848, Minibatch Loss= 9471.812500, Training Accuracy= 0.67188\n",
      "Iter 54912, Minibatch Loss= 11098.230469, Training Accuracy= 0.65625\n",
      "Iter 54976, Minibatch Loss= 14945.658203, Training Accuracy= 0.60938\n",
      "Iter 55040, Minibatch Loss= 8914.484375, Training Accuracy= 0.75000\n",
      "Iter 55104, Minibatch Loss= 10432.814453, Training Accuracy= 0.71875\n",
      "Iter 55168, Minibatch Loss= 9097.841797, Training Accuracy= 0.65625\n",
      "Iter 55232, Minibatch Loss= 9536.058594, Training Accuracy= 0.65625\n",
      "Iter 55296, Minibatch Loss= 6269.809082, Training Accuracy= 0.76562\n",
      "Iter 55360, Minibatch Loss= 7333.717285, Training Accuracy= 0.75000\n",
      "Iter 55424, Minibatch Loss= 14416.402344, Training Accuracy= 0.60938\n",
      "Iter 55488, Minibatch Loss= 9463.558594, Training Accuracy= 0.76562\n",
      "Iter 55552, Minibatch Loss= 15194.904297, Training Accuracy= 0.64062\n",
      "Iter 55616, Minibatch Loss= 6740.310547, Training Accuracy= 0.78125\n",
      "Iter 55680, Minibatch Loss= 9047.038086, Training Accuracy= 0.64062\n",
      "Iter 55744, Minibatch Loss= 8816.232422, Training Accuracy= 0.70312\n",
      "Iter 55808, Minibatch Loss= 12727.038086, Training Accuracy= 0.60938\n",
      "Iter 55872, Minibatch Loss= 10437.938477, Training Accuracy= 0.68750\n",
      "Iter 55936, Minibatch Loss= 9710.050781, Training Accuracy= 0.70312\n",
      "Iter 56000, Minibatch Loss= 9299.728516, Training Accuracy= 0.73438\n",
      "Iter 56064, Minibatch Loss= 9083.173828, Training Accuracy= 0.71875\n",
      "Iter 56128, Minibatch Loss= 8537.107422, Training Accuracy= 0.67188\n",
      "Iter 56192, Minibatch Loss= 9304.423828, Training Accuracy= 0.68750\n",
      "Iter 56256, Minibatch Loss= 7439.937500, Training Accuracy= 0.76562\n",
      "Iter 56320, Minibatch Loss= 12832.303711, Training Accuracy= 0.75000\n",
      "Iter 56384, Minibatch Loss= 9822.376953, Training Accuracy= 0.73438\n",
      "Iter 56448, Minibatch Loss= 8253.796875, Training Accuracy= 0.67188\n",
      "Iter 56512, Minibatch Loss= 12733.107422, Training Accuracy= 0.60938\n",
      "Iter 56576, Minibatch Loss= 7606.525391, Training Accuracy= 0.76562\n",
      "Iter 56640, Minibatch Loss= 12499.582031, Training Accuracy= 0.56250\n",
      "Iter 56704, Minibatch Loss= 10857.821289, Training Accuracy= 0.60938\n",
      "Iter 56768, Minibatch Loss= 12832.740234, Training Accuracy= 0.65625\n",
      "Iter 56832, Minibatch Loss= 13189.285156, Training Accuracy= 0.67188\n",
      "Iter 56896, Minibatch Loss= 9785.881836, Training Accuracy= 0.68750\n",
      "Iter 56960, Minibatch Loss= 9399.481445, Training Accuracy= 0.68750\n",
      "Iter 57024, Minibatch Loss= 8304.710938, Training Accuracy= 0.68750\n",
      "Iter 57088, Minibatch Loss= 15141.876953, Training Accuracy= 0.57812\n",
      "Iter 57152, Minibatch Loss= 6609.902344, Training Accuracy= 0.67188\n",
      "Iter 57216, Minibatch Loss= 13187.708984, Training Accuracy= 0.54688\n",
      "Iter 57280, Minibatch Loss= 8425.056641, Training Accuracy= 0.65625\n",
      "Iter 57344, Minibatch Loss= 8271.042969, Training Accuracy= 0.68750\n",
      "Iter 57408, Minibatch Loss= 8877.085938, Training Accuracy= 0.68750\n",
      "Iter 57472, Minibatch Loss= 11897.108398, Training Accuracy= 0.64062\n",
      "Iter 57536, Minibatch Loss= 9037.796875, Training Accuracy= 0.73438\n",
      "Iter 57600, Minibatch Loss= 7224.408203, Training Accuracy= 0.68750\n",
      "Iter 57664, Minibatch Loss= 14633.562500, Training Accuracy= 0.64062\n",
      "Iter 57728, Minibatch Loss= 7599.484375, Training Accuracy= 0.67188\n",
      "Iter 57792, Minibatch Loss= 6913.128418, Training Accuracy= 0.78125\n",
      "Iter 57856, Minibatch Loss= 8323.833008, Training Accuracy= 0.70312\n",
      "Iter 57920, Minibatch Loss= 10396.110352, Training Accuracy= 0.75000\n",
      "Iter 57984, Minibatch Loss= 8336.050781, Training Accuracy= 0.67188\n",
      "Iter 58048, Minibatch Loss= 6982.129395, Training Accuracy= 0.75000\n",
      "Iter 58112, Minibatch Loss= 7227.311523, Training Accuracy= 0.76562\n",
      "Iter 58176, Minibatch Loss= 14581.550781, Training Accuracy= 0.64062\n",
      "Iter 58240, Minibatch Loss= 12756.538086, Training Accuracy= 0.65625\n",
      "Iter 58304, Minibatch Loss= 9928.001953, Training Accuracy= 0.65625\n",
      "Iter 58368, Minibatch Loss= 6942.739258, Training Accuracy= 0.75000\n",
      "Iter 58432, Minibatch Loss= 7930.183594, Training Accuracy= 0.70312\n",
      "Iter 58496, Minibatch Loss= 13056.656250, Training Accuracy= 0.59375\n",
      "Iter 58560, Minibatch Loss= 8850.039062, Training Accuracy= 0.73438\n",
      "Iter 58624, Minibatch Loss= 9478.262695, Training Accuracy= 0.64062\n",
      "Iter 58688, Minibatch Loss= 12994.732422, Training Accuracy= 0.65625\n",
      "Iter 58752, Minibatch Loss= 7938.615723, Training Accuracy= 0.73438\n",
      "Iter 58816, Minibatch Loss= 7780.091309, Training Accuracy= 0.75000\n",
      "Iter 58880, Minibatch Loss= 12001.538086, Training Accuracy= 0.60938\n",
      "Iter 58944, Minibatch Loss= 8438.334961, Training Accuracy= 0.76562\n",
      "Iter 59008, Minibatch Loss= 7092.641602, Training Accuracy= 0.71875\n",
      "Iter 59072, Minibatch Loss= 6368.203125, Training Accuracy= 0.75000\n",
      "Iter 59136, Minibatch Loss= 7390.518066, Training Accuracy= 0.73438\n",
      "Iter 59200, Minibatch Loss= 5360.761719, Training Accuracy= 0.78125\n",
      "Iter 59264, Minibatch Loss= 2174.313965, Training Accuracy= 0.85938\n",
      "Iter 59328, Minibatch Loss= 8643.639648, Training Accuracy= 0.76562\n",
      "Iter 59392, Minibatch Loss= 8955.437500, Training Accuracy= 0.75000\n",
      "Iter 59456, Minibatch Loss= 13756.567383, Training Accuracy= 0.64062\n",
      "Iter 59520, Minibatch Loss= 10851.791016, Training Accuracy= 0.64062\n",
      "Iter 59584, Minibatch Loss= 11065.666992, Training Accuracy= 0.67188\n",
      "Iter 59648, Minibatch Loss= 7722.243164, Training Accuracy= 0.75000\n",
      "Iter 59712, Minibatch Loss= 7712.250488, Training Accuracy= 0.70312\n",
      "Iter 59776, Minibatch Loss= 8965.663086, Training Accuracy= 0.70312\n",
      "Iter 59840, Minibatch Loss= 10593.005859, Training Accuracy= 0.60938\n",
      "Iter 59904, Minibatch Loss= 4926.166504, Training Accuracy= 0.73438\n",
      "Iter 59968, Minibatch Loss= 5052.686035, Training Accuracy= 0.68750\n",
      "Iter 60032, Minibatch Loss= 6854.140137, Training Accuracy= 0.73438\n",
      "Iter 60096, Minibatch Loss= 8070.071289, Training Accuracy= 0.75000\n",
      "Iter 60160, Minibatch Loss= 9489.632812, Training Accuracy= 0.73438\n",
      "Iter 60224, Minibatch Loss= 7905.092285, Training Accuracy= 0.67188\n",
      "Iter 60288, Minibatch Loss= 9208.839844, Training Accuracy= 0.73438\n",
      "Iter 60352, Minibatch Loss= 11107.814453, Training Accuracy= 0.64062\n",
      "Iter 60416, Minibatch Loss= 13229.358398, Training Accuracy= 0.62500\n",
      "Iter 60480, Minibatch Loss= 8272.652344, Training Accuracy= 0.65625\n",
      "Iter 60544, Minibatch Loss= 6007.656250, Training Accuracy= 0.73438\n",
      "Iter 60608, Minibatch Loss= 7251.700684, Training Accuracy= 0.71875\n",
      "Iter 60672, Minibatch Loss= 11498.205078, Training Accuracy= 0.57812\n",
      "Iter 60736, Minibatch Loss= 6544.835938, Training Accuracy= 0.79688\n",
      "Iter 60800, Minibatch Loss= 8803.688477, Training Accuracy= 0.75000\n",
      "Iter 60864, Minibatch Loss= 10829.777344, Training Accuracy= 0.70312\n",
      "Iter 60928, Minibatch Loss= 11275.511719, Training Accuracy= 0.64062\n",
      "Iter 60992, Minibatch Loss= 8253.977539, Training Accuracy= 0.73438\n",
      "Iter 61056, Minibatch Loss= 11507.919922, Training Accuracy= 0.60938\n",
      "Iter 61120, Minibatch Loss= 9831.666016, Training Accuracy= 0.68750\n",
      "Iter 61184, Minibatch Loss= 18095.984375, Training Accuracy= 0.51562\n",
      "Iter 61248, Minibatch Loss= 5713.435547, Training Accuracy= 0.70312\n",
      "Iter 61312, Minibatch Loss= 10878.041016, Training Accuracy= 0.67188\n",
      "Iter 61376, Minibatch Loss= 4980.480469, Training Accuracy= 0.75000\n",
      "Iter 61440, Minibatch Loss= 5806.682617, Training Accuracy= 0.75000\n",
      "Iter 61504, Minibatch Loss= 4939.210449, Training Accuracy= 0.82812\n",
      "Iter 61568, Minibatch Loss= 4589.783691, Training Accuracy= 0.84375\n",
      "Iter 61632, Minibatch Loss= 7596.166992, Training Accuracy= 0.65625\n",
      "Iter 61696, Minibatch Loss= 6694.991699, Training Accuracy= 0.73438\n",
      "Iter 61760, Minibatch Loss= 8827.240234, Training Accuracy= 0.60938\n",
      "Iter 61824, Minibatch Loss= 13064.891602, Training Accuracy= 0.57812\n",
      "Iter 61888, Minibatch Loss= 7966.526855, Training Accuracy= 0.70312\n",
      "Iter 61952, Minibatch Loss= 9991.336914, Training Accuracy= 0.70312\n",
      "Iter 62016, Minibatch Loss= 10398.929688, Training Accuracy= 0.62500\n",
      "Iter 62080, Minibatch Loss= 8565.459961, Training Accuracy= 0.73438\n",
      "Iter 62144, Minibatch Loss= 7156.633789, Training Accuracy= 0.70312\n",
      "Iter 62208, Minibatch Loss= 6495.674805, Training Accuracy= 0.75000\n",
      "Iter 62272, Minibatch Loss= 12524.483398, Training Accuracy= 0.62500\n",
      "Iter 62336, Minibatch Loss= 9527.957031, Training Accuracy= 0.67188\n",
      "Iter 62400, Minibatch Loss= 8107.771973, Training Accuracy= 0.79688\n",
      "Iter 62464, Minibatch Loss= 4588.369141, Training Accuracy= 0.76562\n",
      "Iter 62528, Minibatch Loss= 8657.785156, Training Accuracy= 0.70312\n",
      "Iter 62592, Minibatch Loss= 6753.069336, Training Accuracy= 0.76562\n",
      "Iter 62656, Minibatch Loss= 4951.680664, Training Accuracy= 0.84375\n",
      "Iter 62720, Minibatch Loss= 8766.341797, Training Accuracy= 0.67188\n",
      "Iter 62784, Minibatch Loss= 6323.059082, Training Accuracy= 0.67188\n",
      "Iter 62848, Minibatch Loss= 7059.291504, Training Accuracy= 0.75000\n",
      "Iter 62912, Minibatch Loss= 7392.871582, Training Accuracy= 0.71875\n",
      "Iter 62976, Minibatch Loss= 8263.358398, Training Accuracy= 0.70312\n",
      "Iter 63040, Minibatch Loss= 11125.509766, Training Accuracy= 0.73438\n",
      "Iter 63104, Minibatch Loss= 4913.042969, Training Accuracy= 0.82812\n",
      "Iter 63168, Minibatch Loss= 7729.252441, Training Accuracy= 0.81250\n",
      "Iter 63232, Minibatch Loss= 9590.161133, Training Accuracy= 0.67188\n",
      "Iter 63296, Minibatch Loss= 8969.871094, Training Accuracy= 0.62500\n",
      "Iter 63360, Minibatch Loss= 8130.621582, Training Accuracy= 0.70312\n",
      "Iter 63424, Minibatch Loss= 10777.350586, Training Accuracy= 0.65625\n",
      "Iter 63488, Minibatch Loss= 8852.372070, Training Accuracy= 0.70312\n",
      "Iter 63552, Minibatch Loss= 7441.693848, Training Accuracy= 0.68750\n",
      "Iter 63616, Minibatch Loss= 8499.917969, Training Accuracy= 0.70312\n",
      "Iter 63680, Minibatch Loss= 8194.791016, Training Accuracy= 0.67188\n",
      "Iter 63744, Minibatch Loss= 3339.288818, Training Accuracy= 0.78125\n",
      "Iter 63808, Minibatch Loss= 8368.963867, Training Accuracy= 0.68750\n",
      "Iter 63872, Minibatch Loss= 7240.048340, Training Accuracy= 0.68750\n",
      "Iter 63936, Minibatch Loss= 5396.540039, Training Accuracy= 0.82812\n",
      "Iter 64000, Minibatch Loss= 6174.426758, Training Accuracy= 0.71875\n",
      "Iter 64064, Minibatch Loss= 5586.314941, Training Accuracy= 0.75000\n",
      "Iter 64128, Minibatch Loss= 6860.384766, Training Accuracy= 0.78125\n",
      "Iter 64192, Minibatch Loss= 10715.869141, Training Accuracy= 0.62500\n",
      "Iter 64256, Minibatch Loss= 5282.293457, Training Accuracy= 0.70312\n",
      "Iter 64320, Minibatch Loss= 4677.669922, Training Accuracy= 0.81250\n",
      "Iter 64384, Minibatch Loss= 9808.236328, Training Accuracy= 0.75000\n",
      "Iter 64448, Minibatch Loss= 10803.230469, Training Accuracy= 0.57812\n",
      "Iter 64512, Minibatch Loss= 6009.171875, Training Accuracy= 0.79688\n",
      "Iter 64576, Minibatch Loss= 7238.969727, Training Accuracy= 0.70312\n",
      "Iter 64640, Minibatch Loss= 8494.464844, Training Accuracy= 0.67188\n",
      "Iter 64704, Minibatch Loss= 3237.467773, Training Accuracy= 0.84375\n",
      "Iter 64768, Minibatch Loss= 14361.805664, Training Accuracy= 0.62500\n",
      "Iter 64832, Minibatch Loss= 12080.496094, Training Accuracy= 0.60938\n",
      "Iter 64896, Minibatch Loss= 7514.258301, Training Accuracy= 0.71875\n",
      "Iter 64960, Minibatch Loss= 13389.179688, Training Accuracy= 0.67188\n",
      "Iter 65024, Minibatch Loss= 5581.275391, Training Accuracy= 0.76562\n",
      "Iter 65088, Minibatch Loss= 8285.847656, Training Accuracy= 0.75000\n",
      "Iter 65152, Minibatch Loss= 9875.115234, Training Accuracy= 0.71875\n",
      "Iter 65216, Minibatch Loss= 6445.781250, Training Accuracy= 0.75000\n",
      "Iter 65280, Minibatch Loss= 6098.379883, Training Accuracy= 0.71875\n",
      "Iter 65344, Minibatch Loss= 10166.734375, Training Accuracy= 0.57812\n",
      "Iter 65408, Minibatch Loss= 4069.505615, Training Accuracy= 0.78125\n",
      "Iter 65472, Minibatch Loss= 11172.390625, Training Accuracy= 0.57812\n",
      "Iter 65536, Minibatch Loss= 8205.634766, Training Accuracy= 0.68750\n",
      "Iter 65600, Minibatch Loss= 5231.758301, Training Accuracy= 0.79688\n",
      "Iter 65664, Minibatch Loss= 4441.937988, Training Accuracy= 0.79688\n",
      "Iter 65728, Minibatch Loss= 10047.439453, Training Accuracy= 0.65625\n",
      "Iter 65792, Minibatch Loss= 9835.322266, Training Accuracy= 0.68750\n",
      "Iter 65856, Minibatch Loss= 6866.527832, Training Accuracy= 0.70312\n",
      "Iter 65920, Minibatch Loss= 6758.992676, Training Accuracy= 0.70312\n",
      "Iter 65984, Minibatch Loss= 7249.479492, Training Accuracy= 0.73438\n",
      "Iter 66048, Minibatch Loss= 14107.750000, Training Accuracy= 0.60938\n",
      "Iter 66112, Minibatch Loss= 9063.250000, Training Accuracy= 0.68750\n",
      "Iter 66176, Minibatch Loss= 6543.474609, Training Accuracy= 0.73438\n",
      "Iter 66240, Minibatch Loss= 5626.170410, Training Accuracy= 0.75000\n",
      "Iter 66304, Minibatch Loss= 9653.279297, Training Accuracy= 0.64062\n",
      "Iter 66368, Minibatch Loss= 5376.165039, Training Accuracy= 0.67188\n",
      "Iter 66432, Minibatch Loss= 11161.367188, Training Accuracy= 0.67188\n",
      "Iter 66496, Minibatch Loss= 8052.221191, Training Accuracy= 0.62500\n",
      "Iter 66560, Minibatch Loss= 9828.300781, Training Accuracy= 0.68750\n",
      "Iter 66624, Minibatch Loss= 10801.570312, Training Accuracy= 0.64062\n",
      "Iter 66688, Minibatch Loss= 8269.902344, Training Accuracy= 0.65625\n",
      "Iter 66752, Minibatch Loss= 6518.861816, Training Accuracy= 0.70312\n",
      "Iter 66816, Minibatch Loss= 8619.071289, Training Accuracy= 0.70312\n",
      "Iter 66880, Minibatch Loss= 12335.162109, Training Accuracy= 0.67188\n",
      "Iter 66944, Minibatch Loss= 6842.074219, Training Accuracy= 0.76562\n",
      "Iter 67008, Minibatch Loss= 5635.260742, Training Accuracy= 0.75000\n",
      "Iter 67072, Minibatch Loss= 6682.720703, Training Accuracy= 0.68750\n",
      "Iter 67136, Minibatch Loss= 6658.864258, Training Accuracy= 0.70312\n",
      "Iter 67200, Minibatch Loss= 6417.233398, Training Accuracy= 0.76562\n",
      "Iter 67264, Minibatch Loss= 7054.461426, Training Accuracy= 0.68750\n",
      "Iter 67328, Minibatch Loss= 6217.610840, Training Accuracy= 0.68750\n",
      "Iter 67392, Minibatch Loss= 8768.580078, Training Accuracy= 0.67188\n",
      "Iter 67456, Minibatch Loss= 6828.955566, Training Accuracy= 0.73438\n",
      "Iter 67520, Minibatch Loss= 9447.404297, Training Accuracy= 0.65625\n",
      "Iter 67584, Minibatch Loss= 5468.744141, Training Accuracy= 0.68750\n",
      "Iter 67648, Minibatch Loss= 4400.606445, Training Accuracy= 0.78125\n",
      "Iter 67712, Minibatch Loss= 4393.600586, Training Accuracy= 0.76562\n",
      "Iter 67776, Minibatch Loss= 5062.125000, Training Accuracy= 0.76562\n",
      "Iter 67840, Minibatch Loss= 8919.185547, Training Accuracy= 0.65625\n",
      "Iter 67904, Minibatch Loss= 8654.296875, Training Accuracy= 0.75000\n",
      "Iter 67968, Minibatch Loss= 6927.976562, Training Accuracy= 0.70312\n",
      "Iter 68032, Minibatch Loss= 11138.847656, Training Accuracy= 0.60938\n",
      "Iter 68096, Minibatch Loss= 8375.567383, Training Accuracy= 0.65625\n",
      "Iter 68160, Minibatch Loss= 9274.873047, Training Accuracy= 0.60938\n",
      "Iter 68224, Minibatch Loss= 10515.177734, Training Accuracy= 0.62500\n",
      "Iter 68288, Minibatch Loss= 6422.943848, Training Accuracy= 0.70312\n",
      "Iter 68352, Minibatch Loss= 9702.369141, Training Accuracy= 0.60938\n",
      "Iter 68416, Minibatch Loss= 5702.793457, Training Accuracy= 0.75000\n",
      "Iter 68480, Minibatch Loss= 6451.115723, Training Accuracy= 0.70312\n",
      "Iter 68544, Minibatch Loss= 4905.457031, Training Accuracy= 0.68750\n",
      "Iter 68608, Minibatch Loss= 9641.561523, Training Accuracy= 0.64062\n",
      "Iter 68672, Minibatch Loss= 6523.378906, Training Accuracy= 0.70312\n",
      "Iter 68736, Minibatch Loss= 7598.597168, Training Accuracy= 0.73438\n",
      "Iter 68800, Minibatch Loss= 10592.748047, Training Accuracy= 0.70312\n",
      "Iter 68864, Minibatch Loss= 7526.771973, Training Accuracy= 0.71875\n",
      "Iter 68928, Minibatch Loss= 10208.728516, Training Accuracy= 0.73438\n",
      "Iter 68992, Minibatch Loss= 5670.758789, Training Accuracy= 0.78125\n",
      "Iter 69056, Minibatch Loss= 6910.612305, Training Accuracy= 0.70312\n",
      "Iter 69120, Minibatch Loss= 7209.008789, Training Accuracy= 0.70312\n",
      "Iter 69184, Minibatch Loss= 7820.169922, Training Accuracy= 0.64062\n",
      "Iter 69248, Minibatch Loss= 5030.632324, Training Accuracy= 0.76562\n",
      "Iter 69312, Minibatch Loss= 4951.871094, Training Accuracy= 0.67188\n",
      "Iter 69376, Minibatch Loss= 4481.554199, Training Accuracy= 0.76562\n",
      "Iter 69440, Minibatch Loss= 7778.949219, Training Accuracy= 0.75000\n",
      "Iter 69504, Minibatch Loss= 7712.268555, Training Accuracy= 0.67188\n",
      "Iter 69568, Minibatch Loss= 6494.959961, Training Accuracy= 0.67188\n",
      "Iter 69632, Minibatch Loss= 7940.527344, Training Accuracy= 0.68750\n",
      "Iter 69696, Minibatch Loss= 8162.268555, Training Accuracy= 0.76562\n",
      "Iter 69760, Minibatch Loss= 4173.211914, Training Accuracy= 0.67188\n",
      "Iter 69824, Minibatch Loss= 4780.577148, Training Accuracy= 0.71875\n",
      "Iter 69888, Minibatch Loss= 8770.853516, Training Accuracy= 0.64062\n",
      "Iter 69952, Minibatch Loss= 8943.084961, Training Accuracy= 0.73438\n",
      "Iter 70016, Minibatch Loss= 4635.012207, Training Accuracy= 0.71875\n",
      "Iter 70080, Minibatch Loss= 7341.911621, Training Accuracy= 0.64062\n",
      "Iter 70144, Minibatch Loss= 7120.225098, Training Accuracy= 0.62500\n",
      "Iter 70208, Minibatch Loss= 9015.897461, Training Accuracy= 0.67188\n",
      "Iter 70272, Minibatch Loss= 6833.607422, Training Accuracy= 0.78125\n",
      "Iter 70336, Minibatch Loss= 6227.133301, Training Accuracy= 0.65625\n",
      "Iter 70400, Minibatch Loss= 5557.295410, Training Accuracy= 0.73438\n",
      "Iter 70464, Minibatch Loss= 3255.771973, Training Accuracy= 0.73438\n",
      "Iter 70528, Minibatch Loss= 4790.581543, Training Accuracy= 0.71875\n",
      "Iter 70592, Minibatch Loss= 5005.238770, Training Accuracy= 0.71875\n",
      "Iter 70656, Minibatch Loss= 5902.428223, Training Accuracy= 0.68750\n",
      "Iter 70720, Minibatch Loss= 7974.336426, Training Accuracy= 0.64062\n",
      "Iter 70784, Minibatch Loss= 6264.800293, Training Accuracy= 0.71875\n",
      "Iter 70848, Minibatch Loss= 6929.101562, Training Accuracy= 0.71875\n",
      "Iter 70912, Minibatch Loss= 5277.327148, Training Accuracy= 0.65625\n",
      "Iter 70976, Minibatch Loss= 4577.340332, Training Accuracy= 0.75000\n",
      "Iter 71040, Minibatch Loss= 10696.315430, Training Accuracy= 0.68750\n",
      "Iter 71104, Minibatch Loss= 7038.608398, Training Accuracy= 0.71875\n",
      "Iter 71168, Minibatch Loss= 10946.679688, Training Accuracy= 0.67188\n",
      "Iter 71232, Minibatch Loss= 9403.964844, Training Accuracy= 0.68750\n",
      "Iter 71296, Minibatch Loss= 6786.219727, Training Accuracy= 0.68750\n",
      "Iter 71360, Minibatch Loss= 7167.310059, Training Accuracy= 0.65625\n",
      "Iter 71424, Minibatch Loss= 7759.459473, Training Accuracy= 0.76562\n",
      "Iter 71488, Minibatch Loss= 7571.992188, Training Accuracy= 0.70312\n",
      "Iter 71552, Minibatch Loss= 2890.788086, Training Accuracy= 0.79688\n",
      "Iter 71616, Minibatch Loss= 7670.423340, Training Accuracy= 0.71875\n",
      "Iter 71680, Minibatch Loss= 9866.609375, Training Accuracy= 0.64062\n",
      "Iter 71744, Minibatch Loss= 9055.195312, Training Accuracy= 0.75000\n",
      "Iter 71808, Minibatch Loss= 7186.390625, Training Accuracy= 0.75000\n",
      "Iter 71872, Minibatch Loss= 7227.296875, Training Accuracy= 0.70312\n",
      "Iter 71936, Minibatch Loss= 9136.623047, Training Accuracy= 0.70312\n",
      "Iter 72000, Minibatch Loss= 6322.094238, Training Accuracy= 0.71875\n",
      "Iter 72064, Minibatch Loss= 9758.311523, Training Accuracy= 0.70312\n",
      "Iter 72128, Minibatch Loss= 7483.976562, Training Accuracy= 0.75000\n",
      "Iter 72192, Minibatch Loss= 5465.967285, Training Accuracy= 0.82812\n",
      "Iter 72256, Minibatch Loss= 10693.973633, Training Accuracy= 0.67188\n",
      "Iter 72320, Minibatch Loss= 8681.372070, Training Accuracy= 0.62500\n",
      "Iter 72384, Minibatch Loss= 7669.130859, Training Accuracy= 0.68750\n",
      "Iter 72448, Minibatch Loss= 7998.000977, Training Accuracy= 0.68750\n",
      "Iter 72512, Minibatch Loss= 6021.961426, Training Accuracy= 0.70312\n",
      "Iter 72576, Minibatch Loss= 6929.309082, Training Accuracy= 0.64062\n",
      "Iter 72640, Minibatch Loss= 14010.304688, Training Accuracy= 0.56250\n",
      "Iter 72704, Minibatch Loss= 8276.929688, Training Accuracy= 0.68750\n",
      "Iter 72768, Minibatch Loss= 6762.056641, Training Accuracy= 0.84375\n",
      "Iter 72832, Minibatch Loss= 5705.874023, Training Accuracy= 0.73438\n",
      "Iter 72896, Minibatch Loss= 5512.472656, Training Accuracy= 0.68750\n",
      "Iter 72960, Minibatch Loss= 4469.718750, Training Accuracy= 0.75000\n",
      "Iter 73024, Minibatch Loss= 6191.313477, Training Accuracy= 0.73438\n",
      "Iter 73088, Minibatch Loss= 6356.557129, Training Accuracy= 0.71875\n",
      "Iter 73152, Minibatch Loss= 9139.544922, Training Accuracy= 0.71875\n",
      "Iter 73216, Minibatch Loss= 11287.666016, Training Accuracy= 0.68750\n",
      "Iter 73280, Minibatch Loss= 7584.934570, Training Accuracy= 0.68750\n",
      "Iter 73344, Minibatch Loss= 12029.818359, Training Accuracy= 0.68750\n",
      "Iter 73408, Minibatch Loss= 6603.861816, Training Accuracy= 0.70312\n",
      "Iter 73472, Minibatch Loss= 8653.136719, Training Accuracy= 0.71875\n",
      "Iter 73536, Minibatch Loss= 6664.161621, Training Accuracy= 0.71875\n",
      "Iter 73600, Minibatch Loss= 6449.835938, Training Accuracy= 0.76562\n",
      "Iter 73664, Minibatch Loss= 7395.890625, Training Accuracy= 0.64062\n",
      "Iter 73728, Minibatch Loss= 9374.700195, Training Accuracy= 0.64062\n",
      "Iter 73792, Minibatch Loss= 7636.594727, Training Accuracy= 0.65625\n",
      "Iter 73856, Minibatch Loss= 8716.533203, Training Accuracy= 0.65625\n",
      "Iter 73920, Minibatch Loss= 11244.763672, Training Accuracy= 0.64062\n",
      "Iter 73984, Minibatch Loss= 6408.786133, Training Accuracy= 0.75000\n",
      "Iter 74048, Minibatch Loss= 8046.389648, Training Accuracy= 0.71875\n",
      "Iter 74112, Minibatch Loss= 6395.263672, Training Accuracy= 0.64062\n",
      "Iter 74176, Minibatch Loss= 6158.337891, Training Accuracy= 0.71875\n",
      "Iter 74240, Minibatch Loss= 7985.239258, Training Accuracy= 0.59375\n",
      "Iter 74304, Minibatch Loss= 6571.738281, Training Accuracy= 0.73438\n",
      "Iter 74368, Minibatch Loss= 7767.344727, Training Accuracy= 0.67188\n",
      "Iter 74432, Minibatch Loss= 7129.064453, Training Accuracy= 0.67188\n",
      "Iter 74496, Minibatch Loss= 6850.271973, Training Accuracy= 0.78125\n",
      "Iter 74560, Minibatch Loss= 10840.394531, Training Accuracy= 0.62500\n",
      "Iter 74624, Minibatch Loss= 9809.498047, Training Accuracy= 0.60938\n",
      "Iter 74688, Minibatch Loss= 5574.322266, Training Accuracy= 0.73438\n",
      "Iter 74752, Minibatch Loss= 9330.343750, Training Accuracy= 0.62500\n",
      "Iter 74816, Minibatch Loss= 9698.172852, Training Accuracy= 0.68750\n",
      "Iter 74880, Minibatch Loss= 4717.625488, Training Accuracy= 0.73438\n",
      "Iter 74944, Minibatch Loss= 6608.151855, Training Accuracy= 0.68750\n",
      "Iter 75008, Minibatch Loss= 7978.600586, Training Accuracy= 0.67188\n",
      "Iter 75072, Minibatch Loss= 5530.391602, Training Accuracy= 0.73438\n",
      "Iter 75136, Minibatch Loss= 5114.320801, Training Accuracy= 0.71875\n",
      "Iter 75200, Minibatch Loss= 6506.575195, Training Accuracy= 0.73438\n",
      "Iter 75264, Minibatch Loss= 6921.700684, Training Accuracy= 0.71875\n",
      "Iter 75328, Minibatch Loss= 7974.067871, Training Accuracy= 0.70312\n",
      "Iter 75392, Minibatch Loss= 10655.175781, Training Accuracy= 0.62500\n",
      "Iter 75456, Minibatch Loss= 9346.571289, Training Accuracy= 0.68750\n",
      "Iter 75520, Minibatch Loss= 6660.780273, Training Accuracy= 0.70312\n",
      "Iter 75584, Minibatch Loss= 7587.239746, Training Accuracy= 0.71875\n",
      "Iter 75648, Minibatch Loss= 8944.910156, Training Accuracy= 0.65625\n",
      "Iter 75712, Minibatch Loss= 6449.989746, Training Accuracy= 0.68750\n",
      "Iter 75776, Minibatch Loss= 6587.017578, Training Accuracy= 0.64062\n",
      "Iter 75840, Minibatch Loss= 7845.666016, Training Accuracy= 0.67188\n",
      "Iter 75904, Minibatch Loss= 5181.114258, Training Accuracy= 0.73438\n",
      "Iter 75968, Minibatch Loss= 6885.612305, Training Accuracy= 0.59375\n",
      "Iter 76032, Minibatch Loss= 6612.333984, Training Accuracy= 0.76562\n",
      "Iter 76096, Minibatch Loss= 7261.654297, Training Accuracy= 0.73438\n",
      "Iter 76160, Minibatch Loss= 10143.859375, Training Accuracy= 0.70312\n",
      "Iter 76224, Minibatch Loss= 7118.620117, Training Accuracy= 0.70312\n",
      "Iter 76288, Minibatch Loss= 6213.553223, Training Accuracy= 0.75000\n",
      "Iter 76352, Minibatch Loss= 5131.652344, Training Accuracy= 0.73438\n",
      "Iter 76416, Minibatch Loss= 8924.063477, Training Accuracy= 0.67188\n",
      "Iter 76480, Minibatch Loss= 5263.243164, Training Accuracy= 0.73438\n",
      "Iter 76544, Minibatch Loss= 5001.098145, Training Accuracy= 0.76562\n",
      "Iter 76608, Minibatch Loss= 5546.242188, Training Accuracy= 0.65625\n",
      "Iter 76672, Minibatch Loss= 7493.334961, Training Accuracy= 0.70312\n",
      "Iter 76736, Minibatch Loss= 5146.938477, Training Accuracy= 0.73438\n",
      "Iter 76800, Minibatch Loss= 3735.268066, Training Accuracy= 0.73438\n",
      "Iter 76864, Minibatch Loss= 5807.985352, Training Accuracy= 0.75000\n",
      "Iter 76928, Minibatch Loss= 7895.529785, Training Accuracy= 0.68750\n",
      "Iter 76992, Minibatch Loss= 11087.845703, Training Accuracy= 0.65625\n",
      "Iter 77056, Minibatch Loss= 3595.819580, Training Accuracy= 0.89062\n",
      "Iter 77120, Minibatch Loss= 9873.795898, Training Accuracy= 0.59375\n",
      "Iter 77184, Minibatch Loss= 5776.802734, Training Accuracy= 0.75000\n",
      "Iter 77248, Minibatch Loss= 7703.400879, Training Accuracy= 0.68750\n",
      "Iter 77312, Minibatch Loss= 4626.317871, Training Accuracy= 0.71875\n",
      "Iter 77376, Minibatch Loss= 9577.716797, Training Accuracy= 0.65625\n",
      "Iter 77440, Minibatch Loss= 6779.233398, Training Accuracy= 0.68750\n",
      "Iter 77504, Minibatch Loss= 9768.487305, Training Accuracy= 0.64062\n",
      "Iter 77568, Minibatch Loss= 9517.896484, Training Accuracy= 0.57812\n",
      "Iter 77632, Minibatch Loss= 11165.208008, Training Accuracy= 0.65625\n",
      "Iter 77696, Minibatch Loss= 7771.365723, Training Accuracy= 0.65625\n",
      "Iter 77760, Minibatch Loss= 8290.952148, Training Accuracy= 0.64062\n",
      "Iter 77824, Minibatch Loss= 4227.552246, Training Accuracy= 0.76562\n",
      "Iter 77888, Minibatch Loss= 5428.286621, Training Accuracy= 0.73438\n",
      "Iter 77952, Minibatch Loss= 9707.425781, Training Accuracy= 0.56250\n",
      "Iter 78016, Minibatch Loss= 4383.195801, Training Accuracy= 0.71875\n",
      "Iter 78080, Minibatch Loss= 1922.953369, Training Accuracy= 0.82812\n",
      "Iter 78144, Minibatch Loss= 4906.100098, Training Accuracy= 0.71875\n",
      "Iter 78208, Minibatch Loss= 6616.460938, Training Accuracy= 0.70312\n",
      "Iter 78272, Minibatch Loss= 5381.500000, Training Accuracy= 0.71875\n",
      "Iter 78336, Minibatch Loss= 3911.908447, Training Accuracy= 0.68750\n",
      "Iter 78400, Minibatch Loss= 7414.015137, Training Accuracy= 0.73438\n",
      "Iter 78464, Minibatch Loss= 4884.420410, Training Accuracy= 0.75000\n",
      "Iter 78528, Minibatch Loss= 3292.596680, Training Accuracy= 0.76562\n",
      "Iter 78592, Minibatch Loss= 4891.769043, Training Accuracy= 0.78125\n",
      "Iter 78656, Minibatch Loss= 6651.466309, Training Accuracy= 0.70312\n",
      "Iter 78720, Minibatch Loss= 5100.289062, Training Accuracy= 0.68750\n",
      "Iter 78784, Minibatch Loss= 4015.419678, Training Accuracy= 0.73438\n",
      "Iter 78848, Minibatch Loss= 7567.597656, Training Accuracy= 0.60938\n",
      "Iter 78912, Minibatch Loss= 7579.981445, Training Accuracy= 0.62500\n",
      "Iter 78976, Minibatch Loss= 6801.698242, Training Accuracy= 0.59375\n",
      "Iter 79040, Minibatch Loss= 6137.023438, Training Accuracy= 0.64062\n",
      "Iter 79104, Minibatch Loss= 7727.696289, Training Accuracy= 0.71875\n",
      "Iter 79168, Minibatch Loss= 6379.554199, Training Accuracy= 0.71875\n",
      "Iter 79232, Minibatch Loss= 7580.056641, Training Accuracy= 0.60938\n",
      "Iter 79296, Minibatch Loss= 6327.752930, Training Accuracy= 0.76562\n",
      "Iter 79360, Minibatch Loss= 6300.646484, Training Accuracy= 0.64062\n",
      "Iter 79424, Minibatch Loss= 5792.581543, Training Accuracy= 0.68750\n",
      "Iter 79488, Minibatch Loss= 4875.165527, Training Accuracy= 0.71875\n",
      "Iter 79552, Minibatch Loss= 5510.168457, Training Accuracy= 0.67188\n",
      "Iter 79616, Minibatch Loss= 6421.448242, Training Accuracy= 0.65625\n",
      "Iter 79680, Minibatch Loss= 10012.324219, Training Accuracy= 0.67188\n",
      "Iter 79744, Minibatch Loss= 10164.729492, Training Accuracy= 0.65625\n",
      "Iter 79808, Minibatch Loss= 5532.391602, Training Accuracy= 0.76562\n",
      "Iter 79872, Minibatch Loss= 1518.211426, Training Accuracy= 0.84375\n",
      "Iter 79936, Minibatch Loss= 4697.456055, Training Accuracy= 0.73438\n",
      "Iter 80000, Minibatch Loss= 3965.208984, Training Accuracy= 0.73438\n",
      "Iter 80064, Minibatch Loss= 6816.450195, Training Accuracy= 0.64062\n",
      "Iter 80128, Minibatch Loss= 4915.185547, Training Accuracy= 0.70312\n",
      "Iter 80192, Minibatch Loss= 6106.552734, Training Accuracy= 0.76562\n",
      "Iter 80256, Minibatch Loss= 7096.026367, Training Accuracy= 0.76562\n",
      "Iter 80320, Minibatch Loss= 7457.890625, Training Accuracy= 0.64062\n",
      "Iter 80384, Minibatch Loss= 3744.779053, Training Accuracy= 0.76562\n",
      "Iter 80448, Minibatch Loss= 7486.724609, Training Accuracy= 0.54688\n",
      "Iter 80512, Minibatch Loss= 3835.854736, Training Accuracy= 0.75000\n",
      "Iter 80576, Minibatch Loss= 9123.730469, Training Accuracy= 0.70312\n",
      "Iter 80640, Minibatch Loss= 8019.826660, Training Accuracy= 0.68750\n",
      "Iter 80704, Minibatch Loss= 5394.198242, Training Accuracy= 0.70312\n",
      "Iter 80768, Minibatch Loss= 5990.109863, Training Accuracy= 0.68750\n",
      "Iter 80832, Minibatch Loss= 3176.523926, Training Accuracy= 0.82812\n",
      "Iter 80896, Minibatch Loss= 5341.585938, Training Accuracy= 0.70312\n",
      "Iter 80960, Minibatch Loss= 1805.601074, Training Accuracy= 0.79688\n",
      "Iter 81024, Minibatch Loss= 4555.346191, Training Accuracy= 0.68750\n",
      "Iter 81088, Minibatch Loss= 2376.457031, Training Accuracy= 0.79688\n",
      "Iter 81152, Minibatch Loss= 5996.106934, Training Accuracy= 0.65625\n",
      "Iter 81216, Minibatch Loss= 3728.468262, Training Accuracy= 0.71875\n",
      "Iter 81280, Minibatch Loss= 6897.676270, Training Accuracy= 0.70312\n",
      "Iter 81344, Minibatch Loss= 4903.820312, Training Accuracy= 0.68750\n",
      "Iter 81408, Minibatch Loss= 4868.597656, Training Accuracy= 0.76562\n",
      "Iter 81472, Minibatch Loss= 2030.259277, Training Accuracy= 0.85938\n",
      "Iter 81536, Minibatch Loss= 3731.006592, Training Accuracy= 0.87500\n",
      "Iter 81600, Minibatch Loss= 2351.836670, Training Accuracy= 0.84375\n",
      "Iter 81664, Minibatch Loss= 2682.642090, Training Accuracy= 0.81250\n",
      "Iter 81728, Minibatch Loss= 2615.504639, Training Accuracy= 0.78125\n",
      "Iter 81792, Minibatch Loss= 5569.457520, Training Accuracy= 0.67188\n",
      "Iter 81856, Minibatch Loss= 3390.226074, Training Accuracy= 0.75000\n",
      "Iter 81920, Minibatch Loss= 2834.708496, Training Accuracy= 0.67188\n",
      "Iter 81984, Minibatch Loss= 8300.365234, Training Accuracy= 0.68750\n",
      "Iter 82048, Minibatch Loss= 8363.960938, Training Accuracy= 0.78125\n",
      "Iter 82112, Minibatch Loss= 4787.125000, Training Accuracy= 0.75000\n",
      "Iter 82176, Minibatch Loss= 7230.780273, Training Accuracy= 0.67188\n",
      "Iter 82240, Minibatch Loss= 4516.696289, Training Accuracy= 0.71875\n",
      "Iter 82304, Minibatch Loss= 7102.778320, Training Accuracy= 0.70312\n",
      "Iter 82368, Minibatch Loss= 4373.139160, Training Accuracy= 0.76562\n",
      "Iter 82432, Minibatch Loss= 4760.073730, Training Accuracy= 0.70312\n",
      "Iter 82496, Minibatch Loss= 8205.003906, Training Accuracy= 0.67188\n",
      "Iter 82560, Minibatch Loss= 5784.005859, Training Accuracy= 0.79688\n",
      "Iter 82624, Minibatch Loss= 1376.650513, Training Accuracy= 0.85938\n",
      "Iter 82688, Minibatch Loss= 4271.283203, Training Accuracy= 0.70312\n",
      "Iter 82752, Minibatch Loss= 3821.443359, Training Accuracy= 0.73438\n",
      "Iter 82816, Minibatch Loss= 9045.116211, Training Accuracy= 0.60938\n",
      "Iter 82880, Minibatch Loss= 6065.564453, Training Accuracy= 0.75000\n",
      "Iter 82944, Minibatch Loss= 2800.319092, Training Accuracy= 0.76562\n",
      "Iter 83008, Minibatch Loss= 3401.267334, Training Accuracy= 0.81250\n",
      "Iter 83072, Minibatch Loss= 7489.304688, Training Accuracy= 0.65625\n",
      "Iter 83136, Minibatch Loss= 3500.300781, Training Accuracy= 0.73438\n",
      "Iter 83200, Minibatch Loss= 3843.145508, Training Accuracy= 0.75000\n",
      "Iter 83264, Minibatch Loss= 6648.960938, Training Accuracy= 0.67188\n",
      "Iter 83328, Minibatch Loss= 6905.707031, Training Accuracy= 0.73438\n",
      "Iter 83392, Minibatch Loss= 3227.685791, Training Accuracy= 0.75000\n",
      "Iter 83456, Minibatch Loss= 7024.954102, Training Accuracy= 0.68750\n",
      "Iter 83520, Minibatch Loss= 5107.994141, Training Accuracy= 0.65625\n",
      "Iter 83584, Minibatch Loss= 6060.255859, Training Accuracy= 0.71875\n",
      "Iter 83648, Minibatch Loss= 7117.649902, Training Accuracy= 0.68750\n",
      "Iter 83712, Minibatch Loss= 5377.918457, Training Accuracy= 0.68750\n",
      "Iter 83776, Minibatch Loss= 7878.152832, Training Accuracy= 0.62500\n",
      "Iter 83840, Minibatch Loss= 8469.742188, Training Accuracy= 0.65625\n",
      "Iter 83904, Minibatch Loss= 3172.216553, Training Accuracy= 0.76562\n",
      "Iter 83968, Minibatch Loss= 6705.745117, Training Accuracy= 0.70312\n",
      "Iter 84032, Minibatch Loss= 3453.887207, Training Accuracy= 0.78125\n",
      "Iter 84096, Minibatch Loss= 6196.098633, Training Accuracy= 0.64062\n",
      "Iter 84160, Minibatch Loss= 5031.364258, Training Accuracy= 0.76562\n",
      "Iter 84224, Minibatch Loss= 6516.975586, Training Accuracy= 0.76562\n",
      "Iter 84288, Minibatch Loss= 4728.775879, Training Accuracy= 0.65625\n",
      "Iter 84352, Minibatch Loss= 4368.077637, Training Accuracy= 0.67188\n",
      "Iter 84416, Minibatch Loss= 1862.811523, Training Accuracy= 0.76562\n",
      "Iter 84480, Minibatch Loss= 6272.729492, Training Accuracy= 0.70312\n",
      "Iter 84544, Minibatch Loss= 3025.622559, Training Accuracy= 0.79688\n",
      "Iter 84608, Minibatch Loss= 5715.184570, Training Accuracy= 0.67188\n",
      "Iter 84672, Minibatch Loss= 4367.129395, Training Accuracy= 0.73438\n",
      "Iter 84736, Minibatch Loss= 5489.486328, Training Accuracy= 0.75000\n",
      "Iter 84800, Minibatch Loss= 5696.640137, Training Accuracy= 0.73438\n",
      "Iter 84864, Minibatch Loss= 4385.570312, Training Accuracy= 0.70312\n",
      "Iter 84928, Minibatch Loss= 6641.922852, Training Accuracy= 0.67188\n",
      "Iter 84992, Minibatch Loss= 6754.033203, Training Accuracy= 0.67188\n",
      "Iter 85056, Minibatch Loss= 2446.979980, Training Accuracy= 0.78125\n",
      "Iter 85120, Minibatch Loss= 3899.900879, Training Accuracy= 0.73438\n",
      "Iter 85184, Minibatch Loss= 8120.928223, Training Accuracy= 0.71875\n",
      "Iter 85248, Minibatch Loss= 7419.954102, Training Accuracy= 0.70312\n",
      "Iter 85312, Minibatch Loss= 4621.308105, Training Accuracy= 0.75000\n",
      "Iter 85376, Minibatch Loss= 3481.534424, Training Accuracy= 0.78125\n",
      "Iter 85440, Minibatch Loss= 3380.696045, Training Accuracy= 0.68750\n",
      "Iter 85504, Minibatch Loss= 3037.322998, Training Accuracy= 0.81250\n",
      "Iter 85568, Minibatch Loss= 6482.394531, Training Accuracy= 0.68750\n",
      "Iter 85632, Minibatch Loss= 6098.322266, Training Accuracy= 0.67188\n",
      "Iter 85696, Minibatch Loss= 6563.220703, Training Accuracy= 0.65625\n",
      "Iter 85760, Minibatch Loss= 6886.069824, Training Accuracy= 0.67188\n",
      "Iter 85824, Minibatch Loss= 7809.800781, Training Accuracy= 0.68750\n",
      "Iter 85888, Minibatch Loss= 4816.991699, Training Accuracy= 0.71875\n",
      "Iter 85952, Minibatch Loss= 4310.718262, Training Accuracy= 0.73438\n",
      "Iter 86016, Minibatch Loss= 5787.569336, Training Accuracy= 0.65625\n",
      "Iter 86080, Minibatch Loss= 6870.994141, Training Accuracy= 0.70312\n",
      "Iter 86144, Minibatch Loss= 4799.395508, Training Accuracy= 0.62500\n",
      "Iter 86208, Minibatch Loss= 6989.308105, Training Accuracy= 0.60938\n",
      "Iter 86272, Minibatch Loss= 5156.986816, Training Accuracy= 0.71875\n",
      "Iter 86336, Minibatch Loss= 4892.802734, Training Accuracy= 0.67188\n",
      "Iter 86400, Minibatch Loss= 7654.788086, Training Accuracy= 0.73438\n",
      "Iter 86464, Minibatch Loss= 4801.645508, Training Accuracy= 0.73438\n",
      "Iter 86528, Minibatch Loss= 3163.681885, Training Accuracy= 0.73438\n",
      "Iter 86592, Minibatch Loss= 4493.932129, Training Accuracy= 0.64062\n",
      "Iter 86656, Minibatch Loss= 3301.478027, Training Accuracy= 0.68750\n",
      "Iter 86720, Minibatch Loss= 3961.446289, Training Accuracy= 0.75000\n",
      "Iter 86784, Minibatch Loss= 11137.120117, Training Accuracy= 0.68750\n",
      "Iter 86848, Minibatch Loss= 4274.998047, Training Accuracy= 0.68750\n",
      "Iter 86912, Minibatch Loss= 4010.623779, Training Accuracy= 0.75000\n",
      "Iter 86976, Minibatch Loss= 5437.591309, Training Accuracy= 0.67188\n",
      "Iter 87040, Minibatch Loss= 4002.339600, Training Accuracy= 0.75000\n",
      "Iter 87104, Minibatch Loss= 5274.067871, Training Accuracy= 0.67188\n",
      "Iter 87168, Minibatch Loss= 5681.967773, Training Accuracy= 0.78125\n",
      "Iter 87232, Minibatch Loss= 9066.576172, Training Accuracy= 0.62500\n",
      "Iter 87296, Minibatch Loss= 4307.435059, Training Accuracy= 0.67188\n",
      "Iter 87360, Minibatch Loss= 6412.857910, Training Accuracy= 0.67188\n",
      "Iter 87424, Minibatch Loss= 4020.339844, Training Accuracy= 0.71875\n",
      "Iter 87488, Minibatch Loss= 1936.970093, Training Accuracy= 0.84375\n",
      "Iter 87552, Minibatch Loss= 5042.188477, Training Accuracy= 0.60938\n",
      "Iter 87616, Minibatch Loss= 2054.781982, Training Accuracy= 0.78125\n",
      "Iter 87680, Minibatch Loss= 3846.810791, Training Accuracy= 0.73438\n",
      "Iter 87744, Minibatch Loss= 4733.791016, Training Accuracy= 0.62500\n",
      "Iter 87808, Minibatch Loss= 3053.556152, Training Accuracy= 0.81250\n",
      "Iter 87872, Minibatch Loss= 8934.863281, Training Accuracy= 0.65625\n",
      "Iter 87936, Minibatch Loss= 2527.734375, Training Accuracy= 0.76562\n",
      "Iter 88000, Minibatch Loss= 6919.671875, Training Accuracy= 0.68750\n",
      "Iter 88064, Minibatch Loss= 6149.362305, Training Accuracy= 0.68750\n",
      "Iter 88128, Minibatch Loss= 5406.739258, Training Accuracy= 0.70312\n",
      "Iter 88192, Minibatch Loss= 4909.937500, Training Accuracy= 0.68750\n",
      "Iter 88256, Minibatch Loss= 5651.721191, Training Accuracy= 0.73438\n",
      "Iter 88320, Minibatch Loss= 3065.085205, Training Accuracy= 0.79688\n",
      "Iter 88384, Minibatch Loss= 8255.507812, Training Accuracy= 0.57812\n",
      "Iter 88448, Minibatch Loss= 7126.147949, Training Accuracy= 0.73438\n",
      "Iter 88512, Minibatch Loss= 7215.300781, Training Accuracy= 0.62500\n",
      "Iter 88576, Minibatch Loss= 5076.634766, Training Accuracy= 0.76562\n",
      "Iter 88640, Minibatch Loss= 4229.497070, Training Accuracy= 0.67188\n",
      "Iter 88704, Minibatch Loss= 7386.690430, Training Accuracy= 0.64062\n",
      "Iter 88768, Minibatch Loss= 3903.987305, Training Accuracy= 0.71875\n",
      "Iter 88832, Minibatch Loss= 5608.257812, Training Accuracy= 0.68750\n",
      "Iter 88896, Minibatch Loss= 3003.820312, Training Accuracy= 0.79688\n",
      "Iter 88960, Minibatch Loss= 4065.508545, Training Accuracy= 0.68750\n",
      "Iter 89024, Minibatch Loss= 5150.478516, Training Accuracy= 0.62500\n",
      "Iter 89088, Minibatch Loss= 4935.721680, Training Accuracy= 0.73438\n",
      "Iter 89152, Minibatch Loss= 3939.658691, Training Accuracy= 0.76562\n",
      "Iter 89216, Minibatch Loss= 4157.971680, Training Accuracy= 0.81250\n",
      "Iter 89280, Minibatch Loss= 3499.431152, Training Accuracy= 0.75000\n",
      "Iter 89344, Minibatch Loss= 3845.270020, Training Accuracy= 0.71875\n",
      "Iter 89408, Minibatch Loss= 5972.413086, Training Accuracy= 0.70312\n",
      "Iter 89472, Minibatch Loss= 7217.254883, Training Accuracy= 0.64062\n",
      "Iter 89536, Minibatch Loss= 5714.083984, Training Accuracy= 0.70312\n",
      "Iter 89600, Minibatch Loss= 4681.906250, Training Accuracy= 0.68750\n",
      "Iter 89664, Minibatch Loss= 8716.428711, Training Accuracy= 0.59375\n",
      "Iter 89728, Minibatch Loss= 5957.794922, Training Accuracy= 0.59375\n",
      "Iter 89792, Minibatch Loss= 11735.186523, Training Accuracy= 0.59375\n",
      "Iter 89856, Minibatch Loss= 5837.014648, Training Accuracy= 0.76562\n",
      "Iter 89920, Minibatch Loss= 2992.166992, Training Accuracy= 0.82812\n",
      "Iter 89984, Minibatch Loss= 2887.391357, Training Accuracy= 0.71875\n",
      "Iter 90048, Minibatch Loss= 3390.754150, Training Accuracy= 0.73438\n",
      "Iter 90112, Minibatch Loss= 5218.359375, Training Accuracy= 0.64062\n",
      "Iter 90176, Minibatch Loss= 3025.469727, Training Accuracy= 0.78125\n",
      "Iter 90240, Minibatch Loss= 3766.092285, Training Accuracy= 0.76562\n",
      "Iter 90304, Minibatch Loss= 2181.068359, Training Accuracy= 0.76562\n",
      "Iter 90368, Minibatch Loss= 6153.732910, Training Accuracy= 0.73438\n",
      "Iter 90432, Minibatch Loss= 4383.196289, Training Accuracy= 0.76562\n",
      "Iter 90496, Minibatch Loss= 3573.616699, Training Accuracy= 0.73438\n",
      "Iter 90560, Minibatch Loss= 11961.264648, Training Accuracy= 0.51562\n",
      "Iter 90624, Minibatch Loss= 5374.370117, Training Accuracy= 0.73438\n",
      "Iter 90688, Minibatch Loss= 6117.762695, Training Accuracy= 0.68750\n",
      "Iter 90752, Minibatch Loss= 5758.184570, Training Accuracy= 0.76562\n",
      "Iter 90816, Minibatch Loss= 2842.526855, Training Accuracy= 0.78125\n",
      "Iter 90880, Minibatch Loss= 5797.374512, Training Accuracy= 0.60938\n",
      "Iter 90944, Minibatch Loss= 3158.909180, Training Accuracy= 0.78125\n",
      "Iter 91008, Minibatch Loss= 2753.727539, Training Accuracy= 0.75000\n",
      "Iter 91072, Minibatch Loss= 6294.292969, Training Accuracy= 0.71875\n",
      "Iter 91136, Minibatch Loss= 4592.993164, Training Accuracy= 0.70312\n",
      "Iter 91200, Minibatch Loss= 5237.611816, Training Accuracy= 0.71875\n",
      "Iter 91264, Minibatch Loss= 3519.713867, Training Accuracy= 0.79688\n",
      "Iter 91328, Minibatch Loss= 2336.471436, Training Accuracy= 0.79688\n",
      "Iter 91392, Minibatch Loss= 4298.430664, Training Accuracy= 0.75000\n",
      "Iter 91456, Minibatch Loss= 5015.837891, Training Accuracy= 0.75000\n",
      "Iter 91520, Minibatch Loss= 4577.698242, Training Accuracy= 0.73438\n",
      "Iter 91584, Minibatch Loss= 6011.173828, Training Accuracy= 0.62500\n",
      "Iter 91648, Minibatch Loss= 8120.388672, Training Accuracy= 0.65625\n",
      "Iter 91712, Minibatch Loss= 4790.955566, Training Accuracy= 0.70312\n",
      "Iter 91776, Minibatch Loss= 5122.459961, Training Accuracy= 0.70312\n",
      "Iter 91840, Minibatch Loss= 4663.151367, Training Accuracy= 0.70312\n",
      "Iter 91904, Minibatch Loss= 4529.049805, Training Accuracy= 0.71875\n",
      "Iter 91968, Minibatch Loss= 7028.988770, Training Accuracy= 0.67188\n",
      "Iter 92032, Minibatch Loss= 4050.314453, Training Accuracy= 0.70312\n",
      "Iter 92096, Minibatch Loss= 6727.208008, Training Accuracy= 0.68750\n",
      "Iter 92160, Minibatch Loss= 6618.394531, Training Accuracy= 0.64062\n",
      "Iter 92224, Minibatch Loss= 8529.822266, Training Accuracy= 0.65625\n",
      "Iter 92288, Minibatch Loss= 7033.002930, Training Accuracy= 0.75000\n",
      "Iter 92352, Minibatch Loss= 2733.444092, Training Accuracy= 0.78125\n",
      "Iter 92416, Minibatch Loss= 6563.188477, Training Accuracy= 0.70312\n",
      "Iter 92480, Minibatch Loss= 7165.502930, Training Accuracy= 0.70312\n",
      "Iter 92544, Minibatch Loss= 7784.544922, Training Accuracy= 0.56250\n",
      "Iter 92608, Minibatch Loss= 6133.809570, Training Accuracy= 0.62500\n",
      "Iter 92672, Minibatch Loss= 3266.600586, Training Accuracy= 0.79688\n",
      "Iter 92736, Minibatch Loss= 7012.314941, Training Accuracy= 0.68750\n",
      "Iter 92800, Minibatch Loss= 4181.995117, Training Accuracy= 0.70312\n",
      "Iter 92864, Minibatch Loss= 6272.556641, Training Accuracy= 0.65625\n",
      "Iter 92928, Minibatch Loss= 5154.098633, Training Accuracy= 0.64062\n",
      "Iter 92992, Minibatch Loss= 4925.332031, Training Accuracy= 0.75000\n",
      "Iter 93056, Minibatch Loss= 3210.437012, Training Accuracy= 0.79688\n",
      "Iter 93120, Minibatch Loss= 3076.804443, Training Accuracy= 0.68750\n",
      "Iter 93184, Minibatch Loss= 4392.560547, Training Accuracy= 0.70312\n",
      "Iter 93248, Minibatch Loss= 3693.096680, Training Accuracy= 0.68750\n",
      "Iter 93312, Minibatch Loss= 3820.114258, Training Accuracy= 0.73438\n",
      "Iter 93376, Minibatch Loss= 6398.277344, Training Accuracy= 0.70312\n",
      "Iter 93440, Minibatch Loss= 3222.457520, Training Accuracy= 0.76562\n",
      "Iter 93504, Minibatch Loss= 6381.207031, Training Accuracy= 0.62500\n",
      "Iter 93568, Minibatch Loss= 8049.961426, Training Accuracy= 0.65625\n",
      "Iter 93632, Minibatch Loss= 5329.892578, Training Accuracy= 0.65625\n",
      "Iter 93696, Minibatch Loss= 2932.652344, Training Accuracy= 0.76562\n",
      "Iter 93760, Minibatch Loss= 7571.265625, Training Accuracy= 0.64062\n",
      "Iter 93824, Minibatch Loss= 4580.826172, Training Accuracy= 0.75000\n",
      "Iter 93888, Minibatch Loss= 6797.001465, Training Accuracy= 0.64062\n",
      "Iter 93952, Minibatch Loss= 5995.092285, Training Accuracy= 0.64062\n",
      "Iter 94016, Minibatch Loss= 7389.510742, Training Accuracy= 0.68750\n",
      "Iter 94080, Minibatch Loss= 6838.071777, Training Accuracy= 0.64062\n",
      "Iter 94144, Minibatch Loss= 5904.167969, Training Accuracy= 0.68750\n",
      "Iter 94208, Minibatch Loss= 3384.844971, Training Accuracy= 0.70312\n",
      "Iter 94272, Minibatch Loss= 1890.195801, Training Accuracy= 0.70312\n",
      "Iter 94336, Minibatch Loss= 4289.625000, Training Accuracy= 0.65625\n",
      "Iter 94400, Minibatch Loss= 3545.648193, Training Accuracy= 0.73438\n",
      "Iter 94464, Minibatch Loss= 7528.116211, Training Accuracy= 0.62500\n",
      "Iter 94528, Minibatch Loss= 3259.838623, Training Accuracy= 0.81250\n",
      "Iter 94592, Minibatch Loss= 8659.076172, Training Accuracy= 0.60938\n",
      "Iter 94656, Minibatch Loss= 3425.054443, Training Accuracy= 0.79688\n",
      "Iter 94720, Minibatch Loss= 4552.909668, Training Accuracy= 0.68750\n",
      "Iter 94784, Minibatch Loss= 3611.242676, Training Accuracy= 0.75000\n",
      "Iter 94848, Minibatch Loss= 4455.123047, Training Accuracy= 0.62500\n",
      "Iter 94912, Minibatch Loss= 6829.832031, Training Accuracy= 0.64062\n",
      "Iter 94976, Minibatch Loss= 7934.236328, Training Accuracy= 0.64062\n",
      "Iter 95040, Minibatch Loss= 5250.565430, Training Accuracy= 0.70312\n",
      "Iter 95104, Minibatch Loss= 4305.718750, Training Accuracy= 0.68750\n",
      "Iter 95168, Minibatch Loss= 3573.884277, Training Accuracy= 0.78125\n",
      "Iter 95232, Minibatch Loss= 3133.879395, Training Accuracy= 0.71875\n",
      "Iter 95296, Minibatch Loss= 5480.730469, Training Accuracy= 0.73438\n",
      "Iter 95360, Minibatch Loss= 4387.833008, Training Accuracy= 0.76562\n",
      "Iter 95424, Minibatch Loss= 2168.261475, Training Accuracy= 0.82812\n",
      "Iter 95488, Minibatch Loss= 4115.037109, Training Accuracy= 0.76562\n",
      "Iter 95552, Minibatch Loss= 4103.944336, Training Accuracy= 0.71875\n",
      "Iter 95616, Minibatch Loss= 3894.497559, Training Accuracy= 0.75000\n",
      "Iter 95680, Minibatch Loss= 2841.650879, Training Accuracy= 0.76562\n",
      "Iter 95744, Minibatch Loss= 4245.012695, Training Accuracy= 0.68750\n",
      "Iter 95808, Minibatch Loss= 6508.268555, Training Accuracy= 0.71875\n",
      "Iter 95872, Minibatch Loss= 2780.104492, Training Accuracy= 0.79688\n",
      "Iter 95936, Minibatch Loss= 2594.672119, Training Accuracy= 0.76562\n",
      "Iter 96000, Minibatch Loss= 3784.826172, Training Accuracy= 0.75000\n",
      "Iter 96064, Minibatch Loss= 9266.009766, Training Accuracy= 0.57812\n",
      "Iter 96128, Minibatch Loss= 7217.265625, Training Accuracy= 0.71875\n",
      "Iter 96192, Minibatch Loss= 5842.472656, Training Accuracy= 0.68750\n",
      "Iter 96256, Minibatch Loss= 5761.837891, Training Accuracy= 0.70312\n",
      "Iter 96320, Minibatch Loss= 5352.725586, Training Accuracy= 0.60938\n",
      "Iter 96384, Minibatch Loss= 3558.123535, Training Accuracy= 0.75000\n",
      "Iter 96448, Minibatch Loss= 3086.209473, Training Accuracy= 0.71875\n",
      "Iter 96512, Minibatch Loss= 4741.162109, Training Accuracy= 0.67188\n",
      "Iter 96576, Minibatch Loss= 9379.195312, Training Accuracy= 0.59375\n",
      "Iter 96640, Minibatch Loss= 4782.057129, Training Accuracy= 0.73438\n",
      "Iter 96704, Minibatch Loss= 4240.482422, Training Accuracy= 0.73438\n",
      "Iter 96768, Minibatch Loss= 3901.106445, Training Accuracy= 0.73438\n",
      "Iter 96832, Minibatch Loss= 1110.986206, Training Accuracy= 0.82812\n",
      "Iter 96896, Minibatch Loss= 2295.323730, Training Accuracy= 0.82812\n",
      "Iter 96960, Minibatch Loss= 3928.479492, Training Accuracy= 0.71875\n",
      "Iter 97024, Minibatch Loss= 3663.441406, Training Accuracy= 0.71875\n",
      "Iter 97088, Minibatch Loss= 6227.264648, Training Accuracy= 0.67188\n",
      "Iter 97152, Minibatch Loss= 7238.220703, Training Accuracy= 0.60938\n",
      "Iter 97216, Minibatch Loss= 3762.311035, Training Accuracy= 0.76562\n",
      "Iter 97280, Minibatch Loss= 4368.796387, Training Accuracy= 0.76562\n",
      "Iter 97344, Minibatch Loss= 5772.063477, Training Accuracy= 0.62500\n",
      "Iter 97408, Minibatch Loss= 3835.751465, Training Accuracy= 0.75000\n",
      "Iter 97472, Minibatch Loss= 3057.256592, Training Accuracy= 0.75000\n",
      "Iter 97536, Minibatch Loss= 8711.191406, Training Accuracy= 0.60938\n",
      "Iter 97600, Minibatch Loss= 3420.961914, Training Accuracy= 0.73438\n",
      "Iter 97664, Minibatch Loss= 7092.384766, Training Accuracy= 0.65625\n",
      "Iter 97728, Minibatch Loss= 6114.921875, Training Accuracy= 0.62500\n",
      "Iter 97792, Minibatch Loss= 4379.535645, Training Accuracy= 0.70312\n",
      "Iter 97856, Minibatch Loss= 6168.559570, Training Accuracy= 0.76562\n",
      "Iter 97920, Minibatch Loss= 5929.458008, Training Accuracy= 0.73438\n",
      "Iter 97984, Minibatch Loss= 5460.897461, Training Accuracy= 0.65625\n",
      "Iter 98048, Minibatch Loss= 5663.616211, Training Accuracy= 0.70312\n",
      "Iter 98112, Minibatch Loss= 3767.250488, Training Accuracy= 0.79688\n",
      "Iter 98176, Minibatch Loss= 3974.948486, Training Accuracy= 0.81250\n",
      "Iter 98240, Minibatch Loss= 4287.357910, Training Accuracy= 0.67188\n",
      "Iter 98304, Minibatch Loss= 4502.881836, Training Accuracy= 0.67188\n",
      "Iter 98368, Minibatch Loss= 5822.415039, Training Accuracy= 0.65625\n",
      "Iter 98432, Minibatch Loss= 7485.816406, Training Accuracy= 0.64062\n",
      "Iter 98496, Minibatch Loss= 8545.642578, Training Accuracy= 0.67188\n",
      "Iter 98560, Minibatch Loss= 6287.391602, Training Accuracy= 0.57812\n",
      "Iter 98624, Minibatch Loss= 5754.228027, Training Accuracy= 0.60938\n",
      "Iter 98688, Minibatch Loss= 5640.557129, Training Accuracy= 0.62500\n",
      "Iter 98752, Minibatch Loss= 4962.750977, Training Accuracy= 0.67188\n",
      "Iter 98816, Minibatch Loss= 6355.677246, Training Accuracy= 0.64062\n",
      "Iter 98880, Minibatch Loss= 6476.793457, Training Accuracy= 0.71875\n",
      "Iter 98944, Minibatch Loss= 7119.568359, Training Accuracy= 0.68750\n",
      "Iter 99008, Minibatch Loss= 4492.283203, Training Accuracy= 0.68750\n",
      "Iter 99072, Minibatch Loss= 7502.891113, Training Accuracy= 0.68750\n",
      "Iter 99136, Minibatch Loss= 5748.304199, Training Accuracy= 0.64062\n",
      "Iter 99200, Minibatch Loss= 5945.458008, Training Accuracy= 0.67188\n",
      "Iter 99264, Minibatch Loss= 8378.648438, Training Accuracy= 0.65625\n",
      "Iter 99328, Minibatch Loss= 4755.961914, Training Accuracy= 0.71875\n",
      "Iter 99392, Minibatch Loss= 7056.263672, Training Accuracy= 0.62500\n",
      "Iter 99456, Minibatch Loss= 3014.126221, Training Accuracy= 0.71875\n",
      "Iter 99520, Minibatch Loss= 6030.845215, Training Accuracy= 0.67188\n",
      "Iter 99584, Minibatch Loss= 3292.821777, Training Accuracy= 0.70312\n",
      "Iter 99648, Minibatch Loss= 4991.358887, Training Accuracy= 0.70312\n",
      "Iter 99712, Minibatch Loss= 4287.807617, Training Accuracy= 0.75000\n",
      "Iter 99776, Minibatch Loss= 3340.623535, Training Accuracy= 0.68750\n",
      "Iter 99840, Minibatch Loss= 5831.206055, Training Accuracy= 0.71875\n",
      "Iter 99904, Minibatch Loss= 5335.842773, Training Accuracy= 0.78125\n",
      "Iter 99968, Minibatch Loss= 4040.693848, Training Accuracy= 0.64062\n",
      "Iter 100032, Minibatch Loss= 6633.934570, Training Accuracy= 0.62500\n",
      "Iter 100096, Minibatch Loss= 4610.414062, Training Accuracy= 0.67188\n",
      "Iter 100160, Minibatch Loss= 3964.987793, Training Accuracy= 0.71875\n",
      "Iter 100224, Minibatch Loss= 4195.291992, Training Accuracy= 0.70312\n",
      "Iter 100288, Minibatch Loss= 5660.321289, Training Accuracy= 0.67188\n",
      "Iter 100352, Minibatch Loss= 5196.767578, Training Accuracy= 0.67188\n",
      "Iter 100416, Minibatch Loss= 7307.125000, Training Accuracy= 0.59375\n",
      "Iter 100480, Minibatch Loss= 4569.429688, Training Accuracy= 0.73438\n",
      "Iter 100544, Minibatch Loss= 3696.461426, Training Accuracy= 0.71875\n",
      "Iter 100608, Minibatch Loss= 5532.394043, Training Accuracy= 0.73438\n",
      "Iter 100672, Minibatch Loss= 4395.639648, Training Accuracy= 0.68750\n",
      "Iter 100736, Minibatch Loss= 9672.370117, Training Accuracy= 0.64062\n",
      "Iter 100800, Minibatch Loss= 6988.946289, Training Accuracy= 0.60938\n",
      "Iter 100864, Minibatch Loss= 6641.291504, Training Accuracy= 0.70312\n",
      "Iter 100928, Minibatch Loss= 6753.163574, Training Accuracy= 0.71875\n",
      "Iter 100992, Minibatch Loss= 7089.742188, Training Accuracy= 0.71875\n",
      "Iter 101056, Minibatch Loss= 5173.931641, Training Accuracy= 0.70312\n",
      "Iter 101120, Minibatch Loss= 5443.929199, Training Accuracy= 0.62500\n",
      "Iter 101184, Minibatch Loss= 4535.250977, Training Accuracy= 0.67188\n",
      "Iter 101248, Minibatch Loss= 4806.547852, Training Accuracy= 0.79688\n",
      "Iter 101312, Minibatch Loss= 7193.528809, Training Accuracy= 0.65625\n",
      "Iter 101376, Minibatch Loss= 5527.012695, Training Accuracy= 0.71875\n",
      "Iter 101440, Minibatch Loss= 4303.207031, Training Accuracy= 0.68750\n",
      "Iter 101504, Minibatch Loss= 5994.758789, Training Accuracy= 0.68750\n",
      "Iter 101568, Minibatch Loss= 7599.836914, Training Accuracy= 0.62500\n",
      "Iter 101632, Minibatch Loss= 4837.044434, Training Accuracy= 0.71875\n",
      "Iter 101696, Minibatch Loss= 4123.187012, Training Accuracy= 0.70312\n",
      "Iter 101760, Minibatch Loss= 5011.866211, Training Accuracy= 0.70312\n",
      "Iter 101824, Minibatch Loss= 5639.695312, Training Accuracy= 0.62500\n",
      "Iter 101888, Minibatch Loss= 6195.250000, Training Accuracy= 0.71875\n",
      "Iter 101952, Minibatch Loss= 5080.761719, Training Accuracy= 0.70312\n",
      "Iter 102016, Minibatch Loss= 5341.649414, Training Accuracy= 0.70312\n",
      "Iter 102080, Minibatch Loss= 6318.888672, Training Accuracy= 0.68750\n",
      "Iter 102144, Minibatch Loss= 4665.366699, Training Accuracy= 0.75000\n",
      "Iter 102208, Minibatch Loss= 9059.382812, Training Accuracy= 0.62500\n",
      "Iter 102272, Minibatch Loss= 4172.845703, Training Accuracy= 0.71875\n",
      "Iter 102336, Minibatch Loss= 4071.623779, Training Accuracy= 0.73438\n",
      "Iter 102400, Minibatch Loss= 4708.098633, Training Accuracy= 0.75000\n",
      "Iter 102464, Minibatch Loss= 5268.075195, Training Accuracy= 0.75000\n",
      "Iter 102528, Minibatch Loss= 3675.859131, Training Accuracy= 0.78125\n",
      "Iter 102592, Minibatch Loss= 1913.633667, Training Accuracy= 0.73438\n",
      "Iter 102656, Minibatch Loss= 4668.288574, Training Accuracy= 0.68750\n",
      "Iter 102720, Minibatch Loss= 3076.652344, Training Accuracy= 0.71875\n",
      "Iter 102784, Minibatch Loss= 5354.280273, Training Accuracy= 0.68750\n",
      "Iter 102848, Minibatch Loss= 2298.299316, Training Accuracy= 0.73438\n",
      "Iter 102912, Minibatch Loss= 6001.467773, Training Accuracy= 0.70312\n",
      "Iter 102976, Minibatch Loss= 2326.129395, Training Accuracy= 0.75000\n",
      "Iter 103040, Minibatch Loss= 2883.605713, Training Accuracy= 0.70312\n",
      "Iter 103104, Minibatch Loss= 2842.605469, Training Accuracy= 0.70312\n",
      "Iter 103168, Minibatch Loss= 4333.752930, Training Accuracy= 0.73438\n",
      "Iter 103232, Minibatch Loss= 5782.744141, Training Accuracy= 0.70312\n",
      "Iter 103296, Minibatch Loss= 4535.176758, Training Accuracy= 0.71875\n",
      "Iter 103360, Minibatch Loss= 4926.332031, Training Accuracy= 0.67188\n",
      "Iter 103424, Minibatch Loss= 4614.361328, Training Accuracy= 0.71875\n",
      "Iter 103488, Minibatch Loss= 7400.104980, Training Accuracy= 0.65625\n",
      "Iter 103552, Minibatch Loss= 7220.041992, Training Accuracy= 0.62500\n",
      "Iter 103616, Minibatch Loss= 3725.250488, Training Accuracy= 0.73438\n",
      "Iter 103680, Minibatch Loss= 4251.603027, Training Accuracy= 0.75000\n",
      "Iter 103744, Minibatch Loss= 4416.006836, Training Accuracy= 0.56250\n",
      "Iter 103808, Minibatch Loss= 4912.270020, Training Accuracy= 0.73438\n",
      "Iter 103872, Minibatch Loss= 5410.863281, Training Accuracy= 0.70312\n",
      "Iter 103936, Minibatch Loss= 3438.281982, Training Accuracy= 0.67188\n",
      "Iter 104000, Minibatch Loss= 3823.803711, Training Accuracy= 0.73438\n",
      "Iter 104064, Minibatch Loss= 3839.708008, Training Accuracy= 0.70312\n",
      "Iter 104128, Minibatch Loss= 4412.203613, Training Accuracy= 0.67188\n",
      "Iter 104192, Minibatch Loss= 5335.510742, Training Accuracy= 0.59375\n",
      "Iter 104256, Minibatch Loss= 8057.105469, Training Accuracy= 0.54688\n",
      "Iter 104320, Minibatch Loss= 5598.416992, Training Accuracy= 0.67188\n",
      "Iter 104384, Minibatch Loss= 4358.178711, Training Accuracy= 0.70312\n",
      "Iter 104448, Minibatch Loss= 8796.310547, Training Accuracy= 0.54688\n",
      "Iter 104512, Minibatch Loss= 4857.672363, Training Accuracy= 0.71875\n",
      "Iter 104576, Minibatch Loss= 5263.801270, Training Accuracy= 0.78125\n",
      "Iter 104640, Minibatch Loss= 5856.880859, Training Accuracy= 0.70312\n",
      "Iter 104704, Minibatch Loss= 3708.229492, Training Accuracy= 0.71875\n",
      "Iter 104768, Minibatch Loss= 3997.560791, Training Accuracy= 0.75000\n",
      "Iter 104832, Minibatch Loss= 5600.644531, Training Accuracy= 0.70312\n",
      "Iter 104896, Minibatch Loss= 6175.054199, Training Accuracy= 0.73438\n",
      "Iter 104960, Minibatch Loss= 3680.228027, Training Accuracy= 0.75000\n",
      "Iter 105024, Minibatch Loss= 4992.384277, Training Accuracy= 0.71875\n",
      "Iter 105088, Minibatch Loss= 4031.129150, Training Accuracy= 0.68750\n",
      "Iter 105152, Minibatch Loss= 3306.403320, Training Accuracy= 0.78125\n",
      "Iter 105216, Minibatch Loss= 4602.533203, Training Accuracy= 0.68750\n",
      "Iter 105280, Minibatch Loss= 5345.438477, Training Accuracy= 0.71875\n",
      "Iter 105344, Minibatch Loss= 5325.591797, Training Accuracy= 0.70312\n",
      "Iter 105408, Minibatch Loss= 6603.113281, Training Accuracy= 0.64062\n",
      "Iter 105472, Minibatch Loss= 5999.361328, Training Accuracy= 0.73438\n",
      "Iter 105536, Minibatch Loss= 4886.367676, Training Accuracy= 0.75000\n",
      "Iter 105600, Minibatch Loss= 3782.916260, Training Accuracy= 0.76562\n",
      "Iter 105664, Minibatch Loss= 7013.727051, Training Accuracy= 0.68750\n",
      "Iter 105728, Minibatch Loss= 4735.027344, Training Accuracy= 0.70312\n",
      "Iter 105792, Minibatch Loss= 2382.952881, Training Accuracy= 0.76562\n",
      "Iter 105856, Minibatch Loss= 5624.299316, Training Accuracy= 0.75000\n",
      "Iter 105920, Minibatch Loss= 3795.624512, Training Accuracy= 0.76562\n",
      "Iter 105984, Minibatch Loss= 4907.605957, Training Accuracy= 0.75000\n",
      "Iter 106048, Minibatch Loss= 3237.043457, Training Accuracy= 0.81250\n",
      "Iter 106112, Minibatch Loss= 2909.180664, Training Accuracy= 0.78125\n",
      "Iter 106176, Minibatch Loss= 7395.796387, Training Accuracy= 0.65625\n",
      "Iter 106240, Minibatch Loss= 5423.000488, Training Accuracy= 0.67188\n",
      "Iter 106304, Minibatch Loss= 4812.124023, Training Accuracy= 0.79688\n",
      "Iter 106368, Minibatch Loss= 4377.389648, Training Accuracy= 0.65625\n",
      "Iter 106432, Minibatch Loss= 3636.356934, Training Accuracy= 0.67188\n",
      "Iter 106496, Minibatch Loss= 6177.060547, Training Accuracy= 0.68750\n",
      "Iter 106560, Minibatch Loss= 6618.948242, Training Accuracy= 0.65625\n",
      "Iter 106624, Minibatch Loss= 4297.228027, Training Accuracy= 0.70312\n",
      "Iter 106688, Minibatch Loss= 5391.139160, Training Accuracy= 0.68750\n",
      "Iter 106752, Minibatch Loss= 2252.159180, Training Accuracy= 0.67188\n",
      "Iter 106816, Minibatch Loss= 4052.472168, Training Accuracy= 0.78125\n",
      "Iter 106880, Minibatch Loss= 3662.645508, Training Accuracy= 0.79688\n",
      "Iter 106944, Minibatch Loss= 4504.462402, Training Accuracy= 0.67188\n",
      "Iter 107008, Minibatch Loss= 3842.613770, Training Accuracy= 0.73438\n",
      "Iter 107072, Minibatch Loss= 4120.425293, Training Accuracy= 0.79688\n",
      "Iter 107136, Minibatch Loss= 5156.624023, Training Accuracy= 0.64062\n",
      "Iter 107200, Minibatch Loss= 3441.632324, Training Accuracy= 0.76562\n",
      "Iter 107264, Minibatch Loss= 4300.017578, Training Accuracy= 0.67188\n",
      "Iter 107328, Minibatch Loss= 5743.733887, Training Accuracy= 0.64062\n",
      "Iter 107392, Minibatch Loss= 7816.821289, Training Accuracy= 0.56250\n",
      "Iter 107456, Minibatch Loss= 3055.278564, Training Accuracy= 0.73438\n",
      "Iter 107520, Minibatch Loss= 3627.153809, Training Accuracy= 0.78125\n",
      "Iter 107584, Minibatch Loss= 6393.370605, Training Accuracy= 0.64062\n",
      "Iter 107648, Minibatch Loss= 3804.354980, Training Accuracy= 0.73438\n",
      "Iter 107712, Minibatch Loss= 2902.946045, Training Accuracy= 0.82812\n",
      "Iter 107776, Minibatch Loss= 8502.888672, Training Accuracy= 0.53125\n",
      "Iter 107840, Minibatch Loss= 3379.458496, Training Accuracy= 0.79688\n",
      "Iter 107904, Minibatch Loss= 2274.898193, Training Accuracy= 0.76562\n",
      "Iter 107968, Minibatch Loss= 3771.022705, Training Accuracy= 0.60938\n",
      "Iter 108032, Minibatch Loss= 5743.081055, Training Accuracy= 0.76562\n",
      "Iter 108096, Minibatch Loss= 4809.337891, Training Accuracy= 0.68750\n",
      "Iter 108160, Minibatch Loss= 3743.150635, Training Accuracy= 0.68750\n",
      "Iter 108224, Minibatch Loss= 3535.317627, Training Accuracy= 0.64062\n",
      "Iter 108288, Minibatch Loss= 5092.981445, Training Accuracy= 0.71875\n",
      "Iter 108352, Minibatch Loss= 4774.171875, Training Accuracy= 0.70312\n",
      "Iter 108416, Minibatch Loss= 4566.308105, Training Accuracy= 0.65625\n",
      "Iter 108480, Minibatch Loss= 4930.341797, Training Accuracy= 0.64062\n",
      "Iter 108544, Minibatch Loss= 4701.398926, Training Accuracy= 0.60938\n",
      "Iter 108608, Minibatch Loss= 5424.399414, Training Accuracy= 0.67188\n",
      "Iter 108672, Minibatch Loss= 3436.692383, Training Accuracy= 0.70312\n",
      "Iter 108736, Minibatch Loss= 7601.629883, Training Accuracy= 0.62500\n",
      "Iter 108800, Minibatch Loss= 4945.890137, Training Accuracy= 0.65625\n",
      "Iter 108864, Minibatch Loss= 4840.632812, Training Accuracy= 0.70312\n",
      "Iter 108928, Minibatch Loss= 5981.094238, Training Accuracy= 0.67188\n",
      "Iter 108992, Minibatch Loss= 3774.124512, Training Accuracy= 0.70312\n",
      "Iter 109056, Minibatch Loss= 8759.281250, Training Accuracy= 0.59375\n",
      "Iter 109120, Minibatch Loss= 4497.495117, Training Accuracy= 0.64062\n",
      "Iter 109184, Minibatch Loss= 3517.162109, Training Accuracy= 0.73438\n",
      "Iter 109248, Minibatch Loss= 4958.569336, Training Accuracy= 0.60938\n",
      "Iter 109312, Minibatch Loss= 6388.133301, Training Accuracy= 0.67188\n",
      "Iter 109376, Minibatch Loss= 5245.179688, Training Accuracy= 0.67188\n",
      "Iter 109440, Minibatch Loss= 2011.610718, Training Accuracy= 0.73438\n",
      "Iter 109504, Minibatch Loss= 5399.229492, Training Accuracy= 0.71875\n",
      "Iter 109568, Minibatch Loss= 2482.920654, Training Accuracy= 0.71875\n",
      "Iter 109632, Minibatch Loss= 8827.379883, Training Accuracy= 0.64062\n",
      "Iter 109696, Minibatch Loss= 8615.670898, Training Accuracy= 0.59375\n",
      "Iter 109760, Minibatch Loss= 4255.568359, Training Accuracy= 0.65625\n",
      "Iter 109824, Minibatch Loss= 3296.064941, Training Accuracy= 0.71875\n",
      "Iter 109888, Minibatch Loss= 7262.927734, Training Accuracy= 0.50000\n",
      "Iter 109952, Minibatch Loss= 2002.346680, Training Accuracy= 0.82812\n",
      "Iter 110016, Minibatch Loss= 4691.111816, Training Accuracy= 0.62500\n",
      "Iter 110080, Minibatch Loss= 4175.395508, Training Accuracy= 0.64062\n",
      "Iter 110144, Minibatch Loss= 7771.334961, Training Accuracy= 0.65625\n",
      "Iter 110208, Minibatch Loss= 5739.208984, Training Accuracy= 0.78125\n",
      "Iter 110272, Minibatch Loss= 7012.426270, Training Accuracy= 0.64062\n",
      "Iter 110336, Minibatch Loss= 5345.378906, Training Accuracy= 0.65625\n",
      "Iter 110400, Minibatch Loss= 4717.624023, Training Accuracy= 0.67188\n",
      "Iter 110464, Minibatch Loss= 4670.653320, Training Accuracy= 0.65625\n",
      "Iter 110528, Minibatch Loss= 2635.484375, Training Accuracy= 0.75000\n",
      "Iter 110592, Minibatch Loss= 4818.823730, Training Accuracy= 0.64062\n",
      "Iter 110656, Minibatch Loss= 3246.415527, Training Accuracy= 0.67188\n",
      "Iter 110720, Minibatch Loss= 6458.201172, Training Accuracy= 0.57812\n",
      "Iter 110784, Minibatch Loss= 1766.370117, Training Accuracy= 0.75000\n",
      "Iter 110848, Minibatch Loss= 6254.129883, Training Accuracy= 0.62500\n",
      "Iter 110912, Minibatch Loss= 4333.982422, Training Accuracy= 0.71875\n",
      "Iter 110976, Minibatch Loss= 4570.157227, Training Accuracy= 0.67188\n",
      "Iter 111040, Minibatch Loss= 4343.266602, Training Accuracy= 0.73438\n",
      "Iter 111104, Minibatch Loss= 4146.377930, Training Accuracy= 0.62500\n",
      "Iter 111168, Minibatch Loss= 3465.951172, Training Accuracy= 0.70312\n",
      "Iter 111232, Minibatch Loss= 1376.086670, Training Accuracy= 0.81250\n",
      "Iter 111296, Minibatch Loss= 5432.458984, Training Accuracy= 0.59375\n",
      "Iter 111360, Minibatch Loss= 4244.812500, Training Accuracy= 0.64062\n",
      "Iter 111424, Minibatch Loss= 3648.137939, Training Accuracy= 0.75000\n",
      "Iter 111488, Minibatch Loss= 2840.792236, Training Accuracy= 0.76562\n",
      "Iter 111552, Minibatch Loss= 4089.758789, Training Accuracy= 0.64062\n",
      "Iter 111616, Minibatch Loss= 3993.414795, Training Accuracy= 0.67188\n",
      "Iter 111680, Minibatch Loss= 5392.031738, Training Accuracy= 0.62500\n",
      "Iter 111744, Minibatch Loss= 2860.367920, Training Accuracy= 0.75000\n",
      "Iter 111808, Minibatch Loss= 3370.483398, Training Accuracy= 0.76562\n",
      "Iter 111872, Minibatch Loss= 4400.770508, Training Accuracy= 0.71875\n",
      "Iter 111936, Minibatch Loss= 3885.029297, Training Accuracy= 0.76562\n",
      "Iter 112000, Minibatch Loss= 3580.477051, Training Accuracy= 0.67188\n",
      "Iter 112064, Minibatch Loss= 4632.439941, Training Accuracy= 0.70312\n",
      "Iter 112128, Minibatch Loss= 5389.443359, Training Accuracy= 0.78125\n",
      "Iter 112192, Minibatch Loss= 6306.532715, Training Accuracy= 0.64062\n",
      "Iter 112256, Minibatch Loss= 3130.718750, Training Accuracy= 0.71875\n",
      "Iter 112320, Minibatch Loss= 4847.755859, Training Accuracy= 0.62500\n",
      "Iter 112384, Minibatch Loss= 2350.538574, Training Accuracy= 0.79688\n",
      "Iter 112448, Minibatch Loss= 1974.474854, Training Accuracy= 0.75000\n",
      "Iter 112512, Minibatch Loss= 4668.015137, Training Accuracy= 0.68750\n",
      "Iter 112576, Minibatch Loss= 3275.877197, Training Accuracy= 0.76562\n",
      "Iter 112640, Minibatch Loss= 3504.422119, Training Accuracy= 0.71875\n",
      "Iter 112704, Minibatch Loss= 5165.633789, Training Accuracy= 0.78125\n",
      "Iter 112768, Minibatch Loss= 5846.210938, Training Accuracy= 0.71875\n",
      "Iter 112832, Minibatch Loss= 3729.008545, Training Accuracy= 0.73438\n",
      "Iter 112896, Minibatch Loss= 2793.654541, Training Accuracy= 0.78125\n",
      "Iter 112960, Minibatch Loss= 4131.895508, Training Accuracy= 0.75000\n",
      "Iter 113024, Minibatch Loss= 1727.373657, Training Accuracy= 0.78125\n",
      "Iter 113088, Minibatch Loss= 6012.102539, Training Accuracy= 0.64062\n",
      "Iter 113152, Minibatch Loss= 3246.718750, Training Accuracy= 0.76562\n",
      "Iter 113216, Minibatch Loss= 4607.560059, Training Accuracy= 0.82812\n",
      "Iter 113280, Minibatch Loss= 3002.535400, Training Accuracy= 0.71875\n",
      "Iter 113344, Minibatch Loss= 2918.219727, Training Accuracy= 0.81250\n",
      "Iter 113408, Minibatch Loss= 3756.119629, Training Accuracy= 0.70312\n",
      "Iter 113472, Minibatch Loss= 8998.550781, Training Accuracy= 0.51562\n",
      "Iter 113536, Minibatch Loss= 3674.139160, Training Accuracy= 0.78125\n",
      "Iter 113600, Minibatch Loss= 5793.521973, Training Accuracy= 0.71875\n",
      "Iter 113664, Minibatch Loss= 3932.466797, Training Accuracy= 0.70312\n",
      "Iter 113728, Minibatch Loss= 4086.526367, Training Accuracy= 0.71875\n",
      "Iter 113792, Minibatch Loss= 2768.682373, Training Accuracy= 0.75000\n",
      "Iter 113856, Minibatch Loss= 3584.779785, Training Accuracy= 0.81250\n",
      "Iter 113920, Minibatch Loss= 3271.995117, Training Accuracy= 0.73438\n",
      "Iter 113984, Minibatch Loss= 4089.010742, Training Accuracy= 0.68750\n",
      "Iter 114048, Minibatch Loss= 4862.747559, Training Accuracy= 0.71875\n",
      "Iter 114112, Minibatch Loss= 4612.847656, Training Accuracy= 0.68750\n",
      "Iter 114176, Minibatch Loss= 6049.783203, Training Accuracy= 0.62500\n",
      "Iter 114240, Minibatch Loss= 4334.736328, Training Accuracy= 0.59375\n",
      "Iter 114304, Minibatch Loss= 4377.955078, Training Accuracy= 0.68750\n",
      "Iter 114368, Minibatch Loss= 4170.087891, Training Accuracy= 0.65625\n",
      "Iter 114432, Minibatch Loss= 3689.442383, Training Accuracy= 0.79688\n",
      "Iter 114496, Minibatch Loss= 4781.785645, Training Accuracy= 0.76562\n",
      "Iter 114560, Minibatch Loss= 3519.165527, Training Accuracy= 0.70312\n",
      "Iter 114624, Minibatch Loss= 6560.308594, Training Accuracy= 0.64062\n",
      "Iter 114688, Minibatch Loss= 6889.889648, Training Accuracy= 0.53125\n",
      "Iter 114752, Minibatch Loss= 4481.460938, Training Accuracy= 0.65625\n",
      "Iter 114816, Minibatch Loss= 4304.763672, Training Accuracy= 0.73438\n",
      "Iter 114880, Minibatch Loss= 3948.932129, Training Accuracy= 0.73438\n",
      "Iter 114944, Minibatch Loss= 2752.886230, Training Accuracy= 0.87500\n",
      "Iter 115008, Minibatch Loss= 3656.501465, Training Accuracy= 0.73438\n",
      "Iter 115072, Minibatch Loss= 3046.140625, Training Accuracy= 0.81250\n",
      "Iter 115136, Minibatch Loss= 2060.102051, Training Accuracy= 0.75000\n",
      "Iter 115200, Minibatch Loss= 1066.276367, Training Accuracy= 0.82812\n",
      "Iter 115264, Minibatch Loss= 2799.241455, Training Accuracy= 0.79688\n",
      "Iter 115328, Minibatch Loss= 4206.780273, Training Accuracy= 0.75000\n",
      "Iter 115392, Minibatch Loss= 2026.695312, Training Accuracy= 0.76562\n",
      "Iter 115456, Minibatch Loss= 1786.766113, Training Accuracy= 0.71875\n",
      "Iter 115520, Minibatch Loss= 4361.654785, Training Accuracy= 0.71875\n",
      "Iter 115584, Minibatch Loss= 3052.463867, Training Accuracy= 0.81250\n",
      "Iter 115648, Minibatch Loss= 1920.324219, Training Accuracy= 0.78125\n",
      "Iter 115712, Minibatch Loss= 3705.065918, Training Accuracy= 0.75000\n",
      "Iter 115776, Minibatch Loss= 3572.631348, Training Accuracy= 0.81250\n",
      "Iter 115840, Minibatch Loss= 3908.664307, Training Accuracy= 0.70312\n",
      "Iter 115904, Minibatch Loss= 3466.454834, Training Accuracy= 0.71875\n",
      "Iter 115968, Minibatch Loss= 3109.461914, Training Accuracy= 0.76562\n",
      "Iter 116032, Minibatch Loss= 5894.780273, Training Accuracy= 0.67188\n",
      "Iter 116096, Minibatch Loss= 4515.380859, Training Accuracy= 0.73438\n",
      "Iter 116160, Minibatch Loss= 6264.241699, Training Accuracy= 0.68750\n",
      "Iter 116224, Minibatch Loss= 3298.971680, Training Accuracy= 0.76562\n",
      "Iter 116288, Minibatch Loss= 2979.989258, Training Accuracy= 0.76562\n",
      "Iter 116352, Minibatch Loss= 5115.320312, Training Accuracy= 0.75000\n",
      "Iter 116416, Minibatch Loss= 5115.350586, Training Accuracy= 0.70312\n",
      "Iter 116480, Minibatch Loss= 6655.341797, Training Accuracy= 0.59375\n",
      "Iter 116544, Minibatch Loss= 4382.615723, Training Accuracy= 0.70312\n",
      "Iter 116608, Minibatch Loss= 11301.675781, Training Accuracy= 0.54688\n",
      "Iter 116672, Minibatch Loss= 4301.601562, Training Accuracy= 0.70312\n",
      "Iter 116736, Minibatch Loss= 3207.043945, Training Accuracy= 0.70312\n",
      "Iter 116800, Minibatch Loss= 4558.980469, Training Accuracy= 0.71875\n",
      "Iter 116864, Minibatch Loss= 5416.005859, Training Accuracy= 0.68750\n",
      "Iter 116928, Minibatch Loss= 4854.031250, Training Accuracy= 0.76562\n",
      "Iter 116992, Minibatch Loss= 3151.929443, Training Accuracy= 0.76562\n",
      "Iter 117056, Minibatch Loss= 6671.618652, Training Accuracy= 0.67188\n",
      "Iter 117120, Minibatch Loss= 4886.296875, Training Accuracy= 0.67188\n",
      "Iter 117184, Minibatch Loss= 4277.883301, Training Accuracy= 0.67188\n",
      "Iter 117248, Minibatch Loss= 5520.715820, Training Accuracy= 0.71875\n",
      "Iter 117312, Minibatch Loss= 5169.422363, Training Accuracy= 0.62500\n",
      "Iter 117376, Minibatch Loss= 5666.283203, Training Accuracy= 0.62500\n",
      "Iter 117440, Minibatch Loss= 6053.931641, Training Accuracy= 0.70312\n",
      "Iter 117504, Minibatch Loss= 5631.831055, Training Accuracy= 0.78125\n",
      "Iter 117568, Minibatch Loss= 4061.672852, Training Accuracy= 0.73438\n",
      "Iter 117632, Minibatch Loss= 3739.614990, Training Accuracy= 0.67188\n",
      "Iter 117696, Minibatch Loss= 7934.460938, Training Accuracy= 0.71875\n",
      "Iter 117760, Minibatch Loss= 1423.975708, Training Accuracy= 0.76562\n",
      "Iter 117824, Minibatch Loss= 5459.655273, Training Accuracy= 0.68750\n",
      "Iter 117888, Minibatch Loss= 4811.548828, Training Accuracy= 0.68750\n",
      "Iter 117952, Minibatch Loss= 4941.953125, Training Accuracy= 0.67188\n",
      "Iter 118016, Minibatch Loss= 4580.345703, Training Accuracy= 0.70312\n",
      "Iter 118080, Minibatch Loss= 4664.753906, Training Accuracy= 0.75000\n",
      "Iter 118144, Minibatch Loss= 3685.894287, Training Accuracy= 0.68750\n",
      "Iter 118208, Minibatch Loss= 3439.981689, Training Accuracy= 0.71875\n",
      "Iter 118272, Minibatch Loss= 4156.667969, Training Accuracy= 0.70312\n",
      "Iter 118336, Minibatch Loss= 3113.943115, Training Accuracy= 0.68750\n",
      "Iter 118400, Minibatch Loss= 3395.334961, Training Accuracy= 0.71875\n",
      "Iter 118464, Minibatch Loss= 3040.882568, Training Accuracy= 0.76562\n",
      "Iter 118528, Minibatch Loss= 1377.345581, Training Accuracy= 0.81250\n",
      "Iter 118592, Minibatch Loss= 6017.044922, Training Accuracy= 0.68750\n",
      "Iter 118656, Minibatch Loss= 7290.979980, Training Accuracy= 0.62500\n",
      "Iter 118720, Minibatch Loss= 7992.687988, Training Accuracy= 0.56250\n",
      "Iter 118784, Minibatch Loss= 2821.413086, Training Accuracy= 0.76562\n",
      "Iter 118848, Minibatch Loss= 6322.659668, Training Accuracy= 0.68750\n",
      "Iter 118912, Minibatch Loss= 4296.825195, Training Accuracy= 0.75000\n",
      "Iter 118976, Minibatch Loss= 4283.749512, Training Accuracy= 0.70312\n",
      "Iter 119040, Minibatch Loss= 6197.541016, Training Accuracy= 0.62500\n",
      "Iter 119104, Minibatch Loss= 2303.785156, Training Accuracy= 0.78125\n",
      "Iter 119168, Minibatch Loss= 4121.680664, Training Accuracy= 0.70312\n",
      "Iter 119232, Minibatch Loss= 3264.988281, Training Accuracy= 0.68750\n",
      "Iter 119296, Minibatch Loss= 6034.223145, Training Accuracy= 0.67188\n",
      "Iter 119360, Minibatch Loss= 1753.953857, Training Accuracy= 0.84375\n",
      "Iter 119424, Minibatch Loss= 2978.234375, Training Accuracy= 0.68750\n",
      "Iter 119488, Minibatch Loss= 4137.029785, Training Accuracy= 0.70312\n",
      "Iter 119552, Minibatch Loss= 2660.548584, Training Accuracy= 0.75000\n",
      "Iter 119616, Minibatch Loss= 2486.992676, Training Accuracy= 0.78125\n",
      "Iter 119680, Minibatch Loss= 3255.859863, Training Accuracy= 0.67188\n",
      "Iter 119744, Minibatch Loss= 5157.895508, Training Accuracy= 0.65625\n",
      "Iter 119808, Minibatch Loss= 3602.968506, Training Accuracy= 0.73438\n",
      "Iter 119872, Minibatch Loss= 2596.649170, Training Accuracy= 0.78125\n",
      "Iter 119936, Minibatch Loss= 5737.982910, Training Accuracy= 0.70312\n",
      "Iter 120000, Minibatch Loss= 1796.523438, Training Accuracy= 0.76562\n",
      "Iter 120064, Minibatch Loss= 5170.955566, Training Accuracy= 0.68750\n",
      "Iter 120128, Minibatch Loss= 5333.290527, Training Accuracy= 0.68750\n",
      "Iter 120192, Minibatch Loss= 2383.891113, Training Accuracy= 0.82812\n",
      "Iter 120256, Minibatch Loss= 5193.831055, Training Accuracy= 0.73438\n",
      "Iter 120320, Minibatch Loss= 3356.125977, Training Accuracy= 0.73438\n",
      "Iter 120384, Minibatch Loss= 2079.374023, Training Accuracy= 0.78125\n",
      "Iter 120448, Minibatch Loss= 5470.710938, Training Accuracy= 0.73438\n",
      "Iter 120512, Minibatch Loss= 4062.328613, Training Accuracy= 0.59375\n",
      "Iter 120576, Minibatch Loss= 3681.863281, Training Accuracy= 0.73438\n",
      "Iter 120640, Minibatch Loss= 3095.041992, Training Accuracy= 0.76562\n",
      "Iter 120704, Minibatch Loss= 1479.433594, Training Accuracy= 0.78125\n",
      "Iter 120768, Minibatch Loss= 2805.882568, Training Accuracy= 0.73438\n",
      "Iter 120832, Minibatch Loss= 4574.803711, Training Accuracy= 0.60938\n",
      "Iter 120896, Minibatch Loss= 7437.217773, Training Accuracy= 0.60938\n",
      "Iter 120960, Minibatch Loss= 3065.266113, Training Accuracy= 0.70312\n",
      "Iter 121024, Minibatch Loss= 2365.979004, Training Accuracy= 0.70312\n",
      "Iter 121088, Minibatch Loss= 4787.014160, Training Accuracy= 0.76562\n",
      "Iter 121152, Minibatch Loss= 1282.175049, Training Accuracy= 0.79688\n",
      "Iter 121216, Minibatch Loss= 3485.960449, Training Accuracy= 0.78125\n",
      "Iter 121280, Minibatch Loss= 5486.193359, Training Accuracy= 0.64062\n",
      "Iter 121344, Minibatch Loss= 3868.841309, Training Accuracy= 0.65625\n",
      "Iter 121408, Minibatch Loss= 1988.053101, Training Accuracy= 0.76562\n",
      "Iter 121472, Minibatch Loss= 2217.621338, Training Accuracy= 0.68750\n",
      "Iter 121536, Minibatch Loss= 4355.761719, Training Accuracy= 0.71875\n",
      "Iter 121600, Minibatch Loss= 3353.068359, Training Accuracy= 0.68750\n",
      "Iter 121664, Minibatch Loss= 2181.066650, Training Accuracy= 0.76562\n",
      "Iter 121728, Minibatch Loss= 2181.176270, Training Accuracy= 0.82812\n",
      "Iter 121792, Minibatch Loss= 5344.127930, Training Accuracy= 0.73438\n",
      "Iter 121856, Minibatch Loss= 2938.766846, Training Accuracy= 0.73438\n",
      "Iter 121920, Minibatch Loss= 2379.014404, Training Accuracy= 0.79688\n",
      "Iter 121984, Minibatch Loss= 1556.561035, Training Accuracy= 0.84375\n",
      "Iter 122048, Minibatch Loss= 3129.473877, Training Accuracy= 0.75000\n",
      "Iter 122112, Minibatch Loss= 8284.117188, Training Accuracy= 0.60938\n",
      "Iter 122176, Minibatch Loss= 6002.665527, Training Accuracy= 0.71875\n",
      "Iter 122240, Minibatch Loss= 3814.110840, Training Accuracy= 0.70312\n",
      "Iter 122304, Minibatch Loss= 3029.656494, Training Accuracy= 0.71875\n",
      "Iter 122368, Minibatch Loss= 4312.375977, Training Accuracy= 0.73438\n",
      "Iter 122432, Minibatch Loss= 4065.942627, Training Accuracy= 0.71875\n",
      "Iter 122496, Minibatch Loss= 6585.536133, Training Accuracy= 0.60938\n",
      "Iter 122560, Minibatch Loss= 6445.333008, Training Accuracy= 0.67188\n",
      "Iter 122624, Minibatch Loss= 4887.804688, Training Accuracy= 0.70312\n",
      "Iter 122688, Minibatch Loss= 1366.245605, Training Accuracy= 0.78125\n",
      "Iter 122752, Minibatch Loss= 3400.954102, Training Accuracy= 0.81250\n",
      "Iter 122816, Minibatch Loss= 5808.501953, Training Accuracy= 0.70312\n",
      "Iter 122880, Minibatch Loss= 4398.937500, Training Accuracy= 0.67188\n",
      "Iter 122944, Minibatch Loss= 3142.192627, Training Accuracy= 0.67188\n",
      "Iter 123008, Minibatch Loss= 3601.737793, Training Accuracy= 0.79688\n",
      "Iter 123072, Minibatch Loss= 4105.622070, Training Accuracy= 0.82812\n",
      "Iter 123136, Minibatch Loss= 2854.578613, Training Accuracy= 0.75000\n",
      "Iter 123200, Minibatch Loss= 4398.594727, Training Accuracy= 0.71875\n",
      "Iter 123264, Minibatch Loss= 2766.146484, Training Accuracy= 0.73438\n",
      "Iter 123328, Minibatch Loss= 6189.326660, Training Accuracy= 0.68750\n",
      "Iter 123392, Minibatch Loss= 2200.621338, Training Accuracy= 0.76562\n",
      "Iter 123456, Minibatch Loss= 4286.618164, Training Accuracy= 0.68750\n",
      "Iter 123520, Minibatch Loss= 4389.001465, Training Accuracy= 0.67188\n",
      "Iter 123584, Minibatch Loss= 3263.514160, Training Accuracy= 0.78125\n",
      "Iter 123648, Minibatch Loss= 2509.260742, Training Accuracy= 0.78125\n",
      "Iter 123712, Minibatch Loss= 3654.733643, Training Accuracy= 0.67188\n",
      "Iter 123776, Minibatch Loss= 6785.249023, Training Accuracy= 0.68750\n",
      "Iter 123840, Minibatch Loss= 5424.695312, Training Accuracy= 0.64062\n",
      "Iter 123904, Minibatch Loss= 3028.208740, Training Accuracy= 0.81250\n",
      "Iter 123968, Minibatch Loss= 1922.868774, Training Accuracy= 0.81250\n",
      "Iter 124032, Minibatch Loss= 5159.976562, Training Accuracy= 0.67188\n",
      "Iter 124096, Minibatch Loss= 3538.114502, Training Accuracy= 0.70312\n",
      "Iter 124160, Minibatch Loss= 2640.498535, Training Accuracy= 0.67188\n",
      "Iter 124224, Minibatch Loss= 3466.324707, Training Accuracy= 0.68750\n",
      "Iter 124288, Minibatch Loss= 4236.689941, Training Accuracy= 0.70312\n",
      "Iter 124352, Minibatch Loss= 5621.218750, Training Accuracy= 0.68750\n",
      "Iter 124416, Minibatch Loss= 5184.265625, Training Accuracy= 0.67188\n",
      "Iter 124480, Minibatch Loss= 4780.391113, Training Accuracy= 0.60938\n",
      "Iter 124544, Minibatch Loss= 3760.318359, Training Accuracy= 0.67188\n",
      "Iter 124608, Minibatch Loss= 5257.237793, Training Accuracy= 0.60938\n",
      "Iter 124672, Minibatch Loss= 4120.007812, Training Accuracy= 0.76562\n",
      "Iter 124736, Minibatch Loss= 6103.934570, Training Accuracy= 0.62500\n",
      "Iter 124800, Minibatch Loss= 4472.709961, Training Accuracy= 0.68750\n",
      "Iter 124864, Minibatch Loss= 1807.855347, Training Accuracy= 0.79688\n",
      "Iter 124928, Minibatch Loss= 6313.092773, Training Accuracy= 0.64062\n",
      "Iter 124992, Minibatch Loss= 2414.341553, Training Accuracy= 0.78125\n",
      "Iter 125056, Minibatch Loss= 2502.733398, Training Accuracy= 0.73438\n",
      "Iter 125120, Minibatch Loss= 2209.249512, Training Accuracy= 0.78125\n",
      "Iter 125184, Minibatch Loss= 3638.216553, Training Accuracy= 0.81250\n",
      "Iter 125248, Minibatch Loss= 3905.287109, Training Accuracy= 0.75000\n",
      "Iter 125312, Minibatch Loss= 3406.055176, Training Accuracy= 0.71875\n",
      "Iter 125376, Minibatch Loss= 4907.643555, Training Accuracy= 0.62500\n",
      "Iter 125440, Minibatch Loss= 4717.654297, Training Accuracy= 0.76562\n",
      "Iter 125504, Minibatch Loss= 5259.863770, Training Accuracy= 0.64062\n",
      "Iter 125568, Minibatch Loss= 3903.103027, Training Accuracy= 0.68750\n",
      "Iter 125632, Minibatch Loss= 1889.689819, Training Accuracy= 0.73438\n",
      "Iter 125696, Minibatch Loss= 4619.133789, Training Accuracy= 0.78125\n",
      "Iter 125760, Minibatch Loss= 5630.639648, Training Accuracy= 0.64062\n",
      "Iter 125824, Minibatch Loss= 4688.340332, Training Accuracy= 0.65625\n",
      "Iter 125888, Minibatch Loss= 4427.703613, Training Accuracy= 0.67188\n",
      "Iter 125952, Minibatch Loss= 4545.449219, Training Accuracy= 0.73438\n",
      "Iter 126016, Minibatch Loss= 2434.798340, Training Accuracy= 0.79688\n",
      "Iter 126080, Minibatch Loss= 2792.540527, Training Accuracy= 0.68750\n",
      "Iter 126144, Minibatch Loss= 6528.280762, Training Accuracy= 0.67188\n",
      "Iter 126208, Minibatch Loss= 1824.866455, Training Accuracy= 0.78125\n",
      "Iter 126272, Minibatch Loss= 3416.582520, Training Accuracy= 0.70312\n",
      "Iter 126336, Minibatch Loss= 2809.525879, Training Accuracy= 0.75000\n",
      "Iter 126400, Minibatch Loss= 4093.693848, Training Accuracy= 0.76562\n",
      "Iter 126464, Minibatch Loss= 4107.805664, Training Accuracy= 0.68750\n",
      "Iter 126528, Minibatch Loss= 2788.251953, Training Accuracy= 0.76562\n",
      "Iter 126592, Minibatch Loss= 5230.938965, Training Accuracy= 0.65625\n",
      "Iter 126656, Minibatch Loss= 5256.796387, Training Accuracy= 0.68750\n",
      "Iter 126720, Minibatch Loss= 3156.508301, Training Accuracy= 0.71875\n",
      "Iter 126784, Minibatch Loss= 6423.956543, Training Accuracy= 0.64062\n",
      "Iter 126848, Minibatch Loss= 5346.555664, Training Accuracy= 0.59375\n",
      "Iter 126912, Minibatch Loss= 4123.004883, Training Accuracy= 0.71875\n",
      "Iter 126976, Minibatch Loss= 5278.385742, Training Accuracy= 0.71875\n",
      "Iter 127040, Minibatch Loss= 4432.081543, Training Accuracy= 0.70312\n",
      "Iter 127104, Minibatch Loss= 4766.209961, Training Accuracy= 0.65625\n",
      "Iter 127168, Minibatch Loss= 2980.308594, Training Accuracy= 0.73438\n",
      "Iter 127232, Minibatch Loss= 3207.899414, Training Accuracy= 0.76562\n",
      "Iter 127296, Minibatch Loss= 2189.289551, Training Accuracy= 0.75000\n",
      "Iter 127360, Minibatch Loss= 4684.546875, Training Accuracy= 0.73438\n",
      "Iter 127424, Minibatch Loss= 3547.862793, Training Accuracy= 0.68750\n",
      "Iter 127488, Minibatch Loss= 3584.954834, Training Accuracy= 0.70312\n",
      "Iter 127552, Minibatch Loss= 2268.221924, Training Accuracy= 0.70312\n",
      "Iter 127616, Minibatch Loss= 4191.337891, Training Accuracy= 0.75000\n",
      "Iter 127680, Minibatch Loss= 2853.474854, Training Accuracy= 0.73438\n",
      "Iter 127744, Minibatch Loss= 3944.521973, Training Accuracy= 0.75000\n",
      "Iter 127808, Minibatch Loss= 1596.816895, Training Accuracy= 0.71875\n",
      "Iter 127872, Minibatch Loss= 4538.840332, Training Accuracy= 0.68750\n",
      "Iter 127936, Minibatch Loss= 3441.525391, Training Accuracy= 0.65625\n",
      "Iter 128000, Minibatch Loss= 5134.226562, Training Accuracy= 0.60938\n",
      "Iter 128064, Minibatch Loss= 4714.214844, Training Accuracy= 0.64062\n",
      "Iter 128128, Minibatch Loss= 2661.132324, Training Accuracy= 0.78125\n",
      "Iter 128192, Minibatch Loss= 3328.384277, Training Accuracy= 0.68750\n",
      "Iter 128256, Minibatch Loss= 1924.342529, Training Accuracy= 0.73438\n",
      "Iter 128320, Minibatch Loss= 3541.360840, Training Accuracy= 0.75000\n",
      "Iter 128384, Minibatch Loss= 3830.637939, Training Accuracy= 0.67188\n",
      "Iter 128448, Minibatch Loss= 5742.210938, Training Accuracy= 0.62500\n",
      "Iter 128512, Minibatch Loss= 5657.487305, Training Accuracy= 0.65625\n",
      "Iter 128576, Minibatch Loss= 5483.430664, Training Accuracy= 0.71875\n",
      "Iter 128640, Minibatch Loss= 4504.391602, Training Accuracy= 0.70312\n",
      "Iter 128704, Minibatch Loss= 4226.045898, Training Accuracy= 0.68750\n",
      "Iter 128768, Minibatch Loss= 5337.227051, Training Accuracy= 0.59375\n",
      "Iter 128832, Minibatch Loss= 1819.382812, Training Accuracy= 0.71875\n",
      "Iter 128896, Minibatch Loss= 4391.220703, Training Accuracy= 0.65625\n",
      "Iter 128960, Minibatch Loss= 4816.335449, Training Accuracy= 0.62500\n",
      "Iter 129024, Minibatch Loss= 1719.753784, Training Accuracy= 0.78125\n",
      "Iter 129088, Minibatch Loss= 4483.974121, Training Accuracy= 0.59375\n",
      "Iter 129152, Minibatch Loss= 2008.714478, Training Accuracy= 0.70312\n",
      "Iter 129216, Minibatch Loss= 5968.343750, Training Accuracy= 0.65625\n",
      "Iter 129280, Minibatch Loss= 2105.089600, Training Accuracy= 0.73438\n",
      "Iter 129344, Minibatch Loss= 4672.616211, Training Accuracy= 0.65625\n",
      "Iter 129408, Minibatch Loss= 2330.480713, Training Accuracy= 0.71875\n",
      "Iter 129472, Minibatch Loss= 3798.073730, Training Accuracy= 0.64062\n",
      "Iter 129536, Minibatch Loss= 3413.289795, Training Accuracy= 0.67188\n",
      "Iter 129600, Minibatch Loss= 3000.016602, Training Accuracy= 0.75000\n",
      "Iter 129664, Minibatch Loss= 2701.964355, Training Accuracy= 0.75000\n",
      "Iter 129728, Minibatch Loss= 4667.535156, Training Accuracy= 0.71875\n",
      "Iter 129792, Minibatch Loss= 3165.739746, Training Accuracy= 0.70312\n",
      "Iter 129856, Minibatch Loss= 4991.042480, Training Accuracy= 0.67188\n",
      "Iter 129920, Minibatch Loss= 2886.014404, Training Accuracy= 0.71875\n",
      "Iter 129984, Minibatch Loss= 4416.129883, Training Accuracy= 0.68750\n",
      "Iter 130048, Minibatch Loss= 4511.989746, Training Accuracy= 0.71875\n",
      "Iter 130112, Minibatch Loss= 4890.907227, Training Accuracy= 0.62500\n",
      "Iter 130176, Minibatch Loss= 3665.459473, Training Accuracy= 0.79688\n",
      "Iter 130240, Minibatch Loss= 1745.122314, Training Accuracy= 0.78125\n",
      "Iter 130304, Minibatch Loss= 5333.430176, Training Accuracy= 0.71875\n",
      "Iter 130368, Minibatch Loss= 1970.573242, Training Accuracy= 0.76562\n",
      "Iter 130432, Minibatch Loss= 5168.966797, Training Accuracy= 0.71875\n",
      "Iter 130496, Minibatch Loss= 3630.708008, Training Accuracy= 0.65625\n",
      "Iter 130560, Minibatch Loss= 1884.740112, Training Accuracy= 0.76562\n",
      "Iter 130624, Minibatch Loss= 2611.088867, Training Accuracy= 0.71875\n",
      "Iter 130688, Minibatch Loss= 3008.062012, Training Accuracy= 0.75000\n",
      "Iter 130752, Minibatch Loss= 3366.837646, Training Accuracy= 0.76562\n",
      "Iter 130816, Minibatch Loss= 4389.949707, Training Accuracy= 0.71875\n",
      "Iter 130880, Minibatch Loss= 3869.916260, Training Accuracy= 0.71875\n",
      "Iter 130944, Minibatch Loss= 3434.200684, Training Accuracy= 0.81250\n",
      "Iter 131008, Minibatch Loss= 3790.186035, Training Accuracy= 0.68750\n",
      "Iter 131072, Minibatch Loss= 2949.507568, Training Accuracy= 0.70312\n",
      "Iter 131136, Minibatch Loss= 4647.564941, Training Accuracy= 0.71875\n",
      "Iter 131200, Minibatch Loss= 2076.693848, Training Accuracy= 0.81250\n",
      "Iter 131264, Minibatch Loss= 5239.423828, Training Accuracy= 0.60938\n",
      "Iter 131328, Minibatch Loss= 4694.704102, Training Accuracy= 0.68750\n",
      "Iter 131392, Minibatch Loss= 3041.964600, Training Accuracy= 0.68750\n",
      "Iter 131456, Minibatch Loss= 1976.312256, Training Accuracy= 0.71875\n",
      "Iter 131520, Minibatch Loss= 6190.663086, Training Accuracy= 0.71875\n",
      "Iter 131584, Minibatch Loss= 5037.775391, Training Accuracy= 0.68750\n",
      "Iter 131648, Minibatch Loss= 4016.158691, Training Accuracy= 0.64062\n",
      "Iter 131712, Minibatch Loss= 3255.935547, Training Accuracy= 0.71875\n",
      "Iter 131776, Minibatch Loss= 4043.018066, Training Accuracy= 0.75000\n",
      "Iter 131840, Minibatch Loss= 2655.816895, Training Accuracy= 0.76562\n",
      "Iter 131904, Minibatch Loss= 3409.653076, Training Accuracy= 0.70312\n",
      "Iter 131968, Minibatch Loss= 2785.974121, Training Accuracy= 0.78125\n",
      "Iter 132032, Minibatch Loss= 3541.345459, Training Accuracy= 0.71875\n",
      "Iter 132096, Minibatch Loss= 4052.278809, Training Accuracy= 0.65625\n",
      "Iter 132160, Minibatch Loss= 4669.234375, Training Accuracy= 0.71875\n",
      "Iter 132224, Minibatch Loss= 3290.136719, Training Accuracy= 0.73438\n",
      "Iter 132288, Minibatch Loss= 5371.570312, Training Accuracy= 0.60938\n",
      "Iter 132352, Minibatch Loss= 6111.653809, Training Accuracy= 0.76562\n",
      "Iter 132416, Minibatch Loss= 3923.899902, Training Accuracy= 0.64062\n",
      "Iter 132480, Minibatch Loss= 5445.925781, Training Accuracy= 0.65625\n",
      "Iter 132544, Minibatch Loss= 5785.098633, Training Accuracy= 0.64062\n",
      "Iter 132608, Minibatch Loss= 2553.574463, Training Accuracy= 0.75000\n",
      "Iter 132672, Minibatch Loss= 4824.785156, Training Accuracy= 0.68750\n",
      "Iter 132736, Minibatch Loss= 3609.421387, Training Accuracy= 0.78125\n",
      "Iter 132800, Minibatch Loss= 7201.205566, Training Accuracy= 0.54688\n",
      "Iter 132864, Minibatch Loss= 5514.817871, Training Accuracy= 0.57812\n",
      "Iter 132928, Minibatch Loss= 4842.374512, Training Accuracy= 0.54688\n",
      "Iter 132992, Minibatch Loss= 2067.076904, Training Accuracy= 0.78125\n",
      "Iter 133056, Minibatch Loss= 3975.522949, Training Accuracy= 0.67188\n",
      "Iter 133120, Minibatch Loss= 3449.670410, Training Accuracy= 0.70312\n",
      "Iter 133184, Minibatch Loss= 3685.445801, Training Accuracy= 0.65625\n",
      "Iter 133248, Minibatch Loss= 1868.693115, Training Accuracy= 0.78125\n",
      "Iter 133312, Minibatch Loss= 2335.307129, Training Accuracy= 0.71875\n",
      "Iter 133376, Minibatch Loss= 3817.593506, Training Accuracy= 0.79688\n",
      "Iter 133440, Minibatch Loss= 2436.703125, Training Accuracy= 0.81250\n",
      "Iter 133504, Minibatch Loss= 3273.872314, Training Accuracy= 0.75000\n",
      "Iter 133568, Minibatch Loss= 2250.546387, Training Accuracy= 0.78125\n",
      "Iter 133632, Minibatch Loss= 3052.040283, Training Accuracy= 0.65625\n",
      "Iter 133696, Minibatch Loss= 4674.016602, Training Accuracy= 0.67188\n",
      "Iter 133760, Minibatch Loss= 3903.306152, Training Accuracy= 0.65625\n",
      "Iter 133824, Minibatch Loss= 2903.410400, Training Accuracy= 0.75000\n",
      "Iter 133888, Minibatch Loss= 4877.831055, Training Accuracy= 0.59375\n",
      "Iter 133952, Minibatch Loss= 3421.751953, Training Accuracy= 0.76562\n",
      "Iter 134016, Minibatch Loss= 3916.478271, Training Accuracy= 0.71875\n",
      "Iter 134080, Minibatch Loss= 4833.508789, Training Accuracy= 0.65625\n",
      "Iter 134144, Minibatch Loss= 6364.775879, Training Accuracy= 0.60938\n",
      "Iter 134208, Minibatch Loss= 2248.806641, Training Accuracy= 0.76562\n",
      "Iter 134272, Minibatch Loss= 2569.228516, Training Accuracy= 0.65625\n",
      "Iter 134336, Minibatch Loss= 3542.530762, Training Accuracy= 0.70312\n",
      "Iter 134400, Minibatch Loss= 2723.467041, Training Accuracy= 0.71875\n",
      "Iter 134464, Minibatch Loss= 3443.294678, Training Accuracy= 0.76562\n",
      "Iter 134528, Minibatch Loss= 2572.933594, Training Accuracy= 0.71875\n",
      "Iter 134592, Minibatch Loss= 1685.133057, Training Accuracy= 0.76562\n",
      "Iter 134656, Minibatch Loss= 2248.108887, Training Accuracy= 0.75000\n",
      "Iter 134720, Minibatch Loss= 2911.957520, Training Accuracy= 0.64062\n",
      "Iter 134784, Minibatch Loss= 4514.451660, Training Accuracy= 0.68750\n",
      "Iter 134848, Minibatch Loss= 2834.651611, Training Accuracy= 0.73438\n",
      "Iter 134912, Minibatch Loss= 3716.097168, Training Accuracy= 0.76562\n",
      "Iter 134976, Minibatch Loss= 2196.051758, Training Accuracy= 0.73438\n",
      "Iter 135040, Minibatch Loss= 3083.461182, Training Accuracy= 0.71875\n",
      "Iter 135104, Minibatch Loss= 3890.557129, Training Accuracy= 0.68750\n",
      "Iter 135168, Minibatch Loss= 2265.163574, Training Accuracy= 0.79688\n",
      "Iter 135232, Minibatch Loss= 2872.281494, Training Accuracy= 0.71875\n",
      "Iter 135296, Minibatch Loss= 3897.419434, Training Accuracy= 0.76562\n",
      "Iter 135360, Minibatch Loss= 4239.592773, Training Accuracy= 0.70312\n",
      "Iter 135424, Minibatch Loss= 3166.593506, Training Accuracy= 0.65625\n",
      "Iter 135488, Minibatch Loss= 5240.104492, Training Accuracy= 0.60938\n",
      "Iter 135552, Minibatch Loss= 3433.915527, Training Accuracy= 0.76562\n",
      "Iter 135616, Minibatch Loss= 5454.750000, Training Accuracy= 0.60938\n",
      "Iter 135680, Minibatch Loss= 3782.787109, Training Accuracy= 0.76562\n",
      "Iter 135744, Minibatch Loss= 4718.037109, Training Accuracy= 0.64062\n",
      "Iter 135808, Minibatch Loss= 4185.654297, Training Accuracy= 0.67188\n",
      "Iter 135872, Minibatch Loss= 2461.937012, Training Accuracy= 0.78125\n",
      "Iter 135936, Minibatch Loss= 4027.498535, Training Accuracy= 0.75000\n",
      "Iter 136000, Minibatch Loss= 3519.320312, Training Accuracy= 0.75000\n",
      "Iter 136064, Minibatch Loss= 3545.085449, Training Accuracy= 0.81250\n",
      "Iter 136128, Minibatch Loss= 2613.854004, Training Accuracy= 0.71875\n",
      "Iter 136192, Minibatch Loss= 3608.496826, Training Accuracy= 0.75000\n",
      "Iter 136256, Minibatch Loss= 3735.689453, Training Accuracy= 0.67188\n",
      "Iter 136320, Minibatch Loss= 4169.638184, Training Accuracy= 0.75000\n",
      "Iter 136384, Minibatch Loss= 2057.230225, Training Accuracy= 0.78125\n",
      "Iter 136448, Minibatch Loss= 5521.164062, Training Accuracy= 0.73438\n",
      "Iter 136512, Minibatch Loss= 2455.556152, Training Accuracy= 0.76562\n",
      "Iter 136576, Minibatch Loss= 4310.897461, Training Accuracy= 0.62500\n",
      "Iter 136640, Minibatch Loss= 2122.272705, Training Accuracy= 0.75000\n",
      "Iter 136704, Minibatch Loss= 2821.420898, Training Accuracy= 0.75000\n",
      "Iter 136768, Minibatch Loss= 2005.705811, Training Accuracy= 0.70312\n",
      "Iter 136832, Minibatch Loss= 3634.221924, Training Accuracy= 0.68750\n",
      "Iter 136896, Minibatch Loss= 4895.299805, Training Accuracy= 0.73438\n",
      "Iter 136960, Minibatch Loss= 2810.731689, Training Accuracy= 0.75000\n",
      "Iter 137024, Minibatch Loss= 3158.331299, Training Accuracy= 0.79688\n",
      "Iter 137088, Minibatch Loss= 3053.742188, Training Accuracy= 0.73438\n",
      "Iter 137152, Minibatch Loss= 1641.853638, Training Accuracy= 0.78125\n",
      "Iter 137216, Minibatch Loss= 2639.918213, Training Accuracy= 0.71875\n",
      "Iter 137280, Minibatch Loss= 2331.730469, Training Accuracy= 0.76562\n",
      "Iter 137344, Minibatch Loss= 2985.829834, Training Accuracy= 0.71875\n",
      "Iter 137408, Minibatch Loss= 5073.751953, Training Accuracy= 0.71875\n",
      "Iter 137472, Minibatch Loss= 5247.658203, Training Accuracy= 0.54688\n",
      "Iter 137536, Minibatch Loss= 4179.901367, Training Accuracy= 0.65625\n",
      "Iter 137600, Minibatch Loss= 4488.035156, Training Accuracy= 0.70312\n",
      "Iter 137664, Minibatch Loss= 5945.621094, Training Accuracy= 0.64062\n",
      "Iter 137728, Minibatch Loss= 3558.359863, Training Accuracy= 0.64062\n",
      "Iter 137792, Minibatch Loss= 4506.170898, Training Accuracy= 0.70312\n",
      "Iter 137856, Minibatch Loss= 3465.880371, Training Accuracy= 0.68750\n",
      "Iter 137920, Minibatch Loss= 2990.452148, Training Accuracy= 0.64062\n",
      "Iter 137984, Minibatch Loss= 4218.000000, Training Accuracy= 0.73438\n",
      "Iter 138048, Minibatch Loss= 5114.053223, Training Accuracy= 0.68750\n",
      "Iter 138112, Minibatch Loss= 4031.749512, Training Accuracy= 0.78125\n",
      "Iter 138176, Minibatch Loss= 2245.043945, Training Accuracy= 0.73438\n",
      "Iter 138240, Minibatch Loss= 2577.608643, Training Accuracy= 0.71875\n",
      "Iter 138304, Minibatch Loss= 2198.896484, Training Accuracy= 0.81250\n",
      "Iter 138368, Minibatch Loss= 1569.599121, Training Accuracy= 0.79688\n",
      "Iter 138432, Minibatch Loss= 4530.206055, Training Accuracy= 0.64062\n",
      "Iter 138496, Minibatch Loss= 2241.838135, Training Accuracy= 0.76562\n",
      "Iter 138560, Minibatch Loss= 4101.288574, Training Accuracy= 0.62500\n",
      "Iter 138624, Minibatch Loss= 2245.439941, Training Accuracy= 0.71875\n",
      "Iter 138688, Minibatch Loss= 1559.521729, Training Accuracy= 0.79688\n",
      "Iter 138752, Minibatch Loss= 2819.927246, Training Accuracy= 0.70312\n",
      "Iter 138816, Minibatch Loss= 5166.202148, Training Accuracy= 0.60938\n",
      "Iter 138880, Minibatch Loss= 2186.938232, Training Accuracy= 0.81250\n",
      "Iter 138944, Minibatch Loss= 4443.541992, Training Accuracy= 0.64062\n",
      "Iter 139008, Minibatch Loss= 2789.105713, Training Accuracy= 0.75000\n",
      "Iter 139072, Minibatch Loss= 4539.312988, Training Accuracy= 0.65625\n",
      "Iter 139136, Minibatch Loss= 2398.419922, Training Accuracy= 0.68750\n",
      "Iter 139200, Minibatch Loss= 4031.503174, Training Accuracy= 0.62500\n",
      "Iter 139264, Minibatch Loss= 4053.072754, Training Accuracy= 0.76562\n",
      "Iter 139328, Minibatch Loss= 3450.638428, Training Accuracy= 0.75000\n",
      "Iter 139392, Minibatch Loss= 3055.118408, Training Accuracy= 0.78125\n",
      "Iter 139456, Minibatch Loss= 4275.018555, Training Accuracy= 0.75000\n",
      "Iter 139520, Minibatch Loss= 3226.111816, Training Accuracy= 0.73438\n",
      "Iter 139584, Minibatch Loss= 2806.579834, Training Accuracy= 0.68750\n",
      "Iter 139648, Minibatch Loss= 4746.195801, Training Accuracy= 0.62500\n",
      "Iter 139712, Minibatch Loss= 2713.181641, Training Accuracy= 0.73438\n",
      "Iter 139776, Minibatch Loss= 3901.261475, Training Accuracy= 0.65625\n",
      "Iter 139840, Minibatch Loss= 3280.632568, Training Accuracy= 0.73438\n",
      "Iter 139904, Minibatch Loss= 2867.327393, Training Accuracy= 0.73438\n",
      "Iter 139968, Minibatch Loss= 3757.237793, Training Accuracy= 0.75000\n",
      "Iter 140032, Minibatch Loss= 1796.836670, Training Accuracy= 0.78125\n",
      "Iter 140096, Minibatch Loss= 3397.567383, Training Accuracy= 0.65625\n",
      "Iter 140160, Minibatch Loss= 3095.300293, Training Accuracy= 0.71875\n",
      "Iter 140224, Minibatch Loss= 3821.338867, Training Accuracy= 0.62500\n",
      "Iter 140288, Minibatch Loss= 1916.914551, Training Accuracy= 0.65625\n",
      "Iter 140352, Minibatch Loss= 1876.359863, Training Accuracy= 0.75000\n",
      "Iter 140416, Minibatch Loss= 2320.197021, Training Accuracy= 0.75000\n",
      "Iter 140480, Minibatch Loss= 5020.920898, Training Accuracy= 0.67188\n",
      "Iter 140544, Minibatch Loss= 2570.687988, Training Accuracy= 0.75000\n",
      "Iter 140608, Minibatch Loss= 4287.371582, Training Accuracy= 0.75000\n",
      "Iter 140672, Minibatch Loss= 2963.980957, Training Accuracy= 0.75000\n",
      "Iter 140736, Minibatch Loss= 6837.887695, Training Accuracy= 0.62500\n",
      "Iter 140800, Minibatch Loss= 3692.314453, Training Accuracy= 0.81250\n",
      "Iter 140864, Minibatch Loss= 2192.091797, Training Accuracy= 0.75000\n",
      "Iter 140928, Minibatch Loss= 5924.095703, Training Accuracy= 0.67188\n",
      "Iter 140992, Minibatch Loss= 2358.291748, Training Accuracy= 0.75000\n",
      "Iter 141056, Minibatch Loss= 4905.140625, Training Accuracy= 0.60938\n",
      "Iter 141120, Minibatch Loss= 3083.948975, Training Accuracy= 0.67188\n",
      "Iter 141184, Minibatch Loss= 2852.147949, Training Accuracy= 0.75000\n",
      "Iter 141248, Minibatch Loss= 2919.536865, Training Accuracy= 0.64062\n",
      "Iter 141312, Minibatch Loss= 4823.928223, Training Accuracy= 0.65625\n",
      "Iter 141376, Minibatch Loss= 2938.702637, Training Accuracy= 0.75000\n",
      "Iter 141440, Minibatch Loss= 2489.671631, Training Accuracy= 0.71875\n",
      "Iter 141504, Minibatch Loss= 2996.954590, Training Accuracy= 0.68750\n",
      "Iter 141568, Minibatch Loss= 3788.312012, Training Accuracy= 0.67188\n",
      "Iter 141632, Minibatch Loss= 1814.761108, Training Accuracy= 0.76562\n",
      "Iter 141696, Minibatch Loss= 2556.012451, Training Accuracy= 0.75000\n",
      "Iter 141760, Minibatch Loss= 3250.256348, Training Accuracy= 0.71875\n",
      "Iter 141824, Minibatch Loss= 4324.657227, Training Accuracy= 0.59375\n",
      "Iter 141888, Minibatch Loss= 1781.240234, Training Accuracy= 0.82812\n",
      "Iter 141952, Minibatch Loss= 4045.158936, Training Accuracy= 0.73438\n",
      "Iter 142016, Minibatch Loss= 2754.060303, Training Accuracy= 0.81250\n",
      "Iter 142080, Minibatch Loss= 3866.886230, Training Accuracy= 0.75000\n",
      "Iter 142144, Minibatch Loss= 3616.752930, Training Accuracy= 0.67188\n",
      "Iter 142208, Minibatch Loss= 2533.725098, Training Accuracy= 0.78125\n",
      "Iter 142272, Minibatch Loss= 6048.799805, Training Accuracy= 0.59375\n",
      "Iter 142336, Minibatch Loss= 4921.332520, Training Accuracy= 0.67188\n",
      "Iter 142400, Minibatch Loss= 2189.830566, Training Accuracy= 0.64062\n",
      "Iter 142464, Minibatch Loss= 2450.978760, Training Accuracy= 0.67188\n",
      "Iter 142528, Minibatch Loss= 5561.046875, Training Accuracy= 0.73438\n",
      "Iter 142592, Minibatch Loss= 5273.401367, Training Accuracy= 0.57812\n",
      "Iter 142656, Minibatch Loss= 4174.126953, Training Accuracy= 0.65625\n",
      "Iter 142720, Minibatch Loss= 3877.129150, Training Accuracy= 0.70312\n",
      "Iter 142784, Minibatch Loss= 2899.029053, Training Accuracy= 0.78125\n",
      "Iter 142848, Minibatch Loss= 1466.767578, Training Accuracy= 0.76562\n",
      "Iter 142912, Minibatch Loss= 3204.838135, Training Accuracy= 0.76562\n",
      "Iter 142976, Minibatch Loss= 4604.981934, Training Accuracy= 0.62500\n",
      "Iter 143040, Minibatch Loss= 1682.963623, Training Accuracy= 0.78125\n",
      "Iter 143104, Minibatch Loss= 2463.597168, Training Accuracy= 0.81250\n",
      "Iter 143168, Minibatch Loss= 2634.270508, Training Accuracy= 0.75000\n",
      "Iter 143232, Minibatch Loss= 3274.678711, Training Accuracy= 0.75000\n",
      "Iter 143296, Minibatch Loss= 4146.923828, Training Accuracy= 0.64062\n",
      "Iter 143360, Minibatch Loss= 2115.538574, Training Accuracy= 0.79688\n",
      "Iter 143424, Minibatch Loss= 3084.483887, Training Accuracy= 0.73438\n",
      "Iter 143488, Minibatch Loss= 3323.027832, Training Accuracy= 0.73438\n",
      "Iter 143552, Minibatch Loss= 4232.090820, Training Accuracy= 0.73438\n",
      "Iter 143616, Minibatch Loss= 2737.968750, Training Accuracy= 0.67188\n",
      "Iter 143680, Minibatch Loss= 1401.204712, Training Accuracy= 0.79688\n",
      "Iter 143744, Minibatch Loss= 2112.836426, Training Accuracy= 0.70312\n",
      "Iter 143808, Minibatch Loss= 2271.142578, Training Accuracy= 0.75000\n",
      "Iter 143872, Minibatch Loss= 3300.844238, Training Accuracy= 0.76562\n",
      "Iter 143936, Minibatch Loss= 2687.247559, Training Accuracy= 0.73438\n",
      "Iter 144000, Minibatch Loss= 4843.330078, Training Accuracy= 0.67188\n",
      "Iter 144064, Minibatch Loss= 4760.316406, Training Accuracy= 0.59375\n",
      "Iter 144128, Minibatch Loss= 4297.372070, Training Accuracy= 0.64062\n",
      "Iter 144192, Minibatch Loss= 2656.130615, Training Accuracy= 0.73438\n",
      "Iter 144256, Minibatch Loss= 2145.144531, Training Accuracy= 0.78125\n",
      "Iter 144320, Minibatch Loss= 2861.112305, Training Accuracy= 0.84375\n",
      "Iter 144384, Minibatch Loss= 3163.167236, Training Accuracy= 0.75000\n",
      "Iter 144448, Minibatch Loss= 1995.406494, Training Accuracy= 0.73438\n",
      "Iter 144512, Minibatch Loss= 2164.165527, Training Accuracy= 0.75000\n",
      "Iter 144576, Minibatch Loss= 4696.194336, Training Accuracy= 0.68750\n",
      "Iter 144640, Minibatch Loss= 2970.635986, Training Accuracy= 0.71875\n",
      "Iter 144704, Minibatch Loss= 3366.466064, Training Accuracy= 0.67188\n",
      "Iter 144768, Minibatch Loss= 1334.914307, Training Accuracy= 0.81250\n",
      "Iter 144832, Minibatch Loss= 3384.174316, Training Accuracy= 0.71875\n",
      "Iter 144896, Minibatch Loss= 2112.193359, Training Accuracy= 0.73438\n",
      "Iter 144960, Minibatch Loss= 3352.149414, Training Accuracy= 0.67188\n",
      "Iter 145024, Minibatch Loss= 3019.710449, Training Accuracy= 0.75000\n",
      "Iter 145088, Minibatch Loss= 2612.311523, Training Accuracy= 0.75000\n",
      "Iter 145152, Minibatch Loss= 2774.466064, Training Accuracy= 0.76562\n",
      "Iter 145216, Minibatch Loss= 4664.753906, Training Accuracy= 0.59375\n",
      "Iter 145280, Minibatch Loss= 3422.322266, Training Accuracy= 0.71875\n",
      "Iter 145344, Minibatch Loss= 2994.190430, Training Accuracy= 0.81250\n",
      "Iter 145408, Minibatch Loss= 2925.551514, Training Accuracy= 0.71875\n",
      "Iter 145472, Minibatch Loss= 3360.700195, Training Accuracy= 0.70312\n",
      "Iter 145536, Minibatch Loss= 2045.222412, Training Accuracy= 0.78125\n",
      "Iter 145600, Minibatch Loss= 3734.740479, Training Accuracy= 0.73438\n",
      "Iter 145664, Minibatch Loss= 3349.457031, Training Accuracy= 0.78125\n",
      "Iter 145728, Minibatch Loss= 3057.737305, Training Accuracy= 0.70312\n",
      "Iter 145792, Minibatch Loss= 2106.293945, Training Accuracy= 0.78125\n",
      "Iter 145856, Minibatch Loss= 3564.979004, Training Accuracy= 0.68750\n",
      "Iter 145920, Minibatch Loss= 2131.374512, Training Accuracy= 0.75000\n",
      "Iter 145984, Minibatch Loss= 2972.875488, Training Accuracy= 0.57812\n",
      "Iter 146048, Minibatch Loss= 4830.906738, Training Accuracy= 0.75000\n",
      "Iter 146112, Minibatch Loss= 4693.787109, Training Accuracy= 0.59375\n",
      "Iter 146176, Minibatch Loss= 4004.197266, Training Accuracy= 0.68750\n",
      "Iter 146240, Minibatch Loss= 2564.710938, Training Accuracy= 0.71875\n",
      "Iter 146304, Minibatch Loss= 2309.380859, Training Accuracy= 0.76562\n",
      "Iter 146368, Minibatch Loss= 3680.521240, Training Accuracy= 0.70312\n",
      "Iter 146432, Minibatch Loss= 3517.145996, Training Accuracy= 0.71875\n",
      "Iter 146496, Minibatch Loss= 2018.312988, Training Accuracy= 0.71875\n",
      "Iter 146560, Minibatch Loss= 2523.866943, Training Accuracy= 0.71875\n",
      "Iter 146624, Minibatch Loss= 4684.144531, Training Accuracy= 0.64062\n",
      "Iter 146688, Minibatch Loss= 4301.076660, Training Accuracy= 0.62500\n",
      "Iter 146752, Minibatch Loss= 4772.241211, Training Accuracy= 0.60938\n",
      "Iter 146816, Minibatch Loss= 3082.132324, Training Accuracy= 0.73438\n",
      "Iter 146880, Minibatch Loss= 6439.627441, Training Accuracy= 0.65625\n",
      "Iter 146944, Minibatch Loss= 3644.257812, Training Accuracy= 0.62500\n",
      "Iter 147008, Minibatch Loss= 3264.452148, Training Accuracy= 0.70312\n",
      "Iter 147072, Minibatch Loss= 5344.272949, Training Accuracy= 0.62500\n",
      "Iter 147136, Minibatch Loss= 3126.031738, Training Accuracy= 0.62500\n",
      "Iter 147200, Minibatch Loss= 2519.207031, Training Accuracy= 0.68750\n",
      "Iter 147264, Minibatch Loss= 2441.510254, Training Accuracy= 0.68750\n",
      "Iter 147328, Minibatch Loss= 4268.311035, Training Accuracy= 0.54688\n",
      "Iter 147392, Minibatch Loss= 3278.267090, Training Accuracy= 0.76562\n",
      "Iter 147456, Minibatch Loss= 2969.252930, Training Accuracy= 0.79688\n",
      "Iter 147520, Minibatch Loss= 3957.843018, Training Accuracy= 0.62500\n",
      "Iter 147584, Minibatch Loss= 4357.673340, Training Accuracy= 0.57812\n",
      "Iter 147648, Minibatch Loss= 4706.651367, Training Accuracy= 0.64062\n",
      "Iter 147712, Minibatch Loss= 3198.650879, Training Accuracy= 0.70312\n",
      "Iter 147776, Minibatch Loss= 3906.738770, Training Accuracy= 0.64062\n",
      "Iter 147840, Minibatch Loss= 3323.745361, Training Accuracy= 0.65625\n",
      "Iter 147904, Minibatch Loss= 4219.911133, Training Accuracy= 0.73438\n",
      "Iter 147968, Minibatch Loss= 2584.808350, Training Accuracy= 0.70312\n",
      "Iter 148032, Minibatch Loss= 3344.890381, Training Accuracy= 0.68750\n",
      "Iter 148096, Minibatch Loss= 4020.016846, Training Accuracy= 0.67188\n",
      "Iter 148160, Minibatch Loss= 3030.390869, Training Accuracy= 0.71875\n",
      "Iter 148224, Minibatch Loss= 3265.639648, Training Accuracy= 0.71875\n",
      "Iter 148288, Minibatch Loss= 2089.395020, Training Accuracy= 0.81250\n",
      "Iter 148352, Minibatch Loss= 2734.939209, Training Accuracy= 0.73438\n",
      "Iter 148416, Minibatch Loss= 4153.997559, Training Accuracy= 0.67188\n",
      "Iter 148480, Minibatch Loss= 2181.217773, Training Accuracy= 0.75000\n",
      "Iter 148544, Minibatch Loss= 1281.772705, Training Accuracy= 0.87500\n",
      "Iter 148608, Minibatch Loss= 4697.323242, Training Accuracy= 0.67188\n",
      "Iter 148672, Minibatch Loss= 3379.373779, Training Accuracy= 0.73438\n",
      "Iter 148736, Minibatch Loss= 3193.283691, Training Accuracy= 0.67188\n",
      "Iter 148800, Minibatch Loss= 2560.828613, Training Accuracy= 0.73438\n",
      "Iter 148864, Minibatch Loss= 3536.322021, Training Accuracy= 0.68750\n",
      "Iter 148928, Minibatch Loss= 4800.485840, Training Accuracy= 0.60938\n",
      "Iter 148992, Minibatch Loss= 4674.217773, Training Accuracy= 0.65625\n",
      "Iter 149056, Minibatch Loss= 5345.393066, Training Accuracy= 0.67188\n",
      "Iter 149120, Minibatch Loss= 3709.833496, Training Accuracy= 0.64062\n",
      "Iter 149184, Minibatch Loss= 3740.400146, Training Accuracy= 0.73438\n",
      "Iter 149248, Minibatch Loss= 1523.184814, Training Accuracy= 0.81250\n",
      "Iter 149312, Minibatch Loss= 3410.328125, Training Accuracy= 0.73438\n",
      "Iter 149376, Minibatch Loss= 4956.783203, Training Accuracy= 0.53125\n",
      "Iter 149440, Minibatch Loss= 723.449463, Training Accuracy= 0.84375\n",
      "Iter 149504, Minibatch Loss= 3456.123047, Training Accuracy= 0.67188\n",
      "Iter 149568, Minibatch Loss= 3084.210938, Training Accuracy= 0.73438\n",
      "Iter 149632, Minibatch Loss= 2589.932861, Training Accuracy= 0.71875\n",
      "Iter 149696, Minibatch Loss= 1410.587646, Training Accuracy= 0.84375\n",
      "Iter 149760, Minibatch Loss= 962.825806, Training Accuracy= 0.85938\n",
      "Iter 149824, Minibatch Loss= 3468.038086, Training Accuracy= 0.70312\n",
      "Iter 149888, Minibatch Loss= 2937.392334, Training Accuracy= 0.73438\n",
      "Iter 149952, Minibatch Loss= 2222.307617, Training Accuracy= 0.73438\n",
      "Iter 150016, Minibatch Loss= 3420.498535, Training Accuracy= 0.71875\n",
      "Iter 150080, Minibatch Loss= 5533.725586, Training Accuracy= 0.64062\n",
      "Iter 150144, Minibatch Loss= 3919.181396, Training Accuracy= 0.64062\n",
      "Iter 150208, Minibatch Loss= 4635.100586, Training Accuracy= 0.64062\n",
      "Iter 150272, Minibatch Loss= 4339.375000, Training Accuracy= 0.67188\n",
      "Iter 150336, Minibatch Loss= 3718.943848, Training Accuracy= 0.70312\n",
      "Iter 150400, Minibatch Loss= 3112.659180, Training Accuracy= 0.70312\n",
      "Iter 150464, Minibatch Loss= 2608.256836, Training Accuracy= 0.64062\n",
      "Iter 150528, Minibatch Loss= 4430.319824, Training Accuracy= 0.59375\n",
      "Iter 150592, Minibatch Loss= 1904.209473, Training Accuracy= 0.71875\n",
      "Iter 150656, Minibatch Loss= 2055.017578, Training Accuracy= 0.75000\n",
      "Iter 150720, Minibatch Loss= 2899.986816, Training Accuracy= 0.82812\n",
      "Iter 150784, Minibatch Loss= 2251.251953, Training Accuracy= 0.65625\n",
      "Iter 150848, Minibatch Loss= 4849.392090, Training Accuracy= 0.65625\n",
      "Iter 150912, Minibatch Loss= 4971.985840, Training Accuracy= 0.76562\n",
      "Iter 150976, Minibatch Loss= 1425.361084, Training Accuracy= 0.84375\n",
      "Iter 151040, Minibatch Loss= 3569.477295, Training Accuracy= 0.68750\n",
      "Iter 151104, Minibatch Loss= 4454.983398, Training Accuracy= 0.65625\n",
      "Iter 151168, Minibatch Loss= 3956.455322, Training Accuracy= 0.64062\n",
      "Iter 151232, Minibatch Loss= 2893.281738, Training Accuracy= 0.64062\n",
      "Iter 151296, Minibatch Loss= 3063.997559, Training Accuracy= 0.60938\n",
      "Iter 151360, Minibatch Loss= 4312.426270, Training Accuracy= 0.67188\n",
      "Iter 151424, Minibatch Loss= 3186.020264, Training Accuracy= 0.71875\n",
      "Iter 151488, Minibatch Loss= 2653.973633, Training Accuracy= 0.67188\n",
      "Iter 151552, Minibatch Loss= 5132.968262, Training Accuracy= 0.62500\n",
      "Iter 151616, Minibatch Loss= 3766.833252, Training Accuracy= 0.60938\n",
      "Iter 151680, Minibatch Loss= 4560.349609, Training Accuracy= 0.71875\n",
      "Iter 151744, Minibatch Loss= 3503.871094, Training Accuracy= 0.73438\n",
      "Iter 151808, Minibatch Loss= 2592.058105, Training Accuracy= 0.73438\n",
      "Iter 151872, Minibatch Loss= 4280.244141, Training Accuracy= 0.60938\n",
      "Iter 151936, Minibatch Loss= 4530.100586, Training Accuracy= 0.57812\n",
      "Iter 152000, Minibatch Loss= 4235.209473, Training Accuracy= 0.78125\n",
      "Iter 152064, Minibatch Loss= 1956.329468, Training Accuracy= 0.68750\n",
      "Iter 152128, Minibatch Loss= 7052.671875, Training Accuracy= 0.53125\n",
      "Iter 152192, Minibatch Loss= 3031.313965, Training Accuracy= 0.71875\n",
      "Iter 152256, Minibatch Loss= 3558.170898, Training Accuracy= 0.62500\n",
      "Iter 152320, Minibatch Loss= 2017.484863, Training Accuracy= 0.73438\n",
      "Iter 152384, Minibatch Loss= 7172.627930, Training Accuracy= 0.56250\n",
      "Iter 152448, Minibatch Loss= 2692.308594, Training Accuracy= 0.68750\n",
      "Iter 152512, Minibatch Loss= 5012.407227, Training Accuracy= 0.62500\n",
      "Iter 152576, Minibatch Loss= 3983.881348, Training Accuracy= 0.59375\n",
      "Iter 152640, Minibatch Loss= 4590.957031, Training Accuracy= 0.60938\n",
      "Iter 152704, Minibatch Loss= 3801.140137, Training Accuracy= 0.70312\n",
      "Iter 152768, Minibatch Loss= 3754.941406, Training Accuracy= 0.65625\n",
      "Iter 152832, Minibatch Loss= 3604.645996, Training Accuracy= 0.67188\n",
      "Iter 152896, Minibatch Loss= 2911.039062, Training Accuracy= 0.78125\n",
      "Iter 152960, Minibatch Loss= 3362.747070, Training Accuracy= 0.62500\n",
      "Iter 153024, Minibatch Loss= 2928.833496, Training Accuracy= 0.71875\n",
      "Iter 153088, Minibatch Loss= 2868.800293, Training Accuracy= 0.59375\n",
      "Iter 153152, Minibatch Loss= 1728.457397, Training Accuracy= 0.79688\n",
      "Iter 153216, Minibatch Loss= 3709.589844, Training Accuracy= 0.75000\n",
      "Iter 153280, Minibatch Loss= 2381.436035, Training Accuracy= 0.70312\n",
      "Iter 153344, Minibatch Loss= 3850.674316, Training Accuracy= 0.78125\n",
      "Iter 153408, Minibatch Loss= 2725.585205, Training Accuracy= 0.68750\n",
      "Iter 153472, Minibatch Loss= 2925.898193, Training Accuracy= 0.75000\n",
      "Iter 153536, Minibatch Loss= 4278.903320, Training Accuracy= 0.68750\n",
      "Iter 153600, Minibatch Loss= 3393.848145, Training Accuracy= 0.67188\n",
      "Iter 153664, Minibatch Loss= 5616.233398, Training Accuracy= 0.57812\n",
      "Iter 153728, Minibatch Loss= 5345.772949, Training Accuracy= 0.64062\n",
      "Iter 153792, Minibatch Loss= 1681.045898, Training Accuracy= 0.76562\n",
      "Iter 153856, Minibatch Loss= 3761.365234, Training Accuracy= 0.71875\n",
      "Iter 153920, Minibatch Loss= 2855.164551, Training Accuracy= 0.70312\n",
      "Iter 153984, Minibatch Loss= 4306.022461, Training Accuracy= 0.76562\n",
      "Iter 154048, Minibatch Loss= 4342.122070, Training Accuracy= 0.71875\n",
      "Iter 154112, Minibatch Loss= 4242.161133, Training Accuracy= 0.67188\n",
      "Iter 154176, Minibatch Loss= 3270.018555, Training Accuracy= 0.67188\n",
      "Iter 154240, Minibatch Loss= 2466.288818, Training Accuracy= 0.75000\n",
      "Iter 154304, Minibatch Loss= 2008.728760, Training Accuracy= 0.76562\n",
      "Iter 154368, Minibatch Loss= 2737.675049, Training Accuracy= 0.70312\n",
      "Iter 154432, Minibatch Loss= 2606.440430, Training Accuracy= 0.70312\n",
      "Iter 154496, Minibatch Loss= 2286.881348, Training Accuracy= 0.73438\n",
      "Iter 154560, Minibatch Loss= 1399.488770, Training Accuracy= 0.75000\n",
      "Iter 154624, Minibatch Loss= 1873.687256, Training Accuracy= 0.79688\n",
      "Iter 154688, Minibatch Loss= 2024.565674, Training Accuracy= 0.81250\n",
      "Iter 154752, Minibatch Loss= 1886.697266, Training Accuracy= 0.73438\n",
      "Iter 154816, Minibatch Loss= 3982.364258, Training Accuracy= 0.82812\n",
      "Iter 154880, Minibatch Loss= 2745.334961, Training Accuracy= 0.71875\n",
      "Iter 154944, Minibatch Loss= 3671.477783, Training Accuracy= 0.70312\n",
      "Iter 155008, Minibatch Loss= 2480.505859, Training Accuracy= 0.76562\n",
      "Iter 155072, Minibatch Loss= 5189.061523, Training Accuracy= 0.67188\n",
      "Iter 155136, Minibatch Loss= 3344.995605, Training Accuracy= 0.65625\n",
      "Iter 155200, Minibatch Loss= 3319.949707, Training Accuracy= 0.81250\n",
      "Iter 155264, Minibatch Loss= 2461.090088, Training Accuracy= 0.78125\n",
      "Iter 155328, Minibatch Loss= 2071.805664, Training Accuracy= 0.78125\n",
      "Iter 155392, Minibatch Loss= 4901.440430, Training Accuracy= 0.68750\n",
      "Iter 155456, Minibatch Loss= 2179.178955, Training Accuracy= 0.79688\n",
      "Iter 155520, Minibatch Loss= 2548.876465, Training Accuracy= 0.60938\n",
      "Iter 155584, Minibatch Loss= 2253.001953, Training Accuracy= 0.70312\n",
      "Iter 155648, Minibatch Loss= 2735.436523, Training Accuracy= 0.76562\n",
      "Iter 155712, Minibatch Loss= 3580.590332, Training Accuracy= 0.68750\n",
      "Iter 155776, Minibatch Loss= 3356.731934, Training Accuracy= 0.56250\n",
      "Iter 155840, Minibatch Loss= 2649.357910, Training Accuracy= 0.68750\n",
      "Iter 155904, Minibatch Loss= 2874.942383, Training Accuracy= 0.70312\n",
      "Iter 155968, Minibatch Loss= 1607.878906, Training Accuracy= 0.81250\n",
      "Iter 156032, Minibatch Loss= 2463.853027, Training Accuracy= 0.70312\n",
      "Iter 156096, Minibatch Loss= 1886.687012, Training Accuracy= 0.81250\n",
      "Iter 156160, Minibatch Loss= 2815.608887, Training Accuracy= 0.75000\n",
      "Iter 156224, Minibatch Loss= 2593.240723, Training Accuracy= 0.71875\n",
      "Iter 156288, Minibatch Loss= 1256.886597, Training Accuracy= 0.82812\n",
      "Iter 156352, Minibatch Loss= 2549.310059, Training Accuracy= 0.73438\n",
      "Iter 156416, Minibatch Loss= 3058.510254, Training Accuracy= 0.71875\n",
      "Iter 156480, Minibatch Loss= 2361.450684, Training Accuracy= 0.73438\n",
      "Iter 156544, Minibatch Loss= 2913.336426, Training Accuracy= 0.81250\n",
      "Iter 156608, Minibatch Loss= 4257.408203, Training Accuracy= 0.73438\n",
      "Iter 156672, Minibatch Loss= 3005.573730, Training Accuracy= 0.68750\n",
      "Iter 156736, Minibatch Loss= 1674.465210, Training Accuracy= 0.81250\n",
      "Iter 156800, Minibatch Loss= 4220.652832, Training Accuracy= 0.78125\n",
      "Iter 156864, Minibatch Loss= 3242.779541, Training Accuracy= 0.67188\n",
      "Iter 156928, Minibatch Loss= 5236.685059, Training Accuracy= 0.62500\n",
      "Iter 156992, Minibatch Loss= 3153.079590, Training Accuracy= 0.68750\n",
      "Iter 157056, Minibatch Loss= 2973.177979, Training Accuracy= 0.75000\n",
      "Iter 157120, Minibatch Loss= 4362.478516, Training Accuracy= 0.64062\n",
      "Iter 157184, Minibatch Loss= 3904.666748, Training Accuracy= 0.68750\n",
      "Iter 157248, Minibatch Loss= 1132.609619, Training Accuracy= 0.81250\n",
      "Iter 157312, Minibatch Loss= 1896.140625, Training Accuracy= 0.68750\n",
      "Iter 157376, Minibatch Loss= 3212.760254, Training Accuracy= 0.65625\n",
      "Iter 157440, Minibatch Loss= 3031.313477, Training Accuracy= 0.70312\n",
      "Iter 157504, Minibatch Loss= 2049.621582, Training Accuracy= 0.81250\n",
      "Iter 157568, Minibatch Loss= 4659.041016, Training Accuracy= 0.67188\n",
      "Iter 157632, Minibatch Loss= 2853.792236, Training Accuracy= 0.67188\n",
      "Iter 157696, Minibatch Loss= 2340.177734, Training Accuracy= 0.75000\n",
      "Iter 157760, Minibatch Loss= 4001.985596, Training Accuracy= 0.59375\n",
      "Iter 157824, Minibatch Loss= 1740.072510, Training Accuracy= 0.79688\n",
      "Iter 157888, Minibatch Loss= 3034.199219, Training Accuracy= 0.68750\n",
      "Iter 157952, Minibatch Loss= 2682.588623, Training Accuracy= 0.65625\n",
      "Iter 158016, Minibatch Loss= 2201.421387, Training Accuracy= 0.70312\n",
      "Iter 158080, Minibatch Loss= 3315.308350, Training Accuracy= 0.73438\n",
      "Iter 158144, Minibatch Loss= 4020.184570, Training Accuracy= 0.67188\n",
      "Iter 158208, Minibatch Loss= 3891.876221, Training Accuracy= 0.70312\n",
      "Iter 158272, Minibatch Loss= 1108.538696, Training Accuracy= 0.85938\n",
      "Iter 158336, Minibatch Loss= 4770.028320, Training Accuracy= 0.65625\n",
      "Iter 158400, Minibatch Loss= 3414.244141, Training Accuracy= 0.62500\n",
      "Iter 158464, Minibatch Loss= 4647.940918, Training Accuracy= 0.60938\n",
      "Iter 158528, Minibatch Loss= 5046.936523, Training Accuracy= 0.59375\n",
      "Iter 158592, Minibatch Loss= 1907.907593, Training Accuracy= 0.64062\n",
      "Iter 158656, Minibatch Loss= 3263.807129, Training Accuracy= 0.73438\n",
      "Iter 158720, Minibatch Loss= 1616.401978, Training Accuracy= 0.73438\n",
      "Iter 158784, Minibatch Loss= 2298.625488, Training Accuracy= 0.75000\n",
      "Iter 158848, Minibatch Loss= 2853.597900, Training Accuracy= 0.73438\n",
      "Iter 158912, Minibatch Loss= 1788.709595, Training Accuracy= 0.79688\n",
      "Iter 158976, Minibatch Loss= 1445.106323, Training Accuracy= 0.78125\n",
      "Iter 159040, Minibatch Loss= 1792.169067, Training Accuracy= 0.70312\n",
      "Iter 159104, Minibatch Loss= 1435.504395, Training Accuracy= 0.82812\n",
      "Iter 159168, Minibatch Loss= 3498.054199, Training Accuracy= 0.68750\n",
      "Iter 159232, Minibatch Loss= 1889.687744, Training Accuracy= 0.78125\n",
      "Iter 159296, Minibatch Loss= 2584.035645, Training Accuracy= 0.81250\n",
      "Iter 159360, Minibatch Loss= 1576.854004, Training Accuracy= 0.82812\n",
      "Iter 159424, Minibatch Loss= 2774.470947, Training Accuracy= 0.70312\n",
      "Iter 159488, Minibatch Loss= 3787.336426, Training Accuracy= 0.71875\n",
      "Iter 159552, Minibatch Loss= 2734.708740, Training Accuracy= 0.68750\n",
      "Iter 159616, Minibatch Loss= 1932.209229, Training Accuracy= 0.71875\n",
      "Iter 159680, Minibatch Loss= 3208.846191, Training Accuracy= 0.65625\n",
      "Iter 159744, Minibatch Loss= 4087.586426, Training Accuracy= 0.62500\n",
      "Iter 159808, Minibatch Loss= 3981.233887, Training Accuracy= 0.59375\n",
      "Iter 159872, Minibatch Loss= 2792.792480, Training Accuracy= 0.70312\n",
      "Iter 159936, Minibatch Loss= 2951.270508, Training Accuracy= 0.71875\n",
      "Iter 160000, Minibatch Loss= 2239.520508, Training Accuracy= 0.73438\n",
      "Iter 160064, Minibatch Loss= 3443.000732, Training Accuracy= 0.73438\n",
      "Iter 160128, Minibatch Loss= 3026.055176, Training Accuracy= 0.67188\n",
      "Iter 160192, Minibatch Loss= 2430.244873, Training Accuracy= 0.75000\n",
      "Iter 160256, Minibatch Loss= 5065.971191, Training Accuracy= 0.64062\n",
      "Iter 160320, Minibatch Loss= 4184.234375, Training Accuracy= 0.70312\n",
      "Iter 160384, Minibatch Loss= 3980.175293, Training Accuracy= 0.65625\n",
      "Iter 160448, Minibatch Loss= 4184.184082, Training Accuracy= 0.64062\n",
      "Iter 160512, Minibatch Loss= 3980.335205, Training Accuracy= 0.73438\n",
      "Iter 160576, Minibatch Loss= 3814.058838, Training Accuracy= 0.59375\n",
      "Iter 160640, Minibatch Loss= 3714.296875, Training Accuracy= 0.60938\n",
      "Iter 160704, Minibatch Loss= 1890.047607, Training Accuracy= 0.76562\n",
      "Iter 160768, Minibatch Loss= 1773.372681, Training Accuracy= 0.75000\n",
      "Iter 160832, Minibatch Loss= 3181.784424, Training Accuracy= 0.62500\n",
      "Iter 160896, Minibatch Loss= 3474.077637, Training Accuracy= 0.73438\n",
      "Iter 160960, Minibatch Loss= 1637.402832, Training Accuracy= 0.75000\n",
      "Iter 161024, Minibatch Loss= 2023.992798, Training Accuracy= 0.73438\n",
      "Iter 161088, Minibatch Loss= 2152.915283, Training Accuracy= 0.76562\n",
      "Iter 161152, Minibatch Loss= 1454.358398, Training Accuracy= 0.75000\n",
      "Iter 161216, Minibatch Loss= 2574.729492, Training Accuracy= 0.71875\n",
      "Iter 161280, Minibatch Loss= 3248.874023, Training Accuracy= 0.65625\n",
      "Iter 161344, Minibatch Loss= 2715.728271, Training Accuracy= 0.71875\n",
      "Iter 161408, Minibatch Loss= 1606.834595, Training Accuracy= 0.76562\n",
      "Iter 161472, Minibatch Loss= 3005.698730, Training Accuracy= 0.65625\n",
      "Iter 161536, Minibatch Loss= 2887.389648, Training Accuracy= 0.68750\n",
      "Iter 161600, Minibatch Loss= 2802.938965, Training Accuracy= 0.71875\n",
      "Iter 161664, Minibatch Loss= 2559.696289, Training Accuracy= 0.70312\n",
      "Iter 161728, Minibatch Loss= 3463.207764, Training Accuracy= 0.65625\n",
      "Iter 161792, Minibatch Loss= 3776.461426, Training Accuracy= 0.65625\n",
      "Iter 161856, Minibatch Loss= 2240.090088, Training Accuracy= 0.73438\n",
      "Iter 161920, Minibatch Loss= 2904.316895, Training Accuracy= 0.75000\n",
      "Iter 161984, Minibatch Loss= 3184.968750, Training Accuracy= 0.67188\n",
      "Iter 162048, Minibatch Loss= 4550.012695, Training Accuracy= 0.64062\n",
      "Iter 162112, Minibatch Loss= 3625.021973, Training Accuracy= 0.68750\n",
      "Iter 162176, Minibatch Loss= 2343.994141, Training Accuracy= 0.75000\n",
      "Iter 162240, Minibatch Loss= 3584.990723, Training Accuracy= 0.68750\n",
      "Iter 162304, Minibatch Loss= 1794.197510, Training Accuracy= 0.76562\n",
      "Iter 162368, Minibatch Loss= 984.690063, Training Accuracy= 0.75000\n",
      "Iter 162432, Minibatch Loss= 1959.290894, Training Accuracy= 0.65625\n",
      "Iter 162496, Minibatch Loss= 2105.366699, Training Accuracy= 0.70312\n",
      "Iter 162560, Minibatch Loss= 1472.181763, Training Accuracy= 0.76562\n",
      "Iter 162624, Minibatch Loss= 2434.245605, Training Accuracy= 0.76562\n",
      "Iter 162688, Minibatch Loss= 2148.717773, Training Accuracy= 0.67188\n",
      "Iter 162752, Minibatch Loss= 4697.614258, Training Accuracy= 0.62500\n",
      "Iter 162816, Minibatch Loss= 4413.794922, Training Accuracy= 0.62500\n",
      "Iter 162880, Minibatch Loss= 5066.193359, Training Accuracy= 0.73438\n",
      "Iter 162944, Minibatch Loss= 3998.773438, Training Accuracy= 0.59375\n",
      "Iter 163008, Minibatch Loss= 3335.020508, Training Accuracy= 0.67188\n",
      "Iter 163072, Minibatch Loss= 2458.244629, Training Accuracy= 0.68750\n",
      "Iter 163136, Minibatch Loss= 2642.312256, Training Accuracy= 0.73438\n",
      "Iter 163200, Minibatch Loss= 1796.031616, Training Accuracy= 0.71875\n",
      "Iter 163264, Minibatch Loss= 3554.912598, Training Accuracy= 0.73438\n",
      "Iter 163328, Minibatch Loss= 4141.622070, Training Accuracy= 0.70312\n",
      "Iter 163392, Minibatch Loss= 3347.430420, Training Accuracy= 0.71875\n",
      "Iter 163456, Minibatch Loss= 1488.971680, Training Accuracy= 0.75000\n",
      "Iter 163520, Minibatch Loss= 1533.818604, Training Accuracy= 0.78125\n",
      "Iter 163584, Minibatch Loss= 1234.795166, Training Accuracy= 0.78125\n",
      "Iter 163648, Minibatch Loss= 3207.757812, Training Accuracy= 0.68750\n",
      "Iter 163712, Minibatch Loss= 1183.682129, Training Accuracy= 0.73438\n",
      "Iter 163776, Minibatch Loss= 2087.249512, Training Accuracy= 0.67188\n",
      "Iter 163840, Minibatch Loss= 2150.847412, Training Accuracy= 0.73438\n",
      "Iter 163904, Minibatch Loss= 1624.286743, Training Accuracy= 0.73438\n",
      "Iter 163968, Minibatch Loss= 2284.868408, Training Accuracy= 0.71875\n",
      "Iter 164032, Minibatch Loss= 2855.289551, Training Accuracy= 0.76562\n",
      "Iter 164096, Minibatch Loss= 4782.614258, Training Accuracy= 0.65625\n",
      "Iter 164160, Minibatch Loss= 2370.278076, Training Accuracy= 0.71875\n",
      "Iter 164224, Minibatch Loss= 2385.210205, Training Accuracy= 0.76562\n",
      "Iter 164288, Minibatch Loss= 5239.105957, Training Accuracy= 0.65625\n",
      "Iter 164352, Minibatch Loss= 2920.018555, Training Accuracy= 0.65625\n",
      "Iter 164416, Minibatch Loss= 4358.961914, Training Accuracy= 0.64062\n",
      "Iter 164480, Minibatch Loss= 3172.636230, Training Accuracy= 0.65625\n",
      "Iter 164544, Minibatch Loss= 3602.760986, Training Accuracy= 0.71875\n",
      "Iter 164608, Minibatch Loss= 1879.377075, Training Accuracy= 0.81250\n",
      "Iter 164672, Minibatch Loss= 2689.524414, Training Accuracy= 0.71875\n",
      "Iter 164736, Minibatch Loss= 4355.773926, Training Accuracy= 0.51562\n",
      "Iter 164800, Minibatch Loss= 2357.281494, Training Accuracy= 0.71875\n",
      "Iter 164864, Minibatch Loss= 2607.984375, Training Accuracy= 0.68750\n",
      "Iter 164928, Minibatch Loss= 2165.724121, Training Accuracy= 0.75000\n",
      "Iter 164992, Minibatch Loss= 3612.604492, Training Accuracy= 0.68750\n",
      "Iter 165056, Minibatch Loss= 3488.625000, Training Accuracy= 0.62500\n",
      "Iter 165120, Minibatch Loss= 2367.286377, Training Accuracy= 0.64062\n",
      "Iter 165184, Minibatch Loss= 2985.036865, Training Accuracy= 0.71875\n",
      "Iter 165248, Minibatch Loss= 1720.848755, Training Accuracy= 0.81250\n",
      "Iter 165312, Minibatch Loss= 4613.151367, Training Accuracy= 0.65625\n",
      "Iter 165376, Minibatch Loss= 4925.421875, Training Accuracy= 0.71875\n",
      "Iter 165440, Minibatch Loss= 3427.697266, Training Accuracy= 0.71875\n",
      "Iter 165504, Minibatch Loss= 4900.814453, Training Accuracy= 0.56250\n",
      "Iter 165568, Minibatch Loss= 2619.446289, Training Accuracy= 0.71875\n",
      "Iter 165632, Minibatch Loss= 3940.520020, Training Accuracy= 0.59375\n",
      "Iter 165696, Minibatch Loss= 1590.854248, Training Accuracy= 0.73438\n",
      "Iter 165760, Minibatch Loss= 3710.323486, Training Accuracy= 0.65625\n",
      "Iter 165824, Minibatch Loss= 2169.710938, Training Accuracy= 0.71875\n",
      "Iter 165888, Minibatch Loss= 4628.614746, Training Accuracy= 0.67188\n",
      "Iter 165952, Minibatch Loss= 2370.938965, Training Accuracy= 0.71875\n",
      "Iter 166016, Minibatch Loss= 2250.251465, Training Accuracy= 0.65625\n",
      "Iter 166080, Minibatch Loss= 3563.158691, Training Accuracy= 0.60938\n",
      "Iter 166144, Minibatch Loss= 1544.422607, Training Accuracy= 0.76562\n",
      "Iter 166208, Minibatch Loss= 2613.985840, Training Accuracy= 0.65625\n",
      "Iter 166272, Minibatch Loss= 2659.164062, Training Accuracy= 0.68750\n",
      "Iter 166336, Minibatch Loss= 3467.399902, Training Accuracy= 0.64062\n",
      "Iter 166400, Minibatch Loss= 3789.306641, Training Accuracy= 0.65625\n",
      "Iter 166464, Minibatch Loss= 2685.227051, Training Accuracy= 0.68750\n",
      "Iter 166528, Minibatch Loss= 3459.405762, Training Accuracy= 0.75000\n",
      "Iter 166592, Minibatch Loss= 3821.199951, Training Accuracy= 0.75000\n",
      "Iter 166656, Minibatch Loss= 3397.242676, Training Accuracy= 0.65625\n",
      "Iter 166720, Minibatch Loss= 2684.232910, Training Accuracy= 0.71875\n",
      "Iter 166784, Minibatch Loss= 5524.101074, Training Accuracy= 0.64062\n",
      "Iter 166848, Minibatch Loss= 2011.317261, Training Accuracy= 0.75000\n",
      "Iter 166912, Minibatch Loss= 2955.239746, Training Accuracy= 0.64062\n",
      "Iter 166976, Minibatch Loss= 3759.798340, Training Accuracy= 0.68750\n",
      "Iter 167040, Minibatch Loss= 2783.828613, Training Accuracy= 0.70312\n",
      "Iter 167104, Minibatch Loss= 1981.344727, Training Accuracy= 0.78125\n",
      "Iter 167168, Minibatch Loss= 1765.514282, Training Accuracy= 0.73438\n",
      "Iter 167232, Minibatch Loss= 2625.592773, Training Accuracy= 0.73438\n",
      "Iter 167296, Minibatch Loss= 3052.633057, Training Accuracy= 0.70312\n",
      "Iter 167360, Minibatch Loss= 1707.935547, Training Accuracy= 0.71875\n",
      "Iter 167424, Minibatch Loss= 1678.077271, Training Accuracy= 0.73438\n",
      "Iter 167488, Minibatch Loss= 3296.809814, Training Accuracy= 0.65625\n",
      "Iter 167552, Minibatch Loss= 1224.060547, Training Accuracy= 0.79688\n",
      "Iter 167616, Minibatch Loss= 2941.959473, Training Accuracy= 0.67188\n",
      "Iter 167680, Minibatch Loss= 2130.418945, Training Accuracy= 0.76562\n",
      "Iter 167744, Minibatch Loss= 1456.411377, Training Accuracy= 0.78125\n",
      "Iter 167808, Minibatch Loss= 2393.433594, Training Accuracy= 0.76562\n",
      "Iter 167872, Minibatch Loss= 2988.421143, Training Accuracy= 0.71875\n",
      "Iter 167936, Minibatch Loss= 2304.591064, Training Accuracy= 0.71875\n",
      "Iter 168000, Minibatch Loss= 2709.666504, Training Accuracy= 0.70312\n",
      "Iter 168064, Minibatch Loss= 2834.678711, Training Accuracy= 0.68750\n",
      "Iter 168128, Minibatch Loss= 3549.673828, Training Accuracy= 0.68750\n",
      "Iter 168192, Minibatch Loss= 2332.477539, Training Accuracy= 0.79688\n",
      "Iter 168256, Minibatch Loss= 3203.342773, Training Accuracy= 0.73438\n",
      "Iter 168320, Minibatch Loss= 3467.054688, Training Accuracy= 0.70312\n",
      "Iter 168384, Minibatch Loss= 3710.365234, Training Accuracy= 0.70312\n",
      "Iter 168448, Minibatch Loss= 2129.556885, Training Accuracy= 0.81250\n",
      "Iter 168512, Minibatch Loss= 2429.568359, Training Accuracy= 0.75000\n",
      "Iter 168576, Minibatch Loss= 3252.815674, Training Accuracy= 0.68750\n",
      "Iter 168640, Minibatch Loss= 2441.214355, Training Accuracy= 0.67188\n",
      "Iter 168704, Minibatch Loss= 3593.137207, Training Accuracy= 0.62500\n",
      "Iter 168768, Minibatch Loss= 2477.603760, Training Accuracy= 0.70312\n",
      "Iter 168832, Minibatch Loss= 2530.556641, Training Accuracy= 0.76562\n",
      "Iter 168896, Minibatch Loss= 2359.516113, Training Accuracy= 0.71875\n",
      "Iter 168960, Minibatch Loss= 3291.745605, Training Accuracy= 0.78125\n",
      "Iter 169024, Minibatch Loss= 2249.162598, Training Accuracy= 0.65625\n",
      "Iter 169088, Minibatch Loss= 3292.604492, Training Accuracy= 0.68750\n",
      "Iter 169152, Minibatch Loss= 2525.038574, Training Accuracy= 0.76562\n",
      "Iter 169216, Minibatch Loss= 2576.176270, Training Accuracy= 0.71875\n",
      "Iter 169280, Minibatch Loss= 1734.916016, Training Accuracy= 0.75000\n",
      "Iter 169344, Minibatch Loss= 3721.693359, Training Accuracy= 0.64062\n",
      "Iter 169408, Minibatch Loss= 5231.658203, Training Accuracy= 0.65625\n",
      "Iter 169472, Minibatch Loss= 3933.331543, Training Accuracy= 0.65625\n",
      "Iter 169536, Minibatch Loss= 3882.155029, Training Accuracy= 0.67188\n",
      "Iter 169600, Minibatch Loss= 3708.434570, Training Accuracy= 0.65625\n",
      "Iter 169664, Minibatch Loss= 2141.776367, Training Accuracy= 0.78125\n",
      "Iter 169728, Minibatch Loss= 1304.193115, Training Accuracy= 0.82812\n",
      "Iter 169792, Minibatch Loss= 2900.140625, Training Accuracy= 0.65625\n",
      "Iter 169856, Minibatch Loss= 2381.942871, Training Accuracy= 0.70312\n",
      "Iter 169920, Minibatch Loss= 1118.842285, Training Accuracy= 0.81250\n",
      "Iter 169984, Minibatch Loss= 1140.196289, Training Accuracy= 0.78125\n",
      "Iter 170048, Minibatch Loss= 3009.006104, Training Accuracy= 0.70312\n",
      "Iter 170112, Minibatch Loss= 3133.371582, Training Accuracy= 0.73438\n",
      "Iter 170176, Minibatch Loss= 1156.641357, Training Accuracy= 0.81250\n",
      "Iter 170240, Minibatch Loss= 1603.303467, Training Accuracy= 0.82812\n",
      "Iter 170304, Minibatch Loss= 3342.783203, Training Accuracy= 0.76562\n",
      "Iter 170368, Minibatch Loss= 2088.702637, Training Accuracy= 0.81250\n",
      "Iter 170432, Minibatch Loss= 3423.236572, Training Accuracy= 0.64062\n",
      "Iter 170496, Minibatch Loss= 2299.689453, Training Accuracy= 0.71875\n",
      "Iter 170560, Minibatch Loss= 3633.355957, Training Accuracy= 0.76562\n",
      "Iter 170624, Minibatch Loss= 1452.588013, Training Accuracy= 0.67188\n",
      "Iter 170688, Minibatch Loss= 1928.308838, Training Accuracy= 0.70312\n",
      "Iter 170752, Minibatch Loss= 2658.102051, Training Accuracy= 0.79688\n",
      "Iter 170816, Minibatch Loss= 1981.939941, Training Accuracy= 0.71875\n",
      "Iter 170880, Minibatch Loss= 2435.130371, Training Accuracy= 0.79688\n",
      "Iter 170944, Minibatch Loss= 3222.799316, Training Accuracy= 0.79688\n",
      "Iter 171008, Minibatch Loss= 2217.342285, Training Accuracy= 0.75000\n",
      "Iter 171072, Minibatch Loss= 2734.392090, Training Accuracy= 0.67188\n",
      "Iter 171136, Minibatch Loss= 2110.962891, Training Accuracy= 0.73438\n",
      "Iter 171200, Minibatch Loss= 2355.799805, Training Accuracy= 0.70312\n",
      "Iter 171264, Minibatch Loss= 3029.119629, Training Accuracy= 0.73438\n",
      "Iter 171328, Minibatch Loss= 2439.182617, Training Accuracy= 0.71875\n",
      "Iter 171392, Minibatch Loss= 3490.045654, Training Accuracy= 0.62500\n",
      "Iter 171456, Minibatch Loss= 2558.962891, Training Accuracy= 0.68750\n",
      "Iter 171520, Minibatch Loss= 1634.189575, Training Accuracy= 0.71875\n",
      "Iter 171584, Minibatch Loss= 1292.497681, Training Accuracy= 0.71875\n",
      "Iter 171648, Minibatch Loss= 1406.110352, Training Accuracy= 0.82812\n",
      "Iter 171712, Minibatch Loss= 2594.868896, Training Accuracy= 0.70312\n",
      "Iter 171776, Minibatch Loss= 2284.208496, Training Accuracy= 0.76562\n",
      "Iter 171840, Minibatch Loss= 2485.476074, Training Accuracy= 0.75000\n",
      "Iter 171904, Minibatch Loss= 4043.123535, Training Accuracy= 0.68750\n",
      "Iter 171968, Minibatch Loss= 2428.677002, Training Accuracy= 0.75000\n",
      "Iter 172032, Minibatch Loss= 3993.375732, Training Accuracy= 0.62500\n",
      "Iter 172096, Minibatch Loss= 3141.149414, Training Accuracy= 0.73438\n",
      "Iter 172160, Minibatch Loss= 2519.362305, Training Accuracy= 0.62500\n",
      "Iter 172224, Minibatch Loss= 4508.139648, Training Accuracy= 0.70312\n",
      "Iter 172288, Minibatch Loss= 1346.882935, Training Accuracy= 0.85938\n",
      "Iter 172352, Minibatch Loss= 1785.946045, Training Accuracy= 0.75000\n",
      "Iter 172416, Minibatch Loss= 2818.178467, Training Accuracy= 0.76562\n",
      "Iter 172480, Minibatch Loss= 2428.714600, Training Accuracy= 0.65625\n",
      "Iter 172544, Minibatch Loss= 3022.517090, Training Accuracy= 0.70312\n",
      "Iter 172608, Minibatch Loss= 1480.220947, Training Accuracy= 0.78125\n",
      "Iter 172672, Minibatch Loss= 3149.354004, Training Accuracy= 0.73438\n",
      "Iter 172736, Minibatch Loss= 3409.562988, Training Accuracy= 0.65625\n",
      "Iter 172800, Minibatch Loss= 3678.193359, Training Accuracy= 0.53125\n",
      "Iter 172864, Minibatch Loss= 1556.627319, Training Accuracy= 0.70312\n",
      "Iter 172928, Minibatch Loss= 3360.854980, Training Accuracy= 0.60938\n",
      "Iter 172992, Minibatch Loss= 2273.493164, Training Accuracy= 0.70312\n",
      "Iter 173056, Minibatch Loss= 2905.455078, Training Accuracy= 0.71875\n",
      "Iter 173120, Minibatch Loss= 1888.415283, Training Accuracy= 0.71875\n",
      "Iter 173184, Minibatch Loss= 1981.619751, Training Accuracy= 0.75000\n",
      "Iter 173248, Minibatch Loss= 3105.237549, Training Accuracy= 0.67188\n",
      "Iter 173312, Minibatch Loss= 3399.776367, Training Accuracy= 0.71875\n",
      "Iter 173376, Minibatch Loss= 2826.027832, Training Accuracy= 0.71875\n",
      "Iter 173440, Minibatch Loss= 1795.384155, Training Accuracy= 0.70312\n",
      "Iter 173504, Minibatch Loss= 1525.316895, Training Accuracy= 0.73438\n",
      "Iter 173568, Minibatch Loss= 2892.004883, Training Accuracy= 0.68750\n",
      "Iter 173632, Minibatch Loss= 1714.208252, Training Accuracy= 0.79688\n",
      "Iter 173696, Minibatch Loss= 2199.252930, Training Accuracy= 0.67188\n",
      "Iter 173760, Minibatch Loss= 3100.907471, Training Accuracy= 0.78125\n",
      "Iter 173824, Minibatch Loss= 3140.410156, Training Accuracy= 0.76562\n",
      "Iter 173888, Minibatch Loss= 1771.333008, Training Accuracy= 0.71875\n",
      "Iter 173952, Minibatch Loss= 4515.229492, Training Accuracy= 0.64062\n",
      "Iter 174016, Minibatch Loss= 4036.895020, Training Accuracy= 0.67188\n",
      "Iter 174080, Minibatch Loss= 2861.779785, Training Accuracy= 0.60938\n",
      "Iter 174144, Minibatch Loss= 2625.550781, Training Accuracy= 0.67188\n",
      "Iter 174208, Minibatch Loss= 2808.540527, Training Accuracy= 0.70312\n",
      "Iter 174272, Minibatch Loss= 1909.257812, Training Accuracy= 0.68750\n",
      "Iter 174336, Minibatch Loss= 3100.755859, Training Accuracy= 0.73438\n",
      "Iter 174400, Minibatch Loss= 2313.237793, Training Accuracy= 0.67188\n",
      "Iter 174464, Minibatch Loss= 3065.104980, Training Accuracy= 0.73438\n",
      "Iter 174528, Minibatch Loss= 2563.605225, Training Accuracy= 0.70312\n",
      "Iter 174592, Minibatch Loss= 2789.626953, Training Accuracy= 0.68750\n",
      "Iter 174656, Minibatch Loss= 2583.904297, Training Accuracy= 0.79688\n",
      "Iter 174720, Minibatch Loss= 2473.458252, Training Accuracy= 0.79688\n",
      "Iter 174784, Minibatch Loss= 3518.252441, Training Accuracy= 0.68750\n",
      "Iter 174848, Minibatch Loss= 2657.254395, Training Accuracy= 0.64062\n",
      "Iter 174912, Minibatch Loss= 2681.865479, Training Accuracy= 0.67188\n",
      "Iter 174976, Minibatch Loss= 4638.538086, Training Accuracy= 0.64062\n",
      "Iter 175040, Minibatch Loss= 3846.344971, Training Accuracy= 0.68750\n",
      "Iter 175104, Minibatch Loss= 2643.668701, Training Accuracy= 0.62500\n",
      "Iter 175168, Minibatch Loss= 2124.027344, Training Accuracy= 0.71875\n",
      "Iter 175232, Minibatch Loss= 1074.344482, Training Accuracy= 0.82812\n",
      "Iter 175296, Minibatch Loss= 2669.220215, Training Accuracy= 0.76562\n",
      "Iter 175360, Minibatch Loss= 3317.746582, Training Accuracy= 0.70312\n",
      "Iter 175424, Minibatch Loss= 3959.239746, Training Accuracy= 0.82812\n",
      "Iter 175488, Minibatch Loss= 1511.528076, Training Accuracy= 0.81250\n",
      "Iter 175552, Minibatch Loss= 3154.877441, Training Accuracy= 0.64062\n",
      "Iter 175616, Minibatch Loss= 2079.205078, Training Accuracy= 0.76562\n",
      "Iter 175680, Minibatch Loss= 2745.644043, Training Accuracy= 0.76562\n",
      "Iter 175744, Minibatch Loss= 2703.647949, Training Accuracy= 0.70312\n",
      "Iter 175808, Minibatch Loss= 3888.941650, Training Accuracy= 0.62500\n",
      "Iter 175872, Minibatch Loss= 3110.353516, Training Accuracy= 0.65625\n",
      "Iter 175936, Minibatch Loss= 4257.168945, Training Accuracy= 0.64062\n",
      "Iter 176000, Minibatch Loss= 6232.326172, Training Accuracy= 0.57812\n",
      "Iter 176064, Minibatch Loss= 3266.715088, Training Accuracy= 0.62500\n",
      "Iter 176128, Minibatch Loss= 3716.457520, Training Accuracy= 0.62500\n",
      "Iter 176192, Minibatch Loss= 5571.264160, Training Accuracy= 0.59375\n",
      "Iter 176256, Minibatch Loss= 2114.772949, Training Accuracy= 0.67188\n",
      "Iter 176320, Minibatch Loss= 2993.003418, Training Accuracy= 0.73438\n",
      "Iter 176384, Minibatch Loss= 1439.556396, Training Accuracy= 0.81250\n",
      "Iter 176448, Minibatch Loss= 3906.211914, Training Accuracy= 0.70312\n",
      "Iter 176512, Minibatch Loss= 4175.838379, Training Accuracy= 0.67188\n",
      "Iter 176576, Minibatch Loss= 2410.027832, Training Accuracy= 0.73438\n",
      "Iter 176640, Minibatch Loss= 3339.145264, Training Accuracy= 0.73438\n",
      "Iter 176704, Minibatch Loss= 3299.571777, Training Accuracy= 0.73438\n",
      "Iter 176768, Minibatch Loss= 3512.402344, Training Accuracy= 0.70312\n",
      "Iter 176832, Minibatch Loss= 2256.866943, Training Accuracy= 0.68750\n",
      "Iter 176896, Minibatch Loss= 3498.927246, Training Accuracy= 0.62500\n",
      "Iter 176960, Minibatch Loss= 5380.905273, Training Accuracy= 0.62500\n",
      "Iter 177024, Minibatch Loss= 4214.551758, Training Accuracy= 0.65625\n",
      "Iter 177088, Minibatch Loss= 5711.051270, Training Accuracy= 0.68750\n",
      "Iter 177152, Minibatch Loss= 3135.747070, Training Accuracy= 0.73438\n",
      "Iter 177216, Minibatch Loss= 2397.345215, Training Accuracy= 0.68750\n",
      "Iter 177280, Minibatch Loss= 4293.123047, Training Accuracy= 0.59375\n",
      "Iter 177344, Minibatch Loss= 3089.773438, Training Accuracy= 0.67188\n",
      "Iter 177408, Minibatch Loss= 2845.477783, Training Accuracy= 0.68750\n",
      "Iter 177472, Minibatch Loss= 2105.540039, Training Accuracy= 0.70312\n",
      "Iter 177536, Minibatch Loss= 3951.513916, Training Accuracy= 0.67188\n",
      "Iter 177600, Minibatch Loss= 3969.365234, Training Accuracy= 0.65625\n",
      "Iter 177664, Minibatch Loss= 3236.855469, Training Accuracy= 0.67188\n",
      "Iter 177728, Minibatch Loss= 2406.025635, Training Accuracy= 0.71875\n",
      "Iter 177792, Minibatch Loss= 2635.420898, Training Accuracy= 0.75000\n",
      "Iter 177856, Minibatch Loss= 2402.955566, Training Accuracy= 0.76562\n",
      "Iter 177920, Minibatch Loss= 1856.522583, Training Accuracy= 0.78125\n",
      "Iter 177984, Minibatch Loss= 2003.442871, Training Accuracy= 0.79688\n",
      "Iter 178048, Minibatch Loss= 4223.169922, Training Accuracy= 0.64062\n",
      "Iter 178112, Minibatch Loss= 2467.710449, Training Accuracy= 0.75000\n",
      "Iter 178176, Minibatch Loss= 1587.248779, Training Accuracy= 0.78125\n",
      "Iter 178240, Minibatch Loss= 3232.939941, Training Accuracy= 0.68750\n",
      "Iter 178304, Minibatch Loss= 3576.181641, Training Accuracy= 0.60938\n",
      "Iter 178368, Minibatch Loss= 2227.011963, Training Accuracy= 0.68750\n",
      "Iter 178432, Minibatch Loss= 3177.936035, Training Accuracy= 0.64062\n",
      "Iter 178496, Minibatch Loss= 2342.729492, Training Accuracy= 0.62500\n",
      "Iter 178560, Minibatch Loss= 4947.743164, Training Accuracy= 0.64062\n",
      "Iter 178624, Minibatch Loss= 5067.558594, Training Accuracy= 0.62500\n",
      "Iter 178688, Minibatch Loss= 4199.911133, Training Accuracy= 0.60938\n",
      "Iter 178752, Minibatch Loss= 3213.541504, Training Accuracy= 0.76562\n",
      "Iter 178816, Minibatch Loss= 4581.497070, Training Accuracy= 0.73438\n",
      "Iter 178880, Minibatch Loss= 2876.290771, Training Accuracy= 0.75000\n",
      "Iter 178944, Minibatch Loss= 1975.402832, Training Accuracy= 0.73438\n",
      "Iter 179008, Minibatch Loss= 1547.599854, Training Accuracy= 0.84375\n",
      "Iter 179072, Minibatch Loss= 3387.582520, Training Accuracy= 0.70312\n",
      "Iter 179136, Minibatch Loss= 3092.621826, Training Accuracy= 0.73438\n",
      "Iter 179200, Minibatch Loss= 1486.402954, Training Accuracy= 0.76562\n",
      "Iter 179264, Minibatch Loss= 2755.791016, Training Accuracy= 0.71875\n",
      "Iter 179328, Minibatch Loss= 3499.963623, Training Accuracy= 0.60938\n",
      "Iter 179392, Minibatch Loss= 2971.689209, Training Accuracy= 0.73438\n",
      "Iter 179456, Minibatch Loss= 3136.002930, Training Accuracy= 0.71875\n",
      "Iter 179520, Minibatch Loss= 2974.893066, Training Accuracy= 0.68750\n",
      "Iter 179584, Minibatch Loss= 3924.524902, Training Accuracy= 0.62500\n",
      "Iter 179648, Minibatch Loss= 4169.402344, Training Accuracy= 0.53125\n",
      "Iter 179712, Minibatch Loss= 3601.491699, Training Accuracy= 0.68750\n",
      "Iter 179776, Minibatch Loss= 2521.653809, Training Accuracy= 0.71875\n",
      "Iter 179840, Minibatch Loss= 2695.776367, Training Accuracy= 0.73438\n",
      "Iter 179904, Minibatch Loss= 2272.368652, Training Accuracy= 0.76562\n",
      "Iter 179968, Minibatch Loss= 2598.614502, Training Accuracy= 0.73438\n",
      "Iter 180032, Minibatch Loss= 3006.487549, Training Accuracy= 0.70312\n",
      "Iter 180096, Minibatch Loss= 1770.087769, Training Accuracy= 0.73438\n",
      "Iter 180160, Minibatch Loss= 1034.596680, Training Accuracy= 0.84375\n",
      "Iter 180224, Minibatch Loss= 2219.546631, Training Accuracy= 0.71875\n",
      "Iter 180288, Minibatch Loss= 3221.802002, Training Accuracy= 0.70312\n",
      "Iter 180352, Minibatch Loss= 3207.233398, Training Accuracy= 0.70312\n",
      "Iter 180416, Minibatch Loss= 1775.211548, Training Accuracy= 0.68750\n",
      "Iter 180480, Minibatch Loss= 2903.858643, Training Accuracy= 0.68750\n",
      "Iter 180544, Minibatch Loss= 3891.397949, Training Accuracy= 0.68750\n",
      "Iter 180608, Minibatch Loss= 2857.949951, Training Accuracy= 0.71875\n",
      "Iter 180672, Minibatch Loss= 2911.298828, Training Accuracy= 0.65625\n",
      "Iter 180736, Minibatch Loss= 1987.117065, Training Accuracy= 0.75000\n",
      "Iter 180800, Minibatch Loss= 2996.030762, Training Accuracy= 0.78125\n",
      "Iter 180864, Minibatch Loss= 3138.832520, Training Accuracy= 0.71875\n",
      "Iter 180928, Minibatch Loss= 2379.889893, Training Accuracy= 0.70312\n",
      "Iter 180992, Minibatch Loss= 2094.444824, Training Accuracy= 0.68750\n",
      "Iter 181056, Minibatch Loss= 1896.520020, Training Accuracy= 0.75000\n",
      "Iter 181120, Minibatch Loss= 1588.242432, Training Accuracy= 0.68750\n",
      "Iter 181184, Minibatch Loss= 1071.505859, Training Accuracy= 0.82812\n",
      "Iter 181248, Minibatch Loss= 2276.763184, Training Accuracy= 0.71875\n",
      "Iter 181312, Minibatch Loss= 2655.463867, Training Accuracy= 0.71875\n",
      "Iter 181376, Minibatch Loss= 1965.256348, Training Accuracy= 0.76562\n",
      "Iter 181440, Minibatch Loss= 1983.500244, Training Accuracy= 0.78125\n",
      "Iter 181504, Minibatch Loss= 1903.613770, Training Accuracy= 0.75000\n",
      "Iter 181568, Minibatch Loss= 2780.186035, Training Accuracy= 0.60938\n",
      "Iter 181632, Minibatch Loss= 1886.652100, Training Accuracy= 0.70312\n",
      "Iter 181696, Minibatch Loss= 2910.500488, Training Accuracy= 0.59375\n",
      "Iter 181760, Minibatch Loss= 3599.768555, Training Accuracy= 0.68750\n",
      "Iter 181824, Minibatch Loss= 1811.517578, Training Accuracy= 0.75000\n",
      "Iter 181888, Minibatch Loss= 3090.959961, Training Accuracy= 0.75000\n",
      "Iter 181952, Minibatch Loss= 3993.162354, Training Accuracy= 0.62500\n",
      "Iter 182016, Minibatch Loss= 4464.379883, Training Accuracy= 0.65625\n",
      "Iter 182080, Minibatch Loss= 4208.708496, Training Accuracy= 0.71875\n",
      "Iter 182144, Minibatch Loss= 2598.514893, Training Accuracy= 0.78125\n",
      "Iter 182208, Minibatch Loss= 2785.867920, Training Accuracy= 0.78125\n",
      "Iter 182272, Minibatch Loss= 1246.715088, Training Accuracy= 0.79688\n",
      "Iter 182336, Minibatch Loss= 4650.825195, Training Accuracy= 0.65625\n",
      "Iter 182400, Minibatch Loss= 1359.740723, Training Accuracy= 0.76562\n",
      "Iter 182464, Minibatch Loss= 2217.922119, Training Accuracy= 0.75000\n",
      "Iter 182528, Minibatch Loss= 2033.943359, Training Accuracy= 0.73438\n",
      "Iter 182592, Minibatch Loss= 3817.288086, Training Accuracy= 0.71875\n",
      "Iter 182656, Minibatch Loss= 1593.806641, Training Accuracy= 0.78125\n",
      "Iter 182720, Minibatch Loss= 2507.283691, Training Accuracy= 0.78125\n",
      "Iter 182784, Minibatch Loss= 652.071594, Training Accuracy= 0.89062\n",
      "Iter 182848, Minibatch Loss= 1382.138672, Training Accuracy= 0.71875\n",
      "Iter 182912, Minibatch Loss= 2033.370117, Training Accuracy= 0.65625\n",
      "Iter 182976, Minibatch Loss= 1813.299438, Training Accuracy= 0.73438\n",
      "Iter 183040, Minibatch Loss= 1642.198975, Training Accuracy= 0.76562\n",
      "Iter 183104, Minibatch Loss= 3666.975586, Training Accuracy= 0.65625\n",
      "Iter 183168, Minibatch Loss= 2966.391113, Training Accuracy= 0.67188\n",
      "Iter 183232, Minibatch Loss= 4439.398438, Training Accuracy= 0.78125\n",
      "Iter 183296, Minibatch Loss= 4635.338867, Training Accuracy= 0.64062\n",
      "Iter 183360, Minibatch Loss= 3433.555908, Training Accuracy= 0.65625\n",
      "Iter 183424, Minibatch Loss= 2254.987305, Training Accuracy= 0.79688\n",
      "Iter 183488, Minibatch Loss= 2934.575195, Training Accuracy= 0.67188\n",
      "Iter 183552, Minibatch Loss= 2968.267578, Training Accuracy= 0.75000\n",
      "Iter 183616, Minibatch Loss= 2718.196289, Training Accuracy= 0.68750\n",
      "Iter 183680, Minibatch Loss= 1690.542847, Training Accuracy= 0.81250\n",
      "Iter 183744, Minibatch Loss= 2818.305176, Training Accuracy= 0.70312\n",
      "Iter 183808, Minibatch Loss= 3713.969238, Training Accuracy= 0.68750\n",
      "Iter 183872, Minibatch Loss= 2980.272949, Training Accuracy= 0.70312\n",
      "Iter 183936, Minibatch Loss= 5038.194336, Training Accuracy= 0.65625\n",
      "Iter 184000, Minibatch Loss= 2564.886719, Training Accuracy= 0.75000\n",
      "Iter 184064, Minibatch Loss= 3339.408447, Training Accuracy= 0.70312\n",
      "Iter 184128, Minibatch Loss= 3330.822754, Training Accuracy= 0.68750\n",
      "Iter 184192, Minibatch Loss= 3179.486816, Training Accuracy= 0.73438\n",
      "Iter 184256, Minibatch Loss= 5717.743164, Training Accuracy= 0.65625\n",
      "Iter 184320, Minibatch Loss= 1102.383789, Training Accuracy= 0.81250\n",
      "Iter 184384, Minibatch Loss= 1538.303589, Training Accuracy= 0.76562\n",
      "Iter 184448, Minibatch Loss= 2652.260742, Training Accuracy= 0.75000\n",
      "Iter 184512, Minibatch Loss= 1044.240356, Training Accuracy= 0.79688\n",
      "Iter 184576, Minibatch Loss= 2071.599609, Training Accuracy= 0.71875\n",
      "Iter 184640, Minibatch Loss= 3717.738770, Training Accuracy= 0.62500\n",
      "Iter 184704, Minibatch Loss= 577.525879, Training Accuracy= 0.84375\n",
      "Iter 184768, Minibatch Loss= 5439.435059, Training Accuracy= 0.53125\n",
      "Iter 184832, Minibatch Loss= 2384.077637, Training Accuracy= 0.64062\n",
      "Iter 184896, Minibatch Loss= 3085.059082, Training Accuracy= 0.65625\n",
      "Iter 184960, Minibatch Loss= 4726.883789, Training Accuracy= 0.65625\n",
      "Iter 185024, Minibatch Loss= 2904.902588, Training Accuracy= 0.62500\n",
      "Iter 185088, Minibatch Loss= 2819.511230, Training Accuracy= 0.71875\n",
      "Iter 185152, Minibatch Loss= 2316.213379, Training Accuracy= 0.68750\n",
      "Iter 185216, Minibatch Loss= 3848.348145, Training Accuracy= 0.59375\n",
      "Iter 185280, Minibatch Loss= 2745.993164, Training Accuracy= 0.67188\n",
      "Iter 185344, Minibatch Loss= 3378.107910, Training Accuracy= 0.64062\n",
      "Iter 185408, Minibatch Loss= 2599.678467, Training Accuracy= 0.68750\n",
      "Iter 185472, Minibatch Loss= 2575.856445, Training Accuracy= 0.68750\n",
      "Iter 185536, Minibatch Loss= 2529.945312, Training Accuracy= 0.73438\n",
      "Iter 185600, Minibatch Loss= 1603.643921, Training Accuracy= 0.79688\n",
      "Iter 185664, Minibatch Loss= 1944.187744, Training Accuracy= 0.71875\n",
      "Iter 185728, Minibatch Loss= 2553.237549, Training Accuracy= 0.70312\n",
      "Iter 185792, Minibatch Loss= 3950.306885, Training Accuracy= 0.67188\n",
      "Iter 185856, Minibatch Loss= 2108.619385, Training Accuracy= 0.75000\n",
      "Iter 185920, Minibatch Loss= 2650.836426, Training Accuracy= 0.65625\n",
      "Iter 185984, Minibatch Loss= 2567.788086, Training Accuracy= 0.75000\n",
      "Iter 186048, Minibatch Loss= 3919.591797, Training Accuracy= 0.73438\n",
      "Iter 186112, Minibatch Loss= 4650.283203, Training Accuracy= 0.54688\n",
      "Iter 186176, Minibatch Loss= 2336.774658, Training Accuracy= 0.78125\n",
      "Iter 186240, Minibatch Loss= 4278.509277, Training Accuracy= 0.60938\n",
      "Iter 186304, Minibatch Loss= 4989.394531, Training Accuracy= 0.64062\n",
      "Iter 186368, Minibatch Loss= 4077.386230, Training Accuracy= 0.60938\n",
      "Iter 186432, Minibatch Loss= 5331.161133, Training Accuracy= 0.59375\n",
      "Iter 186496, Minibatch Loss= 3600.758301, Training Accuracy= 0.65625\n",
      "Iter 186560, Minibatch Loss= 3567.895752, Training Accuracy= 0.68750\n",
      "Iter 186624, Minibatch Loss= 1580.232178, Training Accuracy= 0.75000\n",
      "Iter 186688, Minibatch Loss= 2475.135498, Training Accuracy= 0.68750\n",
      "Iter 186752, Minibatch Loss= 3642.817139, Training Accuracy= 0.79688\n",
      "Iter 186816, Minibatch Loss= 2050.382324, Training Accuracy= 0.78125\n",
      "Iter 186880, Minibatch Loss= 2719.216309, Training Accuracy= 0.68750\n",
      "Iter 186944, Minibatch Loss= 3668.878906, Training Accuracy= 0.71875\n",
      "Iter 187008, Minibatch Loss= 2085.115967, Training Accuracy= 0.70312\n",
      "Iter 187072, Minibatch Loss= 1277.738281, Training Accuracy= 0.81250\n",
      "Iter 187136, Minibatch Loss= 1903.767822, Training Accuracy= 0.79688\n",
      "Iter 187200, Minibatch Loss= 1861.614258, Training Accuracy= 0.81250\n",
      "Iter 187264, Minibatch Loss= 5743.368652, Training Accuracy= 0.70312\n",
      "Iter 187328, Minibatch Loss= 2357.270996, Training Accuracy= 0.79688\n",
      "Iter 187392, Minibatch Loss= 1974.822876, Training Accuracy= 0.75000\n",
      "Iter 187456, Minibatch Loss= 1956.501587, Training Accuracy= 0.71875\n",
      "Iter 187520, Minibatch Loss= 1935.415771, Training Accuracy= 0.71875\n",
      "Iter 187584, Minibatch Loss= 3123.952637, Training Accuracy= 0.68750\n",
      "Iter 187648, Minibatch Loss= 2809.600098, Training Accuracy= 0.70312\n",
      "Iter 187712, Minibatch Loss= 1548.301514, Training Accuracy= 0.76562\n",
      "Iter 187776, Minibatch Loss= 3094.428955, Training Accuracy= 0.62500\n",
      "Iter 187840, Minibatch Loss= 4004.328857, Training Accuracy= 0.64062\n",
      "Iter 187904, Minibatch Loss= 1965.451294, Training Accuracy= 0.65625\n",
      "Iter 187968, Minibatch Loss= 3816.384277, Training Accuracy= 0.73438\n",
      "Iter 188032, Minibatch Loss= 2158.918457, Training Accuracy= 0.75000\n",
      "Iter 188096, Minibatch Loss= 2516.480469, Training Accuracy= 0.73438\n",
      "Iter 188160, Minibatch Loss= 2859.131348, Training Accuracy= 0.68750\n",
      "Iter 188224, Minibatch Loss= 3374.352051, Training Accuracy= 0.68750\n",
      "Iter 188288, Minibatch Loss= 2526.270020, Training Accuracy= 0.70312\n",
      "Iter 188352, Minibatch Loss= 2673.342529, Training Accuracy= 0.75000\n",
      "Iter 188416, Minibatch Loss= 3178.556152, Training Accuracy= 0.73438\n",
      "Iter 188480, Minibatch Loss= 4514.994629, Training Accuracy= 0.62500\n",
      "Iter 188544, Minibatch Loss= 2296.664551, Training Accuracy= 0.70312\n",
      "Iter 188608, Minibatch Loss= 4973.577148, Training Accuracy= 0.70312\n",
      "Iter 188672, Minibatch Loss= 3310.825684, Training Accuracy= 0.71875\n",
      "Iter 188736, Minibatch Loss= 2701.492188, Training Accuracy= 0.65625\n",
      "Iter 188800, Minibatch Loss= 2514.792236, Training Accuracy= 0.68750\n",
      "Iter 188864, Minibatch Loss= 1822.100342, Training Accuracy= 0.75000\n",
      "Iter 188928, Minibatch Loss= 3551.156738, Training Accuracy= 0.62500\n",
      "Iter 188992, Minibatch Loss= 6206.532715, Training Accuracy= 0.64062\n",
      "Iter 189056, Minibatch Loss= 3465.464844, Training Accuracy= 0.65625\n",
      "Iter 189120, Minibatch Loss= 4210.640137, Training Accuracy= 0.56250\n",
      "Iter 189184, Minibatch Loss= 3002.002930, Training Accuracy= 0.71875\n",
      "Iter 189248, Minibatch Loss= 1813.210327, Training Accuracy= 0.73438\n",
      "Iter 189312, Minibatch Loss= 3022.145752, Training Accuracy= 0.65625\n",
      "Iter 189376, Minibatch Loss= 3000.400146, Training Accuracy= 0.71875\n",
      "Iter 189440, Minibatch Loss= 2096.624268, Training Accuracy= 0.71875\n",
      "Iter 189504, Minibatch Loss= 3533.604492, Training Accuracy= 0.62500\n",
      "Iter 189568, Minibatch Loss= 2275.197266, Training Accuracy= 0.68750\n",
      "Iter 189632, Minibatch Loss= 2242.833740, Training Accuracy= 0.65625\n",
      "Iter 189696, Minibatch Loss= 3228.262695, Training Accuracy= 0.67188\n",
      "Iter 189760, Minibatch Loss= 3144.428955, Training Accuracy= 0.70312\n",
      "Iter 189824, Minibatch Loss= 2055.357666, Training Accuracy= 0.65625\n",
      "Iter 189888, Minibatch Loss= 1877.230347, Training Accuracy= 0.71875\n",
      "Iter 189952, Minibatch Loss= 1433.178223, Training Accuracy= 0.73438\n",
      "Iter 190016, Minibatch Loss= 1421.385254, Training Accuracy= 0.73438\n",
      "Iter 190080, Minibatch Loss= 2343.500732, Training Accuracy= 0.65625\n",
      "Iter 190144, Minibatch Loss= 1790.060547, Training Accuracy= 0.78125\n",
      "Iter 190208, Minibatch Loss= 2332.843750, Training Accuracy= 0.71875\n",
      "Iter 190272, Minibatch Loss= 1710.800659, Training Accuracy= 0.76562\n",
      "Iter 190336, Minibatch Loss= 2787.379639, Training Accuracy= 0.73438\n",
      "Iter 190400, Minibatch Loss= 2047.880371, Training Accuracy= 0.68750\n",
      "Iter 190464, Minibatch Loss= 1913.834106, Training Accuracy= 0.81250\n",
      "Iter 190528, Minibatch Loss= 3174.047607, Training Accuracy= 0.67188\n",
      "Iter 190592, Minibatch Loss= 3525.281738, Training Accuracy= 0.71875\n",
      "Iter 190656, Minibatch Loss= 3190.966309, Training Accuracy= 0.75000\n",
      "Iter 190720, Minibatch Loss= 2567.885742, Training Accuracy= 0.68750\n",
      "Iter 190784, Minibatch Loss= 3458.268066, Training Accuracy= 0.67188\n",
      "Iter 190848, Minibatch Loss= 2298.584961, Training Accuracy= 0.70312\n",
      "Iter 190912, Minibatch Loss= 2614.229980, Training Accuracy= 0.67188\n",
      "Iter 190976, Minibatch Loss= 2974.926270, Training Accuracy= 0.70312\n",
      "Iter 191040, Minibatch Loss= 2055.347900, Training Accuracy= 0.68750\n",
      "Iter 191104, Minibatch Loss= 3555.114990, Training Accuracy= 0.70312\n",
      "Iter 191168, Minibatch Loss= 2403.630859, Training Accuracy= 0.75000\n",
      "Iter 191232, Minibatch Loss= 2242.776855, Training Accuracy= 0.81250\n",
      "Iter 191296, Minibatch Loss= 3237.631348, Training Accuracy= 0.68750\n",
      "Iter 191360, Minibatch Loss= 2413.759277, Training Accuracy= 0.62500\n",
      "Iter 191424, Minibatch Loss= 3307.215820, Training Accuracy= 0.73438\n",
      "Iter 191488, Minibatch Loss= 2065.817383, Training Accuracy= 0.70312\n",
      "Iter 191552, Minibatch Loss= 2662.378418, Training Accuracy= 0.75000\n",
      "Iter 191616, Minibatch Loss= 3750.010986, Training Accuracy= 0.64062\n",
      "Iter 191680, Minibatch Loss= 3944.301514, Training Accuracy= 0.62500\n",
      "Iter 191744, Minibatch Loss= 3077.113770, Training Accuracy= 0.64062\n",
      "Iter 191808, Minibatch Loss= 3122.543945, Training Accuracy= 0.68750\n",
      "Iter 191872, Minibatch Loss= 2688.360352, Training Accuracy= 0.64062\n",
      "Iter 191936, Minibatch Loss= 3180.450684, Training Accuracy= 0.70312\n",
      "Iter 192000, Minibatch Loss= 2516.075439, Training Accuracy= 0.73438\n",
      "Iter 192064, Minibatch Loss= 2564.259766, Training Accuracy= 0.81250\n",
      "Iter 192128, Minibatch Loss= 2374.561523, Training Accuracy= 0.78125\n",
      "Iter 192192, Minibatch Loss= 3201.968506, Training Accuracy= 0.73438\n",
      "Iter 192256, Minibatch Loss= 4777.328613, Training Accuracy= 0.68750\n",
      "Iter 192320, Minibatch Loss= 3847.045898, Training Accuracy= 0.62500\n",
      "Iter 192384, Minibatch Loss= 3184.350098, Training Accuracy= 0.73438\n",
      "Iter 192448, Minibatch Loss= 3267.162842, Training Accuracy= 0.65625\n",
      "Iter 192512, Minibatch Loss= 2003.124634, Training Accuracy= 0.73438\n",
      "Iter 192576, Minibatch Loss= 5304.523438, Training Accuracy= 0.64062\n",
      "Iter 192640, Minibatch Loss= 2775.947754, Training Accuracy= 0.71875\n",
      "Iter 192704, Minibatch Loss= 1643.632080, Training Accuracy= 0.73438\n",
      "Iter 192768, Minibatch Loss= 2462.077637, Training Accuracy= 0.71875\n",
      "Iter 192832, Minibatch Loss= 2703.912354, Training Accuracy= 0.75000\n",
      "Iter 192896, Minibatch Loss= 1990.649902, Training Accuracy= 0.73438\n",
      "Iter 192960, Minibatch Loss= 3132.464355, Training Accuracy= 0.70312\n",
      "Iter 193024, Minibatch Loss= 1996.165527, Training Accuracy= 0.76562\n",
      "Iter 193088, Minibatch Loss= 3289.329590, Training Accuracy= 0.75000\n",
      "Iter 193152, Minibatch Loss= 4887.547363, Training Accuracy= 0.59375\n",
      "Iter 193216, Minibatch Loss= 1293.195190, Training Accuracy= 0.82812\n",
      "Iter 193280, Minibatch Loss= 2447.533447, Training Accuracy= 0.75000\n",
      "Iter 193344, Minibatch Loss= 2448.237793, Training Accuracy= 0.71875\n",
      "Iter 193408, Minibatch Loss= 2862.424805, Training Accuracy= 0.65625\n",
      "Iter 193472, Minibatch Loss= 3296.391602, Training Accuracy= 0.75000\n",
      "Iter 193536, Minibatch Loss= 2080.739990, Training Accuracy= 0.73438\n",
      "Iter 193600, Minibatch Loss= 1629.137573, Training Accuracy= 0.73438\n",
      "Iter 193664, Minibatch Loss= 4709.303711, Training Accuracy= 0.60938\n",
      "Iter 193728, Minibatch Loss= 3267.314453, Training Accuracy= 0.67188\n",
      "Iter 193792, Minibatch Loss= 4382.358398, Training Accuracy= 0.71875\n",
      "Iter 193856, Minibatch Loss= 3036.266602, Training Accuracy= 0.71875\n",
      "Iter 193920, Minibatch Loss= 2329.237549, Training Accuracy= 0.68750\n",
      "Iter 193984, Minibatch Loss= 2847.577148, Training Accuracy= 0.65625\n",
      "Iter 194048, Minibatch Loss= 2658.269043, Training Accuracy= 0.68750\n",
      "Iter 194112, Minibatch Loss= 1835.512939, Training Accuracy= 0.62500\n",
      "Iter 194176, Minibatch Loss= 2069.677979, Training Accuracy= 0.67188\n",
      "Iter 194240, Minibatch Loss= 1437.634033, Training Accuracy= 0.73438\n",
      "Iter 194304, Minibatch Loss= 3224.712891, Training Accuracy= 0.64062\n",
      "Iter 194368, Minibatch Loss= 1901.485840, Training Accuracy= 0.71875\n",
      "Iter 194432, Minibatch Loss= 2703.771484, Training Accuracy= 0.65625\n",
      "Iter 194496, Minibatch Loss= 1821.648804, Training Accuracy= 0.76562\n",
      "Iter 194560, Minibatch Loss= 3770.297852, Training Accuracy= 0.56250\n",
      "Iter 194624, Minibatch Loss= 2518.843506, Training Accuracy= 0.68750\n",
      "Iter 194688, Minibatch Loss= 2504.994385, Training Accuracy= 0.64062\n",
      "Iter 194752, Minibatch Loss= 1893.074707, Training Accuracy= 0.75000\n",
      "Iter 194816, Minibatch Loss= 1953.787842, Training Accuracy= 0.76562\n",
      "Iter 194880, Minibatch Loss= 2202.753662, Training Accuracy= 0.68750\n",
      "Iter 194944, Minibatch Loss= 1890.827271, Training Accuracy= 0.81250\n",
      "Iter 195008, Minibatch Loss= 1765.040405, Training Accuracy= 0.76562\n",
      "Iter 195072, Minibatch Loss= 3298.529053, Training Accuracy= 0.71875\n",
      "Iter 195136, Minibatch Loss= 1792.350098, Training Accuracy= 0.71875\n",
      "Iter 195200, Minibatch Loss= 2752.072998, Training Accuracy= 0.67188\n",
      "Iter 195264, Minibatch Loss= 2871.478271, Training Accuracy= 0.75000\n",
      "Iter 195328, Minibatch Loss= 2349.326904, Training Accuracy= 0.79688\n",
      "Iter 195392, Minibatch Loss= 3154.707031, Training Accuracy= 0.65625\n",
      "Iter 195456, Minibatch Loss= 2535.631592, Training Accuracy= 0.62500\n",
      "Iter 195520, Minibatch Loss= 2135.436279, Training Accuracy= 0.73438\n",
      "Iter 195584, Minibatch Loss= 3704.687500, Training Accuracy= 0.53125\n",
      "Iter 195648, Minibatch Loss= 1770.404785, Training Accuracy= 0.71875\n",
      "Iter 195712, Minibatch Loss= 1291.026001, Training Accuracy= 0.78125\n",
      "Iter 195776, Minibatch Loss= 1842.792969, Training Accuracy= 0.68750\n",
      "Iter 195840, Minibatch Loss= 1935.248901, Training Accuracy= 0.76562\n",
      "Iter 195904, Minibatch Loss= 2707.688477, Training Accuracy= 0.65625\n",
      "Iter 195968, Minibatch Loss= 2260.126953, Training Accuracy= 0.67188\n",
      "Iter 196032, Minibatch Loss= 3269.992188, Training Accuracy= 0.68750\n",
      "Iter 196096, Minibatch Loss= 1910.312988, Training Accuracy= 0.79688\n",
      "Iter 196160, Minibatch Loss= 3209.225586, Training Accuracy= 0.68750\n",
      "Iter 196224, Minibatch Loss= 4098.877930, Training Accuracy= 0.60938\n",
      "Iter 196288, Minibatch Loss= 3191.920898, Training Accuracy= 0.65625\n",
      "Iter 196352, Minibatch Loss= 2734.841553, Training Accuracy= 0.70312\n",
      "Iter 196416, Minibatch Loss= 3318.588867, Training Accuracy= 0.65625\n",
      "Iter 196480, Minibatch Loss= 2659.720459, Training Accuracy= 0.70312\n",
      "Iter 196544, Minibatch Loss= 2803.559082, Training Accuracy= 0.68750\n",
      "Iter 196608, Minibatch Loss= 2543.496094, Training Accuracy= 0.71875\n",
      "Iter 196672, Minibatch Loss= 2146.535645, Training Accuracy= 0.70312\n",
      "Iter 196736, Minibatch Loss= 1991.265625, Training Accuracy= 0.71875\n",
      "Iter 196800, Minibatch Loss= 1404.065063, Training Accuracy= 0.71875\n",
      "Iter 196864, Minibatch Loss= 2566.380371, Training Accuracy= 0.65625\n",
      "Iter 196928, Minibatch Loss= 1712.145142, Training Accuracy= 0.81250\n",
      "Iter 196992, Minibatch Loss= 2968.491455, Training Accuracy= 0.67188\n",
      "Iter 197056, Minibatch Loss= 2286.753174, Training Accuracy= 0.78125\n",
      "Iter 197120, Minibatch Loss= 2984.707031, Training Accuracy= 0.71875\n",
      "Iter 197184, Minibatch Loss= 1806.408691, Training Accuracy= 0.70312\n",
      "Iter 197248, Minibatch Loss= 3830.505859, Training Accuracy= 0.62500\n",
      "Iter 197312, Minibatch Loss= 2351.458984, Training Accuracy= 0.73438\n",
      "Iter 197376, Minibatch Loss= 2672.299316, Training Accuracy= 0.70312\n",
      "Iter 197440, Minibatch Loss= 2297.106934, Training Accuracy= 0.75000\n",
      "Iter 197504, Minibatch Loss= 2705.585693, Training Accuracy= 0.65625\n",
      "Iter 197568, Minibatch Loss= 3289.191406, Training Accuracy= 0.64062\n",
      "Iter 197632, Minibatch Loss= 4729.391602, Training Accuracy= 0.64062\n",
      "Iter 197696, Minibatch Loss= 2140.184082, Training Accuracy= 0.73438\n",
      "Iter 197760, Minibatch Loss= 3341.068848, Training Accuracy= 0.62500\n",
      "Iter 197824, Minibatch Loss= 2274.064941, Training Accuracy= 0.78125\n",
      "Iter 197888, Minibatch Loss= 2735.977783, Training Accuracy= 0.75000\n",
      "Iter 197952, Minibatch Loss= 2495.280762, Training Accuracy= 0.64062\n",
      "Iter 198016, Minibatch Loss= 1634.815308, Training Accuracy= 0.78125\n",
      "Iter 198080, Minibatch Loss= 3867.922607, Training Accuracy= 0.64062\n",
      "Iter 198144, Minibatch Loss= 2497.648682, Training Accuracy= 0.70312\n",
      "Iter 198208, Minibatch Loss= 2439.967285, Training Accuracy= 0.70312\n",
      "Iter 198272, Minibatch Loss= 2843.249512, Training Accuracy= 0.67188\n",
      "Iter 198336, Minibatch Loss= 1817.438721, Training Accuracy= 0.79688\n",
      "Iter 198400, Minibatch Loss= 2935.509033, Training Accuracy= 0.67188\n",
      "Iter 198464, Minibatch Loss= 2476.730469, Training Accuracy= 0.76562\n",
      "Iter 198528, Minibatch Loss= 1266.221680, Training Accuracy= 0.81250\n",
      "Iter 198592, Minibatch Loss= 3664.227783, Training Accuracy= 0.60938\n",
      "Iter 198656, Minibatch Loss= 1864.416748, Training Accuracy= 0.67188\n",
      "Iter 198720, Minibatch Loss= 1351.468628, Training Accuracy= 0.79688\n",
      "Iter 198784, Minibatch Loss= 3258.445801, Training Accuracy= 0.71875\n",
      "Iter 198848, Minibatch Loss= 2717.087402, Training Accuracy= 0.64062\n",
      "Iter 198912, Minibatch Loss= 1106.080078, Training Accuracy= 0.82812\n",
      "Iter 198976, Minibatch Loss= 2260.638184, Training Accuracy= 0.67188\n",
      "Iter 199040, Minibatch Loss= 1543.070557, Training Accuracy= 0.78125\n",
      "Iter 199104, Minibatch Loss= 2224.610596, Training Accuracy= 0.71875\n",
      "Iter 199168, Minibatch Loss= 2554.912598, Training Accuracy= 0.67188\n",
      "Iter 199232, Minibatch Loss= 2430.623047, Training Accuracy= 0.78125\n",
      "Iter 199296, Minibatch Loss= 2732.499512, Training Accuracy= 0.73438\n",
      "Iter 199360, Minibatch Loss= 2365.191162, Training Accuracy= 0.67188\n",
      "Iter 199424, Minibatch Loss= 1853.484863, Training Accuracy= 0.78125\n",
      "Iter 199488, Minibatch Loss= 3469.822021, Training Accuracy= 0.64062\n",
      "Iter 199552, Minibatch Loss= 2081.253418, Training Accuracy= 0.70312\n",
      "Iter 199616, Minibatch Loss= 1974.133545, Training Accuracy= 0.78125\n",
      "Iter 199680, Minibatch Loss= 2958.226562, Training Accuracy= 0.68750\n",
      "Iter 199744, Minibatch Loss= 3297.035645, Training Accuracy= 0.68750\n",
      "Iter 199808, Minibatch Loss= 2408.647949, Training Accuracy= 0.70312\n",
      "Iter 199872, Minibatch Loss= 1806.468140, Training Accuracy= 0.67188\n",
      "Iter 199936, Minibatch Loss= 1614.751709, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.71875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        #if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            # Calculate batch loss\n",
    "        loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y: mnist.test.labels[:256], keep_prob: 1.}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### REFERENCE\n",
    "\n",
    "https://github.com/aymericdamien/TensorFlow-Examples\n",
    "\n",
    "http://cs231n.stanford.edu/\n",
    "\n",
    "http://shop.oreilly.com/product/0636920052289.do\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
